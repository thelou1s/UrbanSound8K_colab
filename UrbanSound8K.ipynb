{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"UrbanSound8K.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1YcoPhjFlj9jkqNNAtDfrsmldDGgikOlQ","authorship_tag":"ABX9TyNyA/ZYWuJfjw1J4DJ0zH13"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"NQD9E-SueOfl","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1592206114248,"user_tz":-480,"elapsed":2068,"user":{"displayName":"SM Health","photoUrl":"","userId":"14421832128980954224"}},"outputId":"0640834e-ea62-459b-ba2a-419f8e45b7d6"},"source":["import tensorflow as tf\n","\n","print(tf.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2.2.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6aG-J--lodfe","colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"status":"ok","timestamp":1591147863166,"user_tz":-480,"elapsed":108186,"user":{"displayName":"SM Health","photoUrl":"","userId":"14421832128980954224"}},"outputId":"789658b3-848d-4ec9-849e-caed1f477e66"},"source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n","# ————————————————\n","# 版权声明：本文为CSDN博主「LCCFlccf」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。\n","# 原文链接：https://blog.csdn.net/LCCFlccf/java/article/details/89302730"],"execution_count":null,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","Selecting previously unselected package google-drive-ocamlfuse.\n","(Reading database ... 144467 files and directories currently installed.)\n","Preparing to unpack .../google-drive-ocamlfuse_0.7.22-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n","Unpacking google-drive-ocamlfuse (0.7.22-0ubuntu1~ubuntu18.04.1) ...\n","Setting up google-drive-ocamlfuse (0.7.22-0ubuntu1~ubuntu18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iavYWzv1zjcB","colab":{"base_uri":"https://localhost:8080/","height":197},"executionInfo":{"status":"ok","timestamp":1592206130844,"user_tz":-480,"elapsed":4345,"user":{"displayName":"SM Health","photoUrl":"","userId":"14421832128980954224"}},"outputId":"edd359c5-4712-4641-e6a4-52116ba9a94b"},"source":["# 指定Google Drive云端硬盘的根目录，名为drive\n","# !mkdir -p drive\n","# !google-drive-ocamlfuse drive\n","\n","# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')\n","\n","!ls /content/drive/'My Drive'\n","# !ls /content/drive/'My Drive'/audio_classifier_tutorial/UrbanSound8K\n","# !top"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"," audio_classifier_tutorial\t\t  'Sleep Monitor_app_v121.gsheet'\n"," bq-results-20200331-154548-i5vvaponde5c  'Sleep Monitor Feedback.gsheet'\n"," bq-results-20200331-154548-qpo4cr21f6xp  'SM_Music License Agreement.gdoc'\n","'Colab Notebooks'\t\t\t   SM_订阅页面翻译v122.gsheet\n","'DrinkWR2020  ROI.gsheet'\t\t  'Untitled spreadsheet.gsheet'\n","'DWR 2020-6月.gsheet'\t\t\t   UrbanSound8K_README.txt\n","'DWR 2020-7月.gsheet'\t\t\t   广告数据分析表.gsheet\n"," FREESOUNDCREDITS.txt\t\t\t   美国.gsheet\n"," LOGO_512.png\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"He4CavTCplNr"},"source":["# https://blog.doiduoyi.com/articles/1587654005620.html?\n","\n","import os\n","\n","import librosa\n","\n","# from numba.decorators import jit as optional_jit\n","\n","\n","def get_data_list(audio_path, list_path):\n","    sound_sum = 0\n","    audios = os.listdir(audio_path)\n","\n","    f_train = open(os.path.join(list_path, 'train_list.txt'), 'w')\n","    f_test = open(os.path.join(list_path, 'test_list.txt'), 'w')\n","\n","    for i in range(len(audios)):\n","        sounds = os.listdir(os.path.join(audio_path, audios[i]))\n","        for sound in sounds:\n","            sound_path = os.path.join(audio_path, audios[i], sound)\n","            print(\"get_data_list, sound_path = %s \" % sound_path)\n","\n","            try:\n","                t = librosa.get_duration(filename=sound_path)\n","                print(\"get_data_list, get_duration = %s \" % t)\n","                # [可能需要修改参数] 过滤小于2.1秒的音频\n","                if t >= 2.1:\n","                    if sound_sum % 100 == 0:\n","                        f_test.write('%s\\t%d\\n' % (sound_path, i))\n","                    else:\n","                        f_train.write('%s\\t%d\\n' % (sound_path, i))\n","                    sound_sum += 1\n","            except:\n","                print(\"get_data_list, except sound_path = %s\" % sound_path)\n","\n","        print(\"get_data_list, Audio：%d/%d\" % (i + 1, len(audios)))\n","\n","    f_test.close()\n","    f_train.close()\n","\n","\n","if __name__ == '__main__':\n","    get_data_list('/content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/audio', '/content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/metadata')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MjHEBC-C6pCU","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1591162555172,"user_tz":-480,"elapsed":7001496,"user":{"displayName":"SM Health","photoUrl":"","userId":"14421832128980954224"}},"outputId":"db4cee7b-867c-419b-9814-84b49e67e950"},"source":["# create_tfrecord.py\n","\n","import tensorflow as tf\n","import librosa\n","import random\n","import numpy as np\n","from tqdm import tqdm\n","\n","# 获取浮点数组\n","def _float_feature(value):\n","    if not isinstance(value, list):\n","        value = [value]\n","    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n","\n","\n","# 获取整型数据\n","def _int64_feature(value):\n","    if not isinstance(value, list):\n","        value = [value]\n","    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n","\n","\n","# 把数据添加到TFRecord中\n","def data_example(data, label):\n","    feature = {\n","        'data': _float_feature(data),\n","        'label': _int64_feature(label),\n","    }\n","    return tf.train.Example(features=tf.train.Features(feature=feature))\n","\n","\n","# 开始创建tfrecord数据\n","def create_data_tfrecord(data_list_path, save_path):\n","    with open(data_list_path, 'r') as f:\n","        data = f.readlines()\n","    with tf.io.TFRecordWriter(save_path) as writer:\n","        for d in tqdm(data):\n","            try:\n","                path, label = d.replace('\\n', '').split('\\t')\n","                wav, sr = librosa.load(path, sr=16000)\n","                intervals = librosa.effects.split(wav, top_db=20)\n","                wav_output = []\n","                # [可能需要修改参数] 音频长度 16000 * 秒数\n","                wav_len = int(16000 * 2.04)\n","                for sliced in intervals:\n","                    wav_output.extend(wav[sliced[0]:sliced[1]])\n","                for i in range(5):\n","                    # 裁剪过长的音频，过短的补0\n","                    if len(wav_output) > wav_len:\n","                        l = len(wav_output) - wav_len\n","                        r = random.randint(0, l)\n","                        wav_output = wav_output[r:wav_len + r]\n","                    else:\n","                        wav_output.extend(np.zeros(shape=[wav_len - len(wav_output)], dtype=np.float32))\n","                    wav_output = np.array(wav_output)\n","                    # 转成梅尔频谱\n","                    ps = librosa.feature.melspectrogram(y=wav_output, sr=sr, hop_length=256).reshape(-1).tolist()\n","                    # [可能需要修改参数] 梅尔频谱shape ，librosa.feature.melspectrogram(y=wav_output, sr=sr, hop_length=256).shape\n","                    if len(ps) != 128 * 128: continue\n","                    tf_example = data_example(ps, int(label))\n","                    writer.write(tf_example.SerializeToString())\n","                    if len(wav_output) <= wav_len:\n","                        break\n","            except Exception as e:\n","                print(e)\n","\n","\n","if __name__ == '__main__':\n","    create_data_tfrecord('/content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/metadata/train_list.txt', '/content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/metadata/train.tfrecord')\n","    create_data_tfrecord('/content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/metadata/test_list.txt', '/content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/metadata/test.tfrecord')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 7631/7631 [1:55:25<00:00,  1.10it/s]\n","100%|██████████| 78/78 [01:14<00:00,  1.05it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"nHLqO3qQTPOR","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592363870858,"user_tz":-480,"elapsed":4386273,"user":{"displayName":"SM Health","photoUrl":"","userId":"14421832128980954224"}},"outputId":"10f8f52d-9c05-4c1c-fad4-4ceef0be3066"},"source":["# train_data.py\n","\n","import tensorflow as tf\n","import numpy as np\n","\n","class_dim = 10\n","EPOCHS = 100\n","BATCH_SIZE=32\n","# EPOCHS = 1\n","# BATCH_SIZE=16\n","\n","tf.compat.v1.enable_eager_execution() # WARNING:tensorflow:From E:/workspace/python/doiduoyi/src/train_data.py:8: The name tf.enable_eager_execution is deprecated. Please use tf.compat.v1.enable_eager_execution instead.\n","#tf.enable_eager_execution() # https://github.com/tensorflow/datasets/issues/233\n","\n","model = tf.keras.models.Sequential([\n","    tf.keras.applications.ResNet50V2(include_top=False, weights=None, input_shape=(128, None, 1)),\n","    tf.keras.layers.ActivityRegularization(l2=0.5),\n","    tf.keras.layers.Dropout(rate=0.5),\n","    tf.keras.layers.GlobalMaxPooling2D(),\n","    tf.keras.layers.Dense(units=class_dim, activation=tf.nn.softmax)\n","])\n","\n","model.summary()\n","\n","\n","# 定义优化方法\n","optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n","\n","##########################################################\n","\n","def _parse_data_function(example):\n","    # [可能需要修改参数】 设置的梅尔频谱的shape相乘的值\n","    data_feature_description = {\n","        'data': tf.io.FixedLenFeature([16384], tf.float32),\n","        'label': tf.io.FixedLenFeature([], tf.int64),\n","    }\n","    return tf.io.parse_single_example(example, data_feature_description)\n","\n","\n","def train_reader_tfrecord(data_path, num_epochs, batch_size):\n","    raw_dataset = tf.data.TFRecordDataset(data_path)\n","    train_dataset = raw_dataset.map(_parse_data_function)\n","    train_dataset = train_dataset.shuffle(buffer_size=1000) \\\n","        .repeat(count=num_epochs) \\\n","        .batch(batch_size=batch_size) \\\n","        .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n","    return train_dataset\n","\n","\n","def test_reader_tfrecord(data_path, batch_size):\n","    raw_dataset = tf.data.TFRecordDataset(data_path)\n","    test_dataset = raw_dataset.map(_parse_data_function)\n","    test_dataset = test_dataset.batch(batch_size=batch_size)\n","    return test_dataset\n","##########################################################\n","\n","\n","# train_dataset = reader.train_reader_tfrecord('F:/Downloads/UrbanSound8K/metadata//train.tfrecord', EPOCHS, batch_size=BATCH_SIZE)\n","# test_dataset = reader.test_reader_tfrecord('F:/Downloads/UrbanSound8K/metadata//test.tfrecord', batch_size=BATCH_SIZE)\n","\n","train_dataset = train_reader_tfrecord('/content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/metadata//train.tfrecord', EPOCHS, batch_size=BATCH_SIZE)\n","test_dataset = test_reader_tfrecord('/content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/metadata//test.tfrecord', batch_size=BATCH_SIZE)\n","\n","\n","##########################################################\n","\n","for batch_id, data in enumerate(train_dataset):\n","    # [可能需要修改参数】 设置的梅尔频谱的shape\n","    sounds = data['data'].numpy().reshape((-1, 128, 128, 1))\n","    labels = data['label']\n","    # 执行训练\n","    with tf.GradientTape() as tape:\n","        predictions = model(sounds)\n","        # 获取损失值\n","        train_loss = tf.keras.losses.sparse_categorical_crossentropy(labels, predictions)\n","        train_loss = tf.reduce_mean(train_loss)\n","        # 获取准确率\n","        train_accuracy = tf.keras.metrics.sparse_categorical_accuracy(labels, predictions)\n","        train_accuracy = np.sum(train_accuracy.numpy()) / len(train_accuracy.numpy())\n","\n","    # 更新梯度\n","    gradients = tape.gradient(train_loss, model.trainable_variables)\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","\n","    # if batch_id % 20 == 0:\n","    #     print(\"Batch %d, Loss %f, Accuracy %f\" % (batch_id, train_loss.numpy(), train_accuracy))\n","    print(\"Batch %d, Loss %f, Accuracy %f\" % (batch_id, train_loss.numpy(), train_accuracy))\n","\n","    if batch_id % 200 == 0 and batch_id != 0:\n","        test_losses = list()\n","        test_accuracies = list()\n","        for d in test_dataset:\n","            try:\n","                print(\"Batch %d\" % (d))\n","            except:\n","                print(\"Batch except\")\n","\n","            # [可能需要修改参数】 设置的梅尔频谱的shape\n","            test_sounds = d['data'].numpy().reshape((-1, 128, 128, 1))\n","            test_labels = d['label']\n","\n","            test_result = model(test_sounds)\n","            # 获取损失值\n","            test_loss = tf.keras.losses.sparse_categorical_crossentropy(test_labels, test_result)\n","            test_loss = tf.reduce_mean(test_loss)\n","            test_losses.append(test_loss)\n","            # 获取准确率\n","            test_accuracy = tf.keras.metrics.sparse_categorical_accuracy(test_labels, test_result)\n","            test_accuracy = np.sum(test_accuracy.numpy()) / len(test_accuracy.numpy())\n","            test_accuracies.append(test_accuracy)\n","\n","        print('=================================================')\n","        print(\"Test, Loss %f, Accuracy %f\" % (\n","            sum(test_losses) / len(test_losses), sum(test_accuracies) / len(test_accuracies)))\n","        print('=================================================')\n","\n","        # 保存模型\n","        # model.save(filepath='F:/Downloads/UrbanSound8K/models/resnet50.h5')\n","        model.save(filepath='/content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/models/resnet50.h5')\n","##########################################################"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[1;30;43m流式输出内容被截断，只能显示最后 5000 行内容。\u001b[0m\n","Batch 18998, Loss 1.453483, Accuracy 0.531250\n","Batch 18999, Loss 1.169668, Accuracy 0.500000\n","Batch 19000, Loss 1.337126, Accuracy 0.468750\n","Batch except\n","Batch except\n","Batch except\n","=================================================\n","Test, Loss 5.117010, Accuracy 0.083333\n","=================================================\n","Batch 19001, Loss 1.729754, Accuracy 0.375000\n","Batch 19002, Loss 1.508246, Accuracy 0.500000\n","Batch 19003, Loss 1.983719, Accuracy 0.375000\n","Batch 19004, Loss 1.634984, Accuracy 0.531250\n","Batch 19005, Loss 1.676693, Accuracy 0.406250\n","Batch 19006, Loss 1.786031, Accuracy 0.375000\n","Batch 19007, Loss 1.558875, Accuracy 0.562500\n","Batch 19008, Loss 1.629131, Accuracy 0.437500\n","Batch 19009, Loss 1.707987, Accuracy 0.312500\n","Batch 19010, Loss 1.506931, Accuracy 0.406250\n","Batch 19011, Loss 1.475863, Accuracy 0.468750\n","Batch 19012, Loss 1.325006, Accuracy 0.531250\n","Batch 19013, Loss 1.449077, Accuracy 0.406250\n","Batch 19014, Loss 1.655189, Accuracy 0.406250\n","Batch 19015, Loss 1.421569, Accuracy 0.343750\n","Batch 19016, Loss 1.780589, Accuracy 0.250000\n","Batch 19017, Loss 1.829737, Accuracy 0.187500\n","Batch 19018, Loss 1.319124, Accuracy 0.406250\n","Batch 19019, Loss 1.264292, Accuracy 0.562500\n","Batch 19020, Loss 1.679022, Accuracy 0.375000\n","Batch 19021, Loss 1.179528, Accuracy 0.593750\n","Batch 19022, Loss 1.289774, Accuracy 0.562500\n","Batch 19023, Loss 1.146593, Accuracy 0.687500\n","Batch 19024, Loss 1.599511, Accuracy 0.406250\n","Batch 19025, Loss 1.520020, Accuracy 0.375000\n","Batch 19026, Loss 1.614801, Accuracy 0.468750\n","Batch 19027, Loss 1.565534, Accuracy 0.437500\n","Batch 19028, Loss 1.608999, Accuracy 0.500000\n","Batch 19029, Loss 1.859895, Accuracy 0.343750\n","Batch 19030, Loss 1.665213, Accuracy 0.468750\n","Batch 19031, Loss 1.665174, Accuracy 0.343750\n","Batch 19032, Loss 1.654563, Accuracy 0.406250\n","Batch 19033, Loss 1.657879, Accuracy 0.406250\n","Batch 19034, Loss 1.589266, Accuracy 0.343750\n","Batch 19035, Loss 1.661337, Accuracy 0.375000\n","Batch 19036, Loss 1.763159, Accuracy 0.250000\n","Batch 19037, Loss 1.442533, Accuracy 0.343750\n","Batch 19038, Loss 1.421277, Accuracy 0.406250\n","Batch 19039, Loss 1.512631, Accuracy 0.500000\n","Batch 19040, Loss 1.388946, Accuracy 0.312500\n","Batch 19041, Loss 1.281915, Accuracy 0.437500\n","Batch 19042, Loss 1.328396, Accuracy 0.468750\n","Batch 19043, Loss 1.464421, Accuracy 0.531250\n","Batch 19044, Loss 1.369971, Accuracy 0.500000\n","Batch 19045, Loss 1.268010, Accuracy 0.593750\n","Batch 19046, Loss 1.373912, Accuracy 0.500000\n","Batch 19047, Loss 1.413498, Accuracy 0.437500\n","Batch 19048, Loss 1.181440, Accuracy 0.625000\n","Batch 19049, Loss 1.207514, Accuracy 0.468750\n","Batch 19050, Loss 1.494746, Accuracy 0.437500\n","Batch 19051, Loss 1.427304, Accuracy 0.312500\n","Batch 19052, Loss 1.259743, Accuracy 0.625000\n","Batch 19053, Loss 1.494473, Accuracy 0.531250\n","Batch 19054, Loss 1.266659, Accuracy 0.656250\n","Batch 19055, Loss 1.068228, Accuracy 0.593750\n","Batch 19056, Loss 1.615229, Accuracy 0.500000\n","Batch 19057, Loss 1.745835, Accuracy 0.375000\n","Batch 19058, Loss 1.273670, Accuracy 0.468750\n","Batch 19059, Loss 1.488860, Accuracy 0.468750\n","Batch 19060, Loss 1.382201, Accuracy 0.343750\n","Batch 19061, Loss 1.401494, Accuracy 0.593750\n","Batch 19062, Loss 1.376225, Accuracy 0.500000\n","Batch 19063, Loss 1.267350, Accuracy 0.531250\n","Batch 19064, Loss 1.252335, Accuracy 0.656250\n","Batch 19065, Loss 1.191559, Accuracy 0.500000\n","Batch 19066, Loss 1.297486, Accuracy 0.468750\n","Batch 19067, Loss 1.381669, Accuracy 0.468750\n","Batch 19068, Loss 1.066805, Accuracy 0.562500\n","Batch 19069, Loss 1.457146, Accuracy 0.500000\n","Batch 19070, Loss 1.492567, Accuracy 0.437500\n","Batch 19071, Loss 1.475316, Accuracy 0.375000\n","Batch 19072, Loss 1.601580, Accuracy 0.531250\n","Batch 19073, Loss 1.407288, Accuracy 0.375000\n","Batch 19074, Loss 1.289302, Accuracy 0.406250\n","Batch 19075, Loss 1.711560, Accuracy 0.250000\n","Batch 19076, Loss 1.399390, Accuracy 0.218750\n","Batch 19077, Loss 2.931215, Accuracy 0.218750\n","Batch 19078, Loss 4.074047, Accuracy 0.000000\n","Batch 19079, Loss 3.225838, Accuracy 0.000000\n","Batch 19080, Loss 2.570593, Accuracy 0.000000\n","Batch 19081, Loss 1.873651, Accuracy 0.718750\n","Batch 19082, Loss 1.687169, Accuracy 0.593750\n","Batch 19083, Loss 1.738718, Accuracy 0.000000\n","Batch 19084, Loss 1.618477, Accuracy 0.468750\n","Batch 19085, Loss 1.446948, Accuracy 0.500000\n","Batch 19086, Loss 1.338349, Accuracy 0.406250\n","Batch 19087, Loss 1.248878, Accuracy 0.562500\n","Batch 19088, Loss 1.190285, Accuracy 0.562500\n","Batch 19089, Loss 1.143615, Accuracy 0.562500\n","Batch 19090, Loss 1.111917, Accuracy 0.437500\n","Batch 19091, Loss 1.080609, Accuracy 0.562500\n","Batch 19092, Loss 1.057445, Accuracy 0.562500\n","Batch 19093, Loss 1.050449, Accuracy 0.312500\n","Batch 19094, Loss 1.017192, Accuracy 0.531250\n","Batch 19095, Loss 1.003801, Accuracy 0.437500\n","Batch 19096, Loss 1.032172, Accuracy 0.437500\n","Batch 19097, Loss 1.059158, Accuracy 0.500000\n","Batch 19098, Loss 1.201221, Accuracy 0.281250\n","Batch 19099, Loss 1.135374, Accuracy 0.375000\n","Batch 19100, Loss 1.124109, Accuracy 0.468750\n","Batch 19101, Loss 1.118456, Accuracy 0.343750\n","Batch 19102, Loss 1.204604, Accuracy 0.593750\n","Batch 19103, Loss 1.435485, Accuracy 0.343750\n","Batch 19104, Loss 1.230145, Accuracy 0.468750\n","Batch 19105, Loss 1.261709, Accuracy 0.500000\n","Batch 19106, Loss 1.270690, Accuracy 0.281250\n","Batch 19107, Loss 1.323758, Accuracy 0.437500\n","Batch 19108, Loss 1.234264, Accuracy 0.531250\n","Batch 19109, Loss 1.285065, Accuracy 0.562500\n","Batch 19110, Loss 1.461449, Accuracy 0.218750\n","Batch 19111, Loss 1.198494, Accuracy 0.437500\n","Batch 19112, Loss 1.290135, Accuracy 0.343750\n","Batch 19113, Loss 1.280271, Accuracy 0.343750\n","Batch 19114, Loss 1.404701, Accuracy 0.312500\n","Batch 19115, Loss 1.228514, Accuracy 0.468750\n","Batch 19116, Loss 1.334897, Accuracy 0.281250\n","Batch 19117, Loss 1.226716, Accuracy 0.281250\n","Batch 19118, Loss 1.294598, Accuracy 0.468750\n","Batch 19119, Loss 1.137360, Accuracy 0.562500\n","Batch 19120, Loss 1.082589, Accuracy 0.531250\n","Batch 19121, Loss 0.882264, Accuracy 0.750000\n","Batch 19122, Loss 1.828324, Accuracy 0.468750\n","Batch 19123, Loss 1.064804, Accuracy 0.593750\n","Batch 19124, Loss 1.462206, Accuracy 0.468750\n","Batch 19125, Loss 1.415396, Accuracy 0.250000\n","Batch 19126, Loss 1.374222, Accuracy 0.531250\n","Batch 19127, Loss 1.376980, Accuracy 0.500000\n","Batch 19128, Loss 1.327675, Accuracy 0.468750\n","Batch 19129, Loss 1.125688, Accuracy 0.625000\n","Batch 19130, Loss 1.567519, Accuracy 0.312500\n","Batch 19131, Loss 1.333031, Accuracy 0.437500\n","Batch 19132, Loss 1.195249, Accuracy 0.500000\n","Batch 19133, Loss 1.414436, Accuracy 0.406250\n","Batch 19134, Loss 1.453294, Accuracy 0.218750\n","Batch 19135, Loss 1.388301, Accuracy 0.343750\n","Batch 19136, Loss 1.359949, Accuracy 0.406250\n","Batch 19137, Loss 1.341696, Accuracy 0.343750\n","Batch 19138, Loss 1.155996, Accuracy 0.562500\n","Batch 19139, Loss 1.165061, Accuracy 0.500000\n","Batch 19140, Loss 1.499900, Accuracy 0.375000\n","Batch 19141, Loss 1.445067, Accuracy 0.343750\n","Batch 19142, Loss 1.189256, Accuracy 0.406250\n","Batch 19143, Loss 1.282444, Accuracy 0.375000\n","Batch 19144, Loss 1.409584, Accuracy 0.218750\n","Batch 19145, Loss 1.340800, Accuracy 0.281250\n","Batch 19146, Loss 1.272491, Accuracy 0.281250\n","Batch 19147, Loss 1.429876, Accuracy 0.312500\n","Batch 19148, Loss 1.316624, Accuracy 0.625000\n","Batch 19149, Loss 1.636515, Accuracy 0.437500\n","Batch 19150, Loss 1.191091, Accuracy 0.718750\n","Batch 19151, Loss 1.429234, Accuracy 0.468750\n","Batch 19152, Loss 1.610591, Accuracy 0.468750\n","Batch 19153, Loss 1.816815, Accuracy 0.343750\n","Batch 19154, Loss 1.833204, Accuracy 0.406250\n","Batch 19155, Loss 1.505681, Accuracy 0.500000\n","Batch 19156, Loss 1.647221, Accuracy 0.437500\n","Batch 19157, Loss 1.743555, Accuracy 0.312500\n","Batch 19158, Loss 1.453180, Accuracy 0.468750\n","Batch 19159, Loss 1.620285, Accuracy 0.218750\n","Batch 19160, Loss 1.457916, Accuracy 0.375000\n","Batch 19161, Loss 1.265949, Accuracy 0.375000\n","Batch 19162, Loss 1.609064, Accuracy 0.125000\n","Batch 19163, Loss 1.462410, Accuracy 0.375000\n","Batch 19164, Loss 1.138927, Accuracy 0.500000\n","Batch 19165, Loss 1.236076, Accuracy 0.531250\n","Batch 19166, Loss 1.321473, Accuracy 0.437500\n","Batch 19167, Loss 1.225161, Accuracy 0.468750\n","Batch 19168, Loss 0.910866, Accuracy 0.750000\n","Batch 19169, Loss 1.167752, Accuracy 0.625000\n","Batch 19170, Loss 1.409104, Accuracy 0.500000\n","Batch 19171, Loss 1.697488, Accuracy 0.375000\n","Batch 19172, Loss 1.973015, Accuracy 0.375000\n","Batch 19173, Loss 1.580690, Accuracy 0.468750\n","Batch 19174, Loss 1.588821, Accuracy 0.375000\n","Batch 19175, Loss 1.574865, Accuracy 0.531250\n","Batch 19176, Loss 1.605095, Accuracy 0.500000\n","Batch 19177, Loss 1.775409, Accuracy 0.343750\n","Batch 19178, Loss 1.949083, Accuracy 0.218750\n","Batch 19179, Loss 1.613866, Accuracy 0.406250\n","Batch 19180, Loss 1.578799, Accuracy 0.312500\n","Batch 19181, Loss 1.441256, Accuracy 0.375000\n","Batch 19182, Loss 1.385510, Accuracy 0.406250\n","Batch 19183, Loss 1.583461, Accuracy 0.406250\n","Batch 19184, Loss 1.348031, Accuracy 0.562500\n","Batch 19185, Loss 1.501857, Accuracy 0.406250\n","Batch 19186, Loss 1.710133, Accuracy 0.375000\n","Batch 19187, Loss 1.203212, Accuracy 0.593750\n","Batch 19188, Loss 1.430603, Accuracy 0.468750\n","Batch 19189, Loss 1.407043, Accuracy 0.468750\n","Batch 19190, Loss 1.389645, Accuracy 0.500000\n","Batch 19191, Loss 1.377055, Accuracy 0.437500\n","Batch 19192, Loss 1.336275, Accuracy 0.500000\n","Batch 19193, Loss 1.576552, Accuracy 0.437500\n","Batch 19194, Loss 1.161707, Accuracy 0.562500\n","Batch 19195, Loss 1.756846, Accuracy 0.437500\n","Batch 19196, Loss 1.844445, Accuracy 0.500000\n","Batch 19197, Loss 1.614925, Accuracy 0.500000\n","Batch 19198, Loss 1.847466, Accuracy 0.500000\n","Batch 19199, Loss 1.907242, Accuracy 0.500000\n","Batch 19200, Loss 1.875423, Accuracy 0.437500\n","Batch except\n","Batch except\n","Batch except\n","=================================================\n","Test, Loss 5.518797, Accuracy 0.083333\n","=================================================\n","Batch 19201, Loss 1.993852, Accuracy 0.437500\n","Batch 19202, Loss 1.930685, Accuracy 0.250000\n","Batch 19203, Loss 1.919715, Accuracy 0.343750\n","Batch 19204, Loss 1.674072, Accuracy 0.531250\n","Batch 19205, Loss 1.676465, Accuracy 0.406250\n","Batch 19206, Loss 1.566034, Accuracy 0.437500\n","Batch 19207, Loss 1.584604, Accuracy 0.312500\n","Batch 19208, Loss 1.335231, Accuracy 0.468750\n","Batch 19209, Loss 1.518326, Accuracy 0.468750\n","Batch 19210, Loss 1.487244, Accuracy 0.406250\n","Batch 19211, Loss 1.680704, Accuracy 0.250000\n","Batch 19212, Loss 1.458112, Accuracy 0.250000\n","Batch 19213, Loss 1.330347, Accuracy 0.281250\n","Batch 19214, Loss 1.420943, Accuracy 0.187500\n","Batch 19215, Loss 1.499678, Accuracy 0.531250\n","Batch 19216, Loss 1.428652, Accuracy 0.562500\n","Batch 19217, Loss 1.514874, Accuracy 0.500000\n","Batch 19218, Loss 1.616019, Accuracy 0.437500\n","Batch 19219, Loss 1.656836, Accuracy 0.437500\n","Batch 19220, Loss 1.410197, Accuracy 0.562500\n","Batch 19221, Loss 1.569965, Accuracy 0.375000\n","Batch 19222, Loss 1.826442, Accuracy 0.343750\n","Batch 19223, Loss 1.898437, Accuracy 0.281250\n","Batch 19224, Loss 1.634691, Accuracy 0.343750\n","Batch 19225, Loss 1.720979, Accuracy 0.312500\n","Batch 19226, Loss 1.758167, Accuracy 0.312500\n","Batch 19227, Loss 1.596089, Accuracy 0.375000\n","Batch 19228, Loss 1.659529, Accuracy 0.343750\n","Batch 19229, Loss 1.891474, Accuracy 0.250000\n","Batch 19230, Loss 1.654791, Accuracy 0.312500\n","Batch 19231, Loss 1.327320, Accuracy 0.562500\n","Batch 19232, Loss 1.898329, Accuracy 0.375000\n","Batch 19233, Loss 1.510376, Accuracy 0.468750\n","Batch 19234, Loss 1.320469, Accuracy 0.468750\n","Batch 19235, Loss 1.415784, Accuracy 0.281250\n","Batch 19236, Loss 1.610591, Accuracy 0.281250\n","Batch 19237, Loss 1.303748, Accuracy 0.468750\n","Batch 19238, Loss 1.397456, Accuracy 0.531250\n","Batch 19239, Loss 1.057511, Accuracy 0.656250\n","Batch 19240, Loss 1.129606, Accuracy 0.687500\n","Batch 19241, Loss 1.494853, Accuracy 0.687500\n","Batch 19242, Loss 1.495937, Accuracy 0.562500\n","Batch 19243, Loss 1.642690, Accuracy 0.593750\n","Batch 19244, Loss 1.797244, Accuracy 0.375000\n","Batch 19245, Loss 1.675586, Accuracy 0.531250\n","Batch 19246, Loss 2.123433, Accuracy 0.250000\n","Batch 19247, Loss 1.728955, Accuracy 0.531250\n","Batch 19248, Loss 1.680300, Accuracy 0.406250\n","Batch 19249, Loss 1.428963, Accuracy 0.375000\n","Batch 19250, Loss 1.457151, Accuracy 0.281250\n","Batch 19251, Loss 1.633873, Accuracy 0.406250\n","Batch 19252, Loss 1.504462, Accuracy 0.343750\n","Batch 19253, Loss 1.609456, Accuracy 0.406250\n","Batch 19254, Loss 1.511901, Accuracy 0.468750\n","Batch 19255, Loss 1.385128, Accuracy 0.343750\n","Batch 19256, Loss 1.505933, Accuracy 0.406250\n","Batch 19257, Loss 1.289280, Accuracy 0.531250\n","Batch 19258, Loss 1.610325, Accuracy 0.531250\n","Batch 19259, Loss 1.569186, Accuracy 0.406250\n","Batch 19260, Loss 1.420794, Accuracy 0.468750\n","Batch 19261, Loss 1.511124, Accuracy 0.437500\n","Batch 19262, Loss 1.287122, Accuracy 0.593750\n","Batch 19263, Loss 1.467834, Accuracy 0.500000\n","Batch 19264, Loss 1.557568, Accuracy 0.500000\n","Batch 19265, Loss 1.485372, Accuracy 0.437500\n","Batch 19266, Loss 1.848562, Accuracy 0.500000\n","Batch 19267, Loss 1.948548, Accuracy 0.312500\n","Batch 19268, Loss 1.562661, Accuracy 0.500000\n","Batch 19269, Loss 1.525774, Accuracy 0.562500\n","Batch 19270, Loss 1.391964, Accuracy 0.562500\n","Batch 19271, Loss 1.649477, Accuracy 0.437500\n","Batch 19272, Loss 1.849983, Accuracy 0.312500\n","Batch 19273, Loss 1.701771, Accuracy 0.343750\n","Batch 19274, Loss 1.600964, Accuracy 0.343750\n","Batch 19275, Loss 1.768448, Accuracy 0.250000\n","Batch 19276, Loss 1.607869, Accuracy 0.218750\n","Batch 19277, Loss 1.530422, Accuracy 0.406250\n","Batch 19278, Loss 1.306450, Accuracy 0.375000\n","Batch 19279, Loss 1.414536, Accuracy 0.406250\n","Batch 19280, Loss 1.289758, Accuracy 0.406250\n","Batch 19281, Loss 1.776182, Accuracy 0.281250\n","Batch 19282, Loss 1.412356, Accuracy 0.312500\n","Batch 19283, Loss 1.268751, Accuracy 0.437500\n","Batch 19284, Loss 1.472453, Accuracy 0.500000\n","Batch 19285, Loss 1.302897, Accuracy 0.656250\n","Batch 19286, Loss 1.237835, Accuracy 0.531250\n","Batch 19287, Loss 1.614848, Accuracy 0.500000\n","Batch 19288, Loss 1.359599, Accuracy 0.437500\n","Batch 19289, Loss 1.542899, Accuracy 0.500000\n","Batch 19290, Loss 1.415244, Accuracy 0.562500\n","Batch 19291, Loss 1.298803, Accuracy 0.562500\n","Batch 19292, Loss 1.366099, Accuracy 0.468750\n","Batch 19293, Loss 1.412291, Accuracy 0.406250\n","Batch 19294, Loss 1.685063, Accuracy 0.437500\n","Batch 19295, Loss 1.411111, Accuracy 0.531250\n","Batch 19296, Loss 1.302527, Accuracy 0.625000\n","Batch 19297, Loss 1.639095, Accuracy 0.406250\n","Batch 19298, Loss 1.333615, Accuracy 0.500000\n","Batch 19299, Loss 1.245803, Accuracy 0.656250\n","Batch 19300, Loss 1.329167, Accuracy 0.468750\n","Batch 19301, Loss 1.244657, Accuracy 0.593750\n","Batch 19302, Loss 1.309615, Accuracy 0.656250\n","Batch 19303, Loss 1.398192, Accuracy 0.500000\n","Batch 19304, Loss 0.957015, Accuracy 0.687500\n","Batch 19305, Loss 1.296072, Accuracy 0.593750\n","Batch 19306, Loss 1.503220, Accuracy 0.468750\n","Batch 19307, Loss 1.416357, Accuracy 0.375000\n","Batch 19308, Loss 1.294865, Accuracy 0.531250\n","Batch 19309, Loss 1.621556, Accuracy 0.312500\n","Batch 19310, Loss 1.280987, Accuracy 0.625000\n","Batch 19311, Loss 1.536072, Accuracy 0.437500\n","Batch 19312, Loss 1.440923, Accuracy 0.468750\n","Batch 19313, Loss 1.282713, Accuracy 0.531250\n","Batch 19314, Loss 1.386385, Accuracy 0.406250\n","Batch 19315, Loss 1.474859, Accuracy 0.687500\n","Batch 19316, Loss 5.047262, Accuracy 0.000000\n","Batch 19317, Loss 3.896293, Accuracy 0.000000\n","Batch 19318, Loss 2.677019, Accuracy 0.000000\n","Batch 19319, Loss 1.741839, Accuracy 0.000000\n","Batch 19320, Loss 1.224606, Accuracy 0.375000\n","Batch 19321, Loss 1.193514, Accuracy 0.218750\n","Batch 19322, Loss 1.136076, Accuracy 0.531250\n","Batch 19323, Loss 1.103134, Accuracy 0.343750\n","Batch 19324, Loss 1.063532, Accuracy 0.437500\n","Batch 19325, Loss 1.035529, Accuracy 0.468750\n","Batch 19326, Loss 1.012829, Accuracy 0.437500\n","Batch 19327, Loss 0.997167, Accuracy 0.406250\n","Batch 19328, Loss 0.982384, Accuracy 0.468750\n","Batch 19329, Loss 0.971942, Accuracy 0.437500\n","Batch 19330, Loss 0.957435, Accuracy 0.468750\n","Batch 19331, Loss 0.943247, Accuracy 0.468750\n","Batch 19332, Loss 0.923004, Accuracy 0.531250\n","Batch 19333, Loss 0.904771, Accuracy 0.562500\n","Batch 19334, Loss 0.888373, Accuracy 0.562500\n","Batch 19335, Loss 1.104848, Accuracy 0.406250\n","Batch 19336, Loss 0.925577, Accuracy 0.375000\n","Batch 19337, Loss 1.087222, Accuracy 0.312500\n","Batch 19338, Loss 1.193038, Accuracy 0.406250\n","Batch 19339, Loss 1.245676, Accuracy 0.343750\n","Batch 19340, Loss 1.398004, Accuracy 0.437500\n","Batch 19341, Loss 0.990139, Accuracy 0.625000\n","Batch 19342, Loss 1.448271, Accuracy 0.437500\n","Batch 19343, Loss 1.378812, Accuracy 0.406250\n","Batch 19344, Loss 1.290819, Accuracy 0.343750\n","Batch 19345, Loss 1.363548, Accuracy 0.281250\n","Batch 19346, Loss 1.214707, Accuracy 0.531250\n","Batch 19347, Loss 1.146657, Accuracy 0.500000\n","Batch 19348, Loss 1.308114, Accuracy 0.375000\n","Batch 19349, Loss 1.280366, Accuracy 0.406250\n","Batch 19350, Loss 1.436661, Accuracy 0.187500\n","Batch 19351, Loss 1.232311, Accuracy 0.437500\n","Batch 19352, Loss 1.218966, Accuracy 0.406250\n","Batch 19353, Loss 1.261596, Accuracy 0.375000\n","Batch 19354, Loss 1.235153, Accuracy 0.250000\n","Batch 19355, Loss 1.082085, Accuracy 0.281250\n","Batch 19356, Loss 1.087430, Accuracy 0.562500\n","Batch 19357, Loss 1.236000, Accuracy 0.437500\n","Batch 19358, Loss 0.980939, Accuracy 0.625000\n","Batch 19359, Loss 1.007066, Accuracy 0.531250\n","Batch 19360, Loss 0.972072, Accuracy 0.562500\n","Batch 19361, Loss 1.383004, Accuracy 0.406250\n","Batch 19362, Loss 1.362670, Accuracy 0.500000\n","Batch 19363, Loss 1.178595, Accuracy 0.562500\n","Batch 19364, Loss 1.197787, Accuracy 0.437500\n","Batch 19365, Loss 1.474602, Accuracy 0.406250\n","Batch 19366, Loss 1.447244, Accuracy 0.562500\n","Batch 19367, Loss 1.562317, Accuracy 0.406250\n","Batch 19368, Loss 1.382513, Accuracy 0.437500\n","Batch 19369, Loss 1.338973, Accuracy 0.468750\n","Batch 19370, Loss 1.557805, Accuracy 0.250000\n","Batch 19371, Loss 1.505646, Accuracy 0.250000\n","Batch 19372, Loss 1.288645, Accuracy 0.562500\n","Batch 19373, Loss 1.245844, Accuracy 0.375000\n","Batch 19374, Loss 1.317708, Accuracy 0.406250\n","Batch 19375, Loss 1.121229, Accuracy 0.468750\n","Batch 19376, Loss 1.138383, Accuracy 0.375000\n","Batch 19377, Loss 1.146204, Accuracy 0.437500\n","Batch 19378, Loss 1.490091, Accuracy 0.406250\n","Batch 19379, Loss 1.301229, Accuracy 0.281250\n","Batch 19380, Loss 1.412424, Accuracy 0.250000\n","Batch 19381, Loss 1.269619, Accuracy 0.437500\n","Batch 19382, Loss 1.328500, Accuracy 0.156250\n","Batch 19383, Loss 1.212193, Accuracy 0.593750\n","Batch 19384, Loss 1.041121, Accuracy 0.656250\n","Batch 19385, Loss 0.695673, Accuracy 0.812500\n","Batch 19386, Loss 2.195539, Accuracy 0.468750\n","Batch 19387, Loss 1.411278, Accuracy 0.593750\n","Batch 19388, Loss 1.687082, Accuracy 0.375000\n","Batch 19389, Loss 1.577619, Accuracy 0.625000\n","Batch 19390, Loss 1.689063, Accuracy 0.468750\n","Batch 19391, Loss 1.875715, Accuracy 0.281250\n","Batch 19392, Loss 1.897116, Accuracy 0.093750\n","Batch 19393, Loss 1.693937, Accuracy 0.437500\n","Batch 19394, Loss 2.103133, Accuracy 0.250000\n","Batch 19395, Loss 2.056619, Accuracy 0.156250\n","Batch 19396, Loss 1.658841, Accuracy 0.375000\n","Batch 19397, Loss 1.572077, Accuracy 0.343750\n","Batch 19398, Loss 1.338142, Accuracy 0.531250\n","Batch 19399, Loss 1.497359, Accuracy 0.312500\n","Batch 19400, Loss 1.432403, Accuracy 0.281250\n","Batch except\n","Batch except\n","Batch except\n","=================================================\n","Test, Loss 8.366283, Accuracy 0.083333\n","=================================================\n","Batch 19401, Loss 1.391784, Accuracy 0.312500\n","Batch 19402, Loss 1.222358, Accuracy 0.375000\n","Batch 19403, Loss 1.461954, Accuracy 0.375000\n","Batch 19404, Loss 1.227075, Accuracy 0.531250\n","Batch 19405, Loss 1.390835, Accuracy 0.468750\n","Batch 19406, Loss 1.152835, Accuracy 0.562500\n","Batch 19407, Loss 1.399615, Accuracy 0.500000\n","Batch 19408, Loss 1.445266, Accuracy 0.531250\n","Batch 19409, Loss 1.523792, Accuracy 0.375000\n","Batch 19410, Loss 1.384997, Accuracy 0.500000\n","Batch 19411, Loss 1.895854, Accuracy 0.187500\n","Batch 19412, Loss 1.692652, Accuracy 0.437500\n","Batch 19413, Loss 1.421005, Accuracy 0.468750\n","Batch 19414, Loss 1.631212, Accuracy 0.375000\n","Batch 19415, Loss 1.402101, Accuracy 0.437500\n","Batch 19416, Loss 1.808986, Accuracy 0.281250\n","Batch 19417, Loss 1.357687, Accuracy 0.562500\n","Batch 19418, Loss 1.567616, Accuracy 0.375000\n","Batch 19419, Loss 1.517022, Accuracy 0.437500\n","Batch 19420, Loss 1.520772, Accuracy 0.281250\n","Batch 19421, Loss 1.618446, Accuracy 0.281250\n","Batch 19422, Loss 1.529423, Accuracy 0.312500\n","Batch 19423, Loss 1.793632, Accuracy 0.250000\n","Batch 19424, Loss 1.501500, Accuracy 0.312500\n","Batch 19425, Loss 1.453820, Accuracy 0.500000\n","Batch 19426, Loss 1.395077, Accuracy 0.468750\n","Batch 19427, Loss 1.420029, Accuracy 0.468750\n","Batch 19428, Loss 1.505501, Accuracy 0.406250\n","Batch 19429, Loss 1.320578, Accuracy 0.593750\n","Batch 19430, Loss 1.084433, Accuracy 0.562500\n","Batch 19431, Loss 1.373879, Accuracy 0.500000\n","Batch 19432, Loss 1.140443, Accuracy 0.750000\n","Batch 19433, Loss 1.803055, Accuracy 0.468750\n","Batch 19434, Loss 1.990449, Accuracy 0.375000\n","Batch 19435, Loss 1.316755, Accuracy 0.468750\n","Batch 19436, Loss 1.702888, Accuracy 0.500000\n","Batch 19437, Loss 1.877411, Accuracy 0.343750\n","Batch 19438, Loss 1.968917, Accuracy 0.218750\n","Batch 19439, Loss 1.581354, Accuracy 0.468750\n","Batch 19440, Loss 1.823194, Accuracy 0.312500\n","Batch 19441, Loss 1.632686, Accuracy 0.375000\n","Batch 19442, Loss 1.479887, Accuracy 0.500000\n","Batch 19443, Loss 1.596535, Accuracy 0.312500\n","Batch 19444, Loss 1.525012, Accuracy 0.343750\n","Batch 19445, Loss 1.481980, Accuracy 0.437500\n","Batch 19446, Loss 1.481233, Accuracy 0.312500\n","Batch 19447, Loss 1.885055, Accuracy 0.343750\n","Batch 19448, Loss 1.465516, Accuracy 0.343750\n","Batch 19449, Loss 1.339424, Accuracy 0.375000\n","Batch 19450, Loss 1.309788, Accuracy 0.281250\n","Batch 19451, Loss 1.460555, Accuracy 0.375000\n","Batch 19452, Loss 1.342990, Accuracy 0.625000\n","Batch 19453, Loss 1.541009, Accuracy 0.375000\n","Batch 19454, Loss 1.502688, Accuracy 0.531250\n","Batch 19455, Loss 1.433208, Accuracy 0.468750\n","Batch 19456, Loss 1.461028, Accuracy 0.437500\n","Batch 19457, Loss 1.793117, Accuracy 0.375000\n","Batch 19458, Loss 1.481871, Accuracy 0.562500\n","Batch 19459, Loss 1.825575, Accuracy 0.281250\n","Batch 19460, Loss 1.713004, Accuracy 0.406250\n","Batch 19461, Loss 1.389846, Accuracy 0.625000\n","Batch 19462, Loss 1.592964, Accuracy 0.406250\n","Batch 19463, Loss 1.693676, Accuracy 0.312500\n","Batch 19464, Loss 1.464347, Accuracy 0.500000\n","Batch 19465, Loss 1.688594, Accuracy 0.437500\n","Batch 19466, Loss 1.776714, Accuracy 0.312500\n","Batch 19467, Loss 1.503584, Accuracy 0.343750\n","Batch 19468, Loss 1.452179, Accuracy 0.343750\n","Batch 19469, Loss 1.542611, Accuracy 0.218750\n","Batch 19470, Loss 1.376354, Accuracy 0.312500\n","Batch 19471, Loss 1.282579, Accuracy 0.500000\n","Batch 19472, Loss 1.083274, Accuracy 0.625000\n","Batch 19473, Loss 1.444650, Accuracy 0.531250\n","Batch 19474, Loss 1.562882, Accuracy 0.468750\n","Batch 19475, Loss 1.175117, Accuracy 0.500000\n","Batch 19476, Loss 1.174046, Accuracy 0.593750\n","Batch 19477, Loss 2.045118, Accuracy 0.468750\n","Batch 19478, Loss 1.309505, Accuracy 0.500000\n","Batch 19479, Loss 1.483838, Accuracy 0.562500\n","Batch 19480, Loss 1.700322, Accuracy 0.375000\n","Batch 19481, Loss 2.024882, Accuracy 0.437500\n","Batch 19482, Loss 1.644236, Accuracy 0.468750\n","Batch 19483, Loss 1.735283, Accuracy 0.468750\n","Batch 19484, Loss 1.592864, Accuracy 0.406250\n","Batch 19485, Loss 1.441651, Accuracy 0.500000\n","Batch 19486, Loss 1.604409, Accuracy 0.406250\n","Batch 19487, Loss 1.828395, Accuracy 0.281250\n","Batch 19488, Loss 1.554196, Accuracy 0.406250\n","Batch 19489, Loss 1.683722, Accuracy 0.468750\n","Batch 19490, Loss 1.702803, Accuracy 0.406250\n","Batch 19491, Loss 1.952265, Accuracy 0.187500\n","Batch 19492, Loss 1.595310, Accuracy 0.218750\n","Batch 19493, Loss 1.436503, Accuracy 0.281250\n","Batch 19494, Loss 1.389118, Accuracy 0.343750\n","Batch 19495, Loss 1.491066, Accuracy 0.312500\n","Batch 19496, Loss 1.423129, Accuracy 0.187500\n","Batch 19497, Loss 1.395100, Accuracy 0.312500\n","Batch 19498, Loss 1.329872, Accuracy 0.687500\n","Batch 19499, Loss 1.375384, Accuracy 0.531250\n","Batch 19500, Loss 1.422030, Accuracy 0.437500\n","Batch 19501, Loss 1.458088, Accuracy 0.312500\n","Batch 19502, Loss 1.577788, Accuracy 0.468750\n","Batch 19503, Loss 1.704483, Accuracy 0.437500\n","Batch 19504, Loss 1.754247, Accuracy 0.531250\n","Batch 19505, Loss 1.566760, Accuracy 0.406250\n","Batch 19506, Loss 1.826833, Accuracy 0.437500\n","Batch 19507, Loss 1.645082, Accuracy 0.343750\n","Batch 19508, Loss 2.040865, Accuracy 0.250000\n","Batch 19509, Loss 1.703269, Accuracy 0.437500\n","Batch 19510, Loss 1.805717, Accuracy 0.218750\n","Batch 19511, Loss 1.645151, Accuracy 0.562500\n","Batch 19512, Loss 1.603811, Accuracy 0.437500\n","Batch 19513, Loss 1.644553, Accuracy 0.437500\n","Batch 19514, Loss 1.597685, Accuracy 0.437500\n","Batch 19515, Loss 1.677962, Accuracy 0.343750\n","Batch 19516, Loss 1.472062, Accuracy 0.531250\n","Batch 19517, Loss 1.353518, Accuracy 0.468750\n","Batch 19518, Loss 1.840966, Accuracy 0.281250\n","Batch 19519, Loss 1.465536, Accuracy 0.312500\n","Batch 19520, Loss 1.563709, Accuracy 0.281250\n","Batch 19521, Loss 1.688837, Accuracy 0.125000\n","Batch 19522, Loss 1.280778, Accuracy 0.343750\n","Batch 19523, Loss 1.321808, Accuracy 0.281250\n","Batch 19524, Loss 1.416919, Accuracy 0.250000\n","Batch 19525, Loss 1.533967, Accuracy 0.250000\n","Batch 19526, Loss 1.185037, Accuracy 0.218750\n","Batch 19527, Loss 1.280775, Accuracy 0.312500\n","Batch 19528, Loss 1.187275, Accuracy 0.437500\n","Batch 19529, Loss 1.400630, Accuracy 0.500000\n","Batch 19530, Loss 1.156842, Accuracy 0.562500\n","Batch 19531, Loss 1.357560, Accuracy 0.500000\n","Batch 19532, Loss 1.322882, Accuracy 0.500000\n","Batch 19533, Loss 1.133951, Accuracy 0.625000\n","Batch 19534, Loss 1.397670, Accuracy 0.593750\n","Batch 19535, Loss 1.339386, Accuracy 0.468750\n","Batch 19536, Loss 1.607250, Accuracy 0.437500\n","Batch 19537, Loss 1.220803, Accuracy 0.531250\n","Batch 19538, Loss 1.423540, Accuracy 0.468750\n","Batch 19539, Loss 1.233474, Accuracy 0.562500\n","Batch 19540, Loss 1.602459, Accuracy 0.406250\n","Batch 19541, Loss 1.536669, Accuracy 0.468750\n","Batch 19542, Loss 1.331163, Accuracy 0.437500\n","Batch 19543, Loss 1.547810, Accuracy 0.500000\n","Batch 19544, Loss 1.399715, Accuracy 0.406250\n","Batch 19545, Loss 1.336985, Accuracy 0.625000\n","Batch 19546, Loss 1.286936, Accuracy 0.500000\n","Batch 19547, Loss 1.515902, Accuracy 0.500000\n","Batch 19548, Loss 1.660838, Accuracy 0.437500\n","Batch 19549, Loss 1.550580, Accuracy 0.375000\n","Batch 19550, Loss 1.385239, Accuracy 0.500000\n","Batch 19551, Loss 1.297943, Accuracy 0.593750\n","Batch 19552, Loss 1.283714, Accuracy 0.687500\n","Batch 19553, Loss 1.523829, Accuracy 0.468750\n","Batch 19554, Loss 3.339324, Accuracy 0.125000\n","Batch 19555, Loss 4.282507, Accuracy 0.000000\n","Batch 19556, Loss 3.447453, Accuracy 0.000000\n","Batch 19557, Loss 2.615884, Accuracy 0.000000\n","Batch 19558, Loss 1.861076, Accuracy 0.000000\n","Batch 19559, Loss 1.500456, Accuracy 0.468750\n","Batch 19560, Loss 1.499296, Accuracy 0.343750\n","Batch 19561, Loss 1.553501, Accuracy 0.375000\n","Batch 19562, Loss 1.502936, Accuracy 0.312500\n","Batch 19563, Loss 1.343082, Accuracy 0.375000\n","Batch 19564, Loss 1.217300, Accuracy 0.375000\n","Batch 19565, Loss 1.130651, Accuracy 0.687500\n","Batch 19566, Loss 1.079330, Accuracy 0.468750\n","Batch 19567, Loss 1.041548, Accuracy 0.625000\n","Batch 19568, Loss 1.016548, Accuracy 0.593750\n","Batch 19569, Loss 1.010783, Accuracy 0.343750\n","Batch 19570, Loss 0.989491, Accuracy 0.406250\n","Batch 19571, Loss 0.973960, Accuracy 0.406250\n","Batch 19572, Loss 0.973796, Accuracy 0.281250\n","Batch 19573, Loss 1.000852, Accuracy 0.343750\n","Batch 19574, Loss 1.019577, Accuracy 0.500000\n","Batch 19575, Loss 1.112815, Accuracy 0.437500\n","Batch 19576, Loss 1.022418, Accuracy 0.281250\n","Batch 19577, Loss 1.202236, Accuracy 0.343750\n","Batch 19578, Loss 1.291357, Accuracy 0.343750\n","Batch 19579, Loss 1.182158, Accuracy 0.312500\n","Batch 19580, Loss 1.317186, Accuracy 0.312500\n","Batch 19581, Loss 1.539119, Accuracy 0.437500\n","Batch 19582, Loss 1.284826, Accuracy 0.468750\n","Batch 19583, Loss 1.414689, Accuracy 0.281250\n","Batch 19584, Loss 1.223863, Accuracy 0.406250\n","Batch 19585, Loss 1.368946, Accuracy 0.406250\n","Batch 19586, Loss 1.238026, Accuracy 0.437500\n","Batch 19587, Loss 1.253998, Accuracy 0.468750\n","Batch 19588, Loss 1.440957, Accuracy 0.250000\n","Batch 19589, Loss 1.350045, Accuracy 0.312500\n","Batch 19590, Loss 1.398172, Accuracy 0.250000\n","Batch 19591, Loss 1.395535, Accuracy 0.375000\n","Batch 19592, Loss 1.302140, Accuracy 0.406250\n","Batch 19593, Loss 1.347078, Accuracy 0.250000\n","Batch 19594, Loss 1.268400, Accuracy 0.343750\n","Batch 19595, Loss 1.310830, Accuracy 0.250000\n","Batch 19596, Loss 1.299666, Accuracy 0.218750\n","Batch 19597, Loss 1.352096, Accuracy 0.125000\n","Batch 19598, Loss 1.263600, Accuracy 0.562500\n","Batch 19599, Loss 1.235749, Accuracy 0.656250\n","Batch 19600, Loss 1.352867, Accuracy 0.468750\n","Batch except\n","Batch except\n","Batch except\n","=================================================\n","Test, Loss 6.882361, Accuracy 0.093750\n","=================================================\n","Batch 19601, Loss 1.211053, Accuracy 0.593750\n","Batch 19602, Loss 1.288250, Accuracy 0.500000\n","Batch 19603, Loss 1.205341, Accuracy 0.562500\n","Batch 19604, Loss 1.244313, Accuracy 0.562500\n","Batch 19605, Loss 1.519503, Accuracy 0.375000\n","Batch 19606, Loss 1.537768, Accuracy 0.375000\n","Batch 19607, Loss 1.641152, Accuracy 0.312500\n","Batch 19608, Loss 1.646195, Accuracy 0.343750\n","Batch 19609, Loss 1.851378, Accuracy 0.187500\n","Batch 19610, Loss 1.824784, Accuracy 0.156250\n","Batch 19611, Loss 1.403928, Accuracy 0.437500\n","Batch 19612, Loss 1.613913, Accuracy 0.312500\n","Batch 19613, Loss 1.463585, Accuracy 0.468750\n","Batch 19614, Loss 1.695823, Accuracy 0.156250\n","Batch 19615, Loss 1.589994, Accuracy 0.312500\n","Batch 19616, Loss 1.512565, Accuracy 0.312500\n","Batch 19617, Loss 1.295274, Accuracy 0.500000\n","Batch 19618, Loss 1.487399, Accuracy 0.218750\n","Batch 19619, Loss 1.367661, Accuracy 0.312500\n","Batch 19620, Loss 1.372814, Accuracy 0.156250\n","Batch 19621, Loss 1.188784, Accuracy 0.625000\n","Batch 19622, Loss 1.232687, Accuracy 0.562500\n","Batch 19623, Loss 1.444448, Accuracy 0.468750\n","Batch 19624, Loss 1.187414, Accuracy 0.531250\n","Batch 19625, Loss 1.329192, Accuracy 0.500000\n","Batch 19626, Loss 1.139438, Accuracy 0.468750\n","Batch 19627, Loss 1.743028, Accuracy 0.312500\n","Batch 19628, Loss 1.363695, Accuracy 0.562500\n","Batch 19629, Loss 1.551275, Accuracy 0.468750\n","Batch 19630, Loss 1.242202, Accuracy 0.562500\n","Batch 19631, Loss 1.776107, Accuracy 0.343750\n","Batch 19632, Loss 1.395180, Accuracy 0.500000\n","Batch 19633, Loss 1.548906, Accuracy 0.468750\n","Batch 19634, Loss 1.735100, Accuracy 0.281250\n","Batch 19635, Loss 1.757888, Accuracy 0.406250\n","Batch 19636, Loss 1.820056, Accuracy 0.250000\n","Batch 19637, Loss 1.602501, Accuracy 0.343750\n","Batch 19638, Loss 1.646959, Accuracy 0.312500\n","Batch 19639, Loss 1.586027, Accuracy 0.250000\n","Batch 19640, Loss 1.619363, Accuracy 0.218750\n","Batch 19641, Loss 1.294195, Accuracy 0.437500\n","Batch 19642, Loss 1.552028, Accuracy 0.281250\n","Batch 19643, Loss 1.491090, Accuracy 0.218750\n","Batch 19644, Loss 1.569532, Accuracy 0.312500\n","Batch 19645, Loss 1.390420, Accuracy 0.218750\n","Batch 19646, Loss 1.510741, Accuracy 0.218750\n","Batch 19647, Loss 1.287242, Accuracy 0.250000\n","Batch 19648, Loss 1.421387, Accuracy 0.593750\n","Batch 19649, Loss 1.570595, Accuracy 0.406250\n","Batch 19650, Loss 1.321294, Accuracy 0.500000\n","Batch 19651, Loss 1.889141, Accuracy 0.343750\n","Batch 19652, Loss 1.520684, Accuracy 0.437500\n","Batch 19653, Loss 1.440689, Accuracy 0.375000\n","Batch 19654, Loss 1.351984, Accuracy 0.468750\n","Batch 19655, Loss 1.758843, Accuracy 0.187500\n","Batch 19656, Loss 1.784931, Accuracy 0.250000\n","Batch 19657, Loss 1.558280, Accuracy 0.500000\n","Batch 19658, Loss 1.436971, Accuracy 0.437500\n","Batch 19659, Loss 1.422657, Accuracy 0.312500\n","Batch 19660, Loss 1.504424, Accuracy 0.281250\n","Batch 19661, Loss 1.491028, Accuracy 0.343750\n","Batch 19662, Loss 1.511869, Accuracy 0.187500\n","Batch 19663, Loss 1.632872, Accuracy 0.375000\n","Batch 19664, Loss 1.400836, Accuracy 0.468750\n","Batch 19665, Loss 1.548873, Accuracy 0.406250\n","Batch 19666, Loss 1.251019, Accuracy 0.593750\n","Batch 19667, Loss 1.051692, Accuracy 0.562500\n","Batch 19668, Loss 1.444972, Accuracy 0.500000\n","Batch 19669, Loss 1.397551, Accuracy 0.500000\n","Batch 19670, Loss 1.127705, Accuracy 0.500000\n","Batch 19671, Loss 1.597306, Accuracy 0.437500\n","Batch 19672, Loss 1.491529, Accuracy 0.531250\n","Batch 19673, Loss 1.769699, Accuracy 0.531250\n","Batch 19674, Loss 1.792093, Accuracy 0.437500\n","Batch 19675, Loss 1.868652, Accuracy 0.375000\n","Batch 19676, Loss 1.593192, Accuracy 0.500000\n","Batch 19677, Loss 1.688261, Accuracy 0.406250\n","Batch 19678, Loss 2.274674, Accuracy 0.250000\n","Batch 19679, Loss 1.938279, Accuracy 0.343750\n","Batch 19680, Loss 1.805151, Accuracy 0.343750\n","Batch 19681, Loss 1.974755, Accuracy 0.218750\n","Batch 19682, Loss 1.822322, Accuracy 0.281250\n","Batch 19683, Loss 1.805212, Accuracy 0.250000\n","Batch 19684, Loss 1.577907, Accuracy 0.250000\n","Batch 19685, Loss 1.557389, Accuracy 0.343750\n","Batch 19686, Loss 1.356629, Accuracy 0.375000\n","Batch 19687, Loss 1.326715, Accuracy 0.375000\n","Batch 19688, Loss 1.089646, Accuracy 0.593750\n","Batch 19689, Loss 1.209962, Accuracy 0.593750\n","Batch 19690, Loss 1.380924, Accuracy 0.500000\n","Batch 19691, Loss 1.518904, Accuracy 0.500000\n","Batch 19692, Loss 1.490495, Accuracy 0.468750\n","Batch 19693, Loss 1.313194, Accuracy 0.562500\n","Batch 19694, Loss 1.805447, Accuracy 0.437500\n","Batch 19695, Loss 2.038678, Accuracy 0.437500\n","Batch 19696, Loss 1.797786, Accuracy 0.468750\n","Batch 19697, Loss 1.439951, Accuracy 0.531250\n","Batch 19698, Loss 1.869138, Accuracy 0.281250\n","Batch 19699, Loss 1.860984, Accuracy 0.343750\n","Batch 19700, Loss 1.620696, Accuracy 0.437500\n","Batch 19701, Loss 1.751752, Accuracy 0.343750\n","Batch 19702, Loss 1.728136, Accuracy 0.281250\n","Batch 19703, Loss 1.636172, Accuracy 0.343750\n","Batch 19704, Loss 1.645814, Accuracy 0.406250\n","Batch 19705, Loss 1.345589, Accuracy 0.437500\n","Batch 19706, Loss 1.592658, Accuracy 0.406250\n","Batch 19707, Loss 1.470314, Accuracy 0.437500\n","Batch 19708, Loss 1.292553, Accuracy 0.468750\n","Batch 19709, Loss 1.454238, Accuracy 0.406250\n","Batch 19710, Loss 1.189927, Accuracy 0.625000\n","Batch 19711, Loss 1.325176, Accuracy 0.562500\n","Batch 19712, Loss 1.022593, Accuracy 0.593750\n","Batch 19713, Loss 1.584110, Accuracy 0.437500\n","Batch 19714, Loss 1.123907, Accuracy 0.562500\n","Batch 19715, Loss 1.415226, Accuracy 0.531250\n","Batch 19716, Loss 1.641329, Accuracy 0.500000\n","Batch 19717, Loss 1.735457, Accuracy 0.406250\n","Batch 19718, Loss 1.667128, Accuracy 0.687500\n","Batch 19719, Loss 2.612208, Accuracy 0.468750\n","Batch 19720, Loss 1.817451, Accuracy 0.437500\n","Batch 19721, Loss 1.926844, Accuracy 0.437500\n","Batch 19722, Loss 2.004999, Accuracy 0.343750\n","Batch 19723, Loss 1.602610, Accuracy 0.468750\n","Batch 19724, Loss 1.823982, Accuracy 0.406250\n","Batch 19725, Loss 1.731105, Accuracy 0.343750\n","Batch 19726, Loss 1.661701, Accuracy 0.343750\n","Batch 19727, Loss 1.729323, Accuracy 0.312500\n","Batch 19728, Loss 1.617647, Accuracy 0.468750\n","Batch 19729, Loss 1.757067, Accuracy 0.343750\n","Batch 19730, Loss 1.748695, Accuracy 0.250000\n","Batch 19731, Loss 1.426748, Accuracy 0.406250\n","Batch 19732, Loss 1.719976, Accuracy 0.406250\n","Batch 19733, Loss 1.595062, Accuracy 0.312500\n","Batch 19734, Loss 1.417197, Accuracy 0.531250\n","Batch 19735, Loss 1.707372, Accuracy 0.375000\n","Batch 19736, Loss 1.545386, Accuracy 0.375000\n","Batch 19737, Loss 1.481266, Accuracy 0.437500\n","Batch 19738, Loss 1.072226, Accuracy 0.750000\n","Batch 19739, Loss 1.421672, Accuracy 0.500000\n","Batch 19740, Loss 1.387174, Accuracy 0.468750\n","Batch 19741, Loss 1.512166, Accuracy 0.593750\n","Batch 19742, Loss 2.173766, Accuracy 0.343750\n","Batch 19743, Loss 1.752024, Accuracy 0.468750\n","Batch 19744, Loss 1.559739, Accuracy 0.437500\n","Batch 19745, Loss 1.892127, Accuracy 0.437500\n","Batch 19746, Loss 1.529136, Accuracy 0.562500\n","Batch 19747, Loss 1.713784, Accuracy 0.343750\n","Batch 19748, Loss 2.044614, Accuracy 0.312500\n","Batch 19749, Loss 1.656642, Accuracy 0.375000\n","Batch 19750, Loss 1.730675, Accuracy 0.406250\n","Batch 19751, Loss 1.585823, Accuracy 0.500000\n","Batch 19752, Loss 1.626082, Accuracy 0.406250\n","Batch 19753, Loss 1.546110, Accuracy 0.343750\n","Batch 19754, Loss 1.612101, Accuracy 0.312500\n","Batch 19755, Loss 1.563246, Accuracy 0.281250\n","Batch 19756, Loss 1.454407, Accuracy 0.406250\n","Batch 19757, Loss 1.583795, Accuracy 0.250000\n","Batch 19758, Loss 1.533151, Accuracy 0.281250\n","Batch 19759, Loss 1.535803, Accuracy 0.125000\n","Batch 19760, Loss 1.472210, Accuracy 0.218750\n","Batch 19761, Loss 1.493536, Accuracy 0.531250\n","Batch 19762, Loss 1.429362, Accuracy 0.500000\n","Batch 19763, Loss 1.358613, Accuracy 0.562500\n","Batch 19764, Loss 1.210756, Accuracy 0.593750\n","Batch 19765, Loss 1.550474, Accuracy 0.437500\n","Batch 19766, Loss 1.365576, Accuracy 0.437500\n","Batch 19767, Loss 1.337572, Accuracy 0.500000\n","Batch 19768, Loss 1.887283, Accuracy 0.375000\n","Batch 19769, Loss 1.464921, Accuracy 0.625000\n","Batch 19770, Loss 1.443756, Accuracy 0.500000\n","Batch 19771, Loss 1.448721, Accuracy 0.343750\n","Batch 19772, Loss 1.472043, Accuracy 0.437500\n","Batch 19773, Loss 1.253309, Accuracy 0.500000\n","Batch 19774, Loss 1.277327, Accuracy 0.500000\n","Batch 19775, Loss 1.409835, Accuracy 0.343750\n","Batch 19776, Loss 1.231691, Accuracy 0.531250\n","Batch 19777, Loss 1.289665, Accuracy 0.562500\n","Batch 19778, Loss 1.164827, Accuracy 0.593750\n","Batch 19779, Loss 1.409706, Accuracy 0.500000\n","Batch 19780, Loss 1.174351, Accuracy 0.625000\n","Batch 19781, Loss 1.508195, Accuracy 0.437500\n","Batch 19782, Loss 1.380417, Accuracy 0.531250\n","Batch 19783, Loss 1.697330, Accuracy 0.437500\n","Batch 19784, Loss 1.377472, Accuracy 0.375000\n","Batch 19785, Loss 1.455356, Accuracy 0.500000\n","Batch 19786, Loss 1.420324, Accuracy 0.468750\n","Batch 19787, Loss 1.668679, Accuracy 0.406250\n","Batch 19788, Loss 1.311110, Accuracy 0.437500\n","Batch 19789, Loss 1.139182, Accuracy 0.562500\n","Batch 19790, Loss 1.343443, Accuracy 0.531250\n","Batch 19791, Loss 1.595281, Accuracy 0.437500\n","Batch 19792, Loss 1.610245, Accuracy 0.593750\n","Batch 19793, Loss 4.700282, Accuracy 0.000000\n","Batch 19794, Loss 4.218298, Accuracy 0.000000\n","Batch 19795, Loss 3.445019, Accuracy 0.000000\n","Batch 19796, Loss 2.687893, Accuracy 0.000000\n","Batch 19797, Loss 1.979818, Accuracy 0.000000\n","Batch 19798, Loss 1.336365, Accuracy 0.656250\n","Batch 19799, Loss 1.129137, Accuracy 0.406250\n","Batch 19800, Loss 1.085746, Accuracy 0.312500\n","Batch except\n","Batch except\n","Batch except\n","=================================================\n","Test, Loss 3.615035, Accuracy 0.083333\n","=================================================\n","Batch 19801, Loss 1.074618, Accuracy 0.562500\n","Batch 19802, Loss 1.068995, Accuracy 0.500000\n","Batch 19803, Loss 1.059278, Accuracy 0.593750\n","Batch 19804, Loss 1.048016, Accuracy 0.656250\n","Batch 19805, Loss 1.042235, Accuracy 0.437500\n","Batch 19806, Loss 1.029996, Accuracy 0.531250\n","Batch 19807, Loss 1.017903, Accuracy 0.406250\n","Batch 19808, Loss 1.004192, Accuracy 0.593750\n","Batch 19809, Loss 0.991279, Accuracy 0.531250\n","Batch 19810, Loss 0.981675, Accuracy 0.343750\n","Batch 19811, Loss 1.005117, Accuracy 0.437500\n","Batch 19812, Loss 1.074777, Accuracy 0.468750\n","Batch 19813, Loss 0.988961, Accuracy 0.375000\n","Batch 19814, Loss 1.150207, Accuracy 0.468750\n","Batch 19815, Loss 1.146486, Accuracy 0.375000\n","Batch 19816, Loss 1.361886, Accuracy 0.312500\n","Batch 19817, Loss 1.349743, Accuracy 0.375000\n","Batch 19818, Loss 1.336592, Accuracy 0.343750\n","Batch 19819, Loss 1.232370, Accuracy 0.531250\n","Batch 19820, Loss 1.429310, Accuracy 0.375000\n","Batch 19821, Loss 1.257796, Accuracy 0.343750\n","Batch 19822, Loss 1.410045, Accuracy 0.187500\n","Batch 19823, Loss 1.267410, Accuracy 0.406250\n","Batch 19824, Loss 1.369508, Accuracy 0.281250\n","Batch 19825, Loss 1.363973, Accuracy 0.406250\n","Batch 19826, Loss 1.184383, Accuracy 0.375000\n","Batch 19827, Loss 1.319259, Accuracy 0.406250\n","Batch 19828, Loss 1.566573, Accuracy 0.125000\n","Batch 19829, Loss 1.362000, Accuracy 0.281250\n","Batch 19830, Loss 1.240986, Accuracy 0.343750\n","Batch 19831, Loss 1.240705, Accuracy 0.281250\n","Batch 19832, Loss 1.209201, Accuracy 0.312500\n","Batch 19833, Loss 1.146945, Accuracy 0.343750\n","Batch 19834, Loss 1.128210, Accuracy 0.562500\n","Batch 19835, Loss 1.140092, Accuracy 0.500000\n","Batch 19836, Loss 1.119579, Accuracy 0.593750\n","Batch 19837, Loss 0.987778, Accuracy 0.656250\n","Batch 19838, Loss 1.008634, Accuracy 0.656250\n","Batch 19839, Loss 1.362379, Accuracy 0.500000\n","Batch 19840, Loss 1.537159, Accuracy 0.406250\n","Batch 19841, Loss 1.586800, Accuracy 0.375000\n","Batch 19842, Loss 1.431802, Accuracy 0.343750\n","Batch 19843, Loss 1.619028, Accuracy 0.406250\n","Batch 19844, Loss 1.401554, Accuracy 0.468750\n","Batch 19845, Loss 1.390107, Accuracy 0.500000\n","Batch 19846, Loss 1.656787, Accuracy 0.406250\n","Batch 19847, Loss 1.516515, Accuracy 0.468750\n","Batch 19848, Loss 1.531171, Accuracy 0.406250\n","Batch 19849, Loss 1.759975, Accuracy 0.312500\n","Batch 19850, Loss 1.515890, Accuracy 0.437500\n","Batch 19851, Loss 1.667128, Accuracy 0.187500\n","Batch 19852, Loss 1.364090, Accuracy 0.437500\n","Batch 19853, Loss 1.358130, Accuracy 0.375000\n","Batch 19854, Loss 1.352658, Accuracy 0.375000\n","Batch 19855, Loss 1.430001, Accuracy 0.250000\n","Batch 19856, Loss 1.342031, Accuracy 0.468750\n","Batch 19857, Loss 1.192830, Accuracy 0.468750\n","Batch 19858, Loss 1.397507, Accuracy 0.406250\n","Batch 19859, Loss 1.165249, Accuracy 0.531250\n","Batch 19860, Loss 1.307566, Accuracy 0.468750\n","Batch 19861, Loss 1.395003, Accuracy 0.531250\n","Batch 19862, Loss 1.195666, Accuracy 0.562500\n","Batch 19863, Loss 1.227793, Accuracy 0.468750\n","Batch 19864, Loss 1.369576, Accuracy 0.406250\n","Batch 19865, Loss 1.339915, Accuracy 0.468750\n","Batch 19866, Loss 1.323521, Accuracy 0.562500\n","Batch 19867, Loss 1.585647, Accuracy 0.406250\n","Batch 19868, Loss 1.611676, Accuracy 0.500000\n","Batch 19869, Loss 1.779919, Accuracy 0.406250\n","Batch 19870, Loss 1.476815, Accuracy 0.468750\n","Batch 19871, Loss 1.752620, Accuracy 0.375000\n","Batch 19872, Loss 1.530344, Accuracy 0.500000\n","Batch 19873, Loss 1.781025, Accuracy 0.468750\n","Batch 19874, Loss 1.832715, Accuracy 0.343750\n","Batch 19875, Loss 1.764333, Accuracy 0.218750\n","Batch 19876, Loss 1.475401, Accuracy 0.468750\n","Batch 19877, Loss 1.555474, Accuracy 0.406250\n","Batch 19878, Loss 1.492879, Accuracy 0.406250\n","Batch 19879, Loss 1.483389, Accuracy 0.375000\n","Batch 19880, Loss 1.577097, Accuracy 0.250000\n","Batch 19881, Loss 1.325434, Accuracy 0.406250\n","Batch 19882, Loss 1.401935, Accuracy 0.406250\n","Batch 19883, Loss 1.433800, Accuracy 0.218750\n","Batch 19884, Loss 1.377554, Accuracy 0.187500\n","Batch 19885, Loss 1.416690, Accuracy 0.281250\n","Batch 19886, Loss 1.749521, Accuracy 0.437500\n","Batch 19887, Loss 1.877016, Accuracy 0.531250\n","Batch 19888, Loss 1.280736, Accuracy 0.625000\n","Batch 19889, Loss 1.606622, Accuracy 0.468750\n","Batch 19890, Loss 1.668755, Accuracy 0.312500\n","Batch 19891, Loss 2.006920, Accuracy 0.250000\n","Batch 19892, Loss 1.615486, Accuracy 0.406250\n","Batch 19893, Loss 1.535515, Accuracy 0.406250\n","Batch 19894, Loss 1.426057, Accuracy 0.531250\n","Batch 19895, Loss 1.716955, Accuracy 0.281250\n","Batch 19896, Loss 1.674524, Accuracy 0.218750\n","Batch 19897, Loss 1.613536, Accuracy 0.343750\n","Batch 19898, Loss 1.563287, Accuracy 0.406250\n","Batch 19899, Loss 1.573635, Accuracy 0.406250\n","Batch 19900, Loss 1.564792, Accuracy 0.375000\n","Batch 19901, Loss 1.337815, Accuracy 0.437500\n","Batch 19902, Loss 1.154634, Accuracy 0.656250\n","Batch 19903, Loss 1.443661, Accuracy 0.375000\n","Batch 19904, Loss 1.260718, Accuracy 0.468750\n","Batch 19905, Loss 1.387389, Accuracy 0.468750\n","Batch 19906, Loss 1.352458, Accuracy 0.468750\n","Batch 19907, Loss 1.236169, Accuracy 0.562500\n","Batch 19908, Loss 1.530342, Accuracy 0.593750\n","Batch 19909, Loss 1.133778, Accuracy 0.625000\n","Batch 19910, Loss 1.426546, Accuracy 0.468750\n","Batch 19911, Loss 1.575408, Accuracy 0.437500\n","Batch 19912, Loss 1.923871, Accuracy 0.437500\n","Batch 19913, Loss 1.819657, Accuracy 0.406250\n","Batch 19914, Loss 1.779459, Accuracy 0.250000\n","Batch 19915, Loss 1.861566, Accuracy 0.343750\n","Batch 19916, Loss 1.622479, Accuracy 0.437500\n","Batch 19917, Loss 1.744357, Accuracy 0.375000\n","Batch 19918, Loss 1.805120, Accuracy 0.312500\n","Batch 19919, Loss 1.726105, Accuracy 0.281250\n","Batch 19920, Loss 1.636564, Accuracy 0.343750\n","Batch 19921, Loss 1.603532, Accuracy 0.218750\n","Batch 19922, Loss 1.244841, Accuracy 0.375000\n","Batch 19923, Loss 1.207483, Accuracy 0.562500\n","Batch 19924, Loss 1.361909, Accuracy 0.468750\n","Batch 19925, Loss 1.751692, Accuracy 0.375000\n","Batch 19926, Loss 1.308953, Accuracy 0.531250\n","Batch 19927, Loss 1.396819, Accuracy 0.437500\n","Batch 19928, Loss 1.593229, Accuracy 0.343750\n","Batch 19929, Loss 1.219418, Accuracy 0.593750\n","Batch 19930, Loss 1.460772, Accuracy 0.406250\n","Batch 19931, Loss 1.641594, Accuracy 0.500000\n","Batch 19932, Loss 1.553167, Accuracy 0.500000\n","Batch 19933, Loss 1.612999, Accuracy 0.437500\n","Batch 19934, Loss 1.812931, Accuracy 0.375000\n","Batch 19935, Loss 1.903084, Accuracy 0.375000\n","Batch 19936, Loss 1.683386, Accuracy 0.281250\n","Batch 19937, Loss 1.952745, Accuracy 0.187500\n","Batch 19938, Loss 1.928344, Accuracy 0.187500\n","Batch 19939, Loss 1.891789, Accuracy 0.218750\n","Batch 19940, Loss 1.514574, Accuracy 0.531250\n","Batch 19941, Loss 1.428109, Accuracy 0.437500\n","Batch 19942, Loss 1.269943, Accuracy 0.468750\n","Batch 19943, Loss 1.740780, Accuracy 0.343750\n","Batch 19944, Loss 1.477616, Accuracy 0.406250\n","Batch 19945, Loss 1.517399, Accuracy 0.343750\n","Batch 19946, Loss 1.595944, Accuracy 0.281250\n","Batch 19947, Loss 1.605415, Accuracy 0.250000\n","Batch 19948, Loss 1.696631, Accuracy 0.187500\n","Batch 19949, Loss 1.644567, Accuracy 0.312500\n","Batch 19950, Loss 1.251851, Accuracy 0.562500\n","Batch 19951, Loss 1.554147, Accuracy 0.468750\n","Batch 19952, Loss 1.674521, Accuracy 0.312500\n","Batch 19953, Loss 1.488623, Accuracy 0.500000\n","Batch 19954, Loss 1.333943, Accuracy 0.406250\n","Batch 19955, Loss 1.380779, Accuracy 0.531250\n","Batch 19956, Loss 1.482736, Accuracy 0.562500\n","Batch 19957, Loss 1.487368, Accuracy 0.562500\n","Batch 19958, Loss 1.539068, Accuracy 0.500000\n","Batch 19959, Loss 1.781214, Accuracy 0.343750\n","Batch 19960, Loss 1.686577, Accuracy 0.437500\n","Batch 19961, Loss 1.675524, Accuracy 0.375000\n","Batch 19962, Loss 1.501871, Accuracy 0.562500\n","Batch 19963, Loss 1.454033, Accuracy 0.468750\n","Batch 19964, Loss 1.513953, Accuracy 0.468750\n","Batch 19965, Loss 1.514618, Accuracy 0.437500\n","Batch 19966, Loss 1.657809, Accuracy 0.406250\n","Batch 19967, Loss 1.829660, Accuracy 0.375000\n","Batch 19968, Loss 1.398231, Accuracy 0.343750\n","Batch 19969, Loss 1.481456, Accuracy 0.281250\n","Batch 19970, Loss 2.142187, Accuracy 0.218750\n","Batch 19971, Loss 1.446445, Accuracy 0.312500\n","Batch 19972, Loss 1.788179, Accuracy 0.156250\n","Batch 19973, Loss 1.535123, Accuracy 0.125000\n","Batch 19974, Loss 1.464479, Accuracy 0.281250\n","Batch 19975, Loss 1.550791, Accuracy 0.406250\n","Batch 19976, Loss 1.314142, Accuracy 0.500000\n","Batch 19977, Loss 1.381612, Accuracy 0.437500\n","Batch 19978, Loss 1.366186, Accuracy 0.500000\n","Batch 19979, Loss 1.500366, Accuracy 0.500000\n","Batch 19980, Loss 1.321562, Accuracy 0.531250\n","Batch 19981, Loss 1.766210, Accuracy 0.437500\n","Batch 19982, Loss 1.454635, Accuracy 0.500000\n","Batch 19983, Loss 1.631930, Accuracy 0.437500\n","Batch 19984, Loss 1.442466, Accuracy 0.531250\n","Batch 19985, Loss 1.651103, Accuracy 0.437500\n","Batch 19986, Loss 1.443134, Accuracy 0.468750\n","Batch 19987, Loss 1.570831, Accuracy 0.406250\n","Batch 19988, Loss 1.583900, Accuracy 0.281250\n","Batch 19989, Loss 1.471365, Accuracy 0.375000\n","Batch 19990, Loss 1.503148, Accuracy 0.406250\n","Batch 19991, Loss 1.520491, Accuracy 0.281250\n","Batch 19992, Loss 1.433351, Accuracy 0.343750\n","Batch 19993, Loss 1.784426, Accuracy 0.312500\n","Batch 19994, Loss 1.288275, Accuracy 0.218750\n","Batch 19995, Loss 1.696726, Accuracy 0.281250\n","Batch 19996, Loss 1.309911, Accuracy 0.406250\n","Batch 19997, Loss 1.460323, Accuracy 0.437500\n","Batch 19998, Loss 1.259273, Accuracy 0.406250\n","Batch 19999, Loss 1.216873, Accuracy 0.531250\n","Batch 20000, Loss 1.504187, Accuracy 0.468750\n","Batch except\n","Batch except\n","Batch except\n","=================================================\n","Test, Loss 3.302533, Accuracy 0.166667\n","=================================================\n","Batch 20001, Loss 1.349649, Accuracy 0.500000\n","Batch 20002, Loss 1.239145, Accuracy 0.562500\n","Batch 20003, Loss 1.367885, Accuracy 0.500000\n","Batch 20004, Loss 1.375551, Accuracy 0.625000\n","Batch 20005, Loss 1.214993, Accuracy 0.625000\n","Batch 20006, Loss 1.319342, Accuracy 0.562500\n","Batch 20007, Loss 1.264062, Accuracy 0.625000\n","Batch 20008, Loss 1.458662, Accuracy 0.437500\n","Batch 20009, Loss 1.292519, Accuracy 0.437500\n","Batch 20010, Loss 1.608582, Accuracy 0.500000\n","Batch 20011, Loss 1.352067, Accuracy 0.531250\n","Batch 20012, Loss 1.253568, Accuracy 0.593750\n","Batch 20013, Loss 1.304740, Accuracy 0.500000\n","Batch 20014, Loss 1.765293, Accuracy 0.343750\n","Batch 20015, Loss 1.521755, Accuracy 0.500000\n","Batch 20016, Loss 1.305336, Accuracy 0.500000\n","Batch 20017, Loss 1.291762, Accuracy 0.562500\n","Batch 20018, Loss 1.552589, Accuracy 0.437500\n","Batch 20019, Loss 1.271087, Accuracy 0.531250\n","Batch 20020, Loss 1.311405, Accuracy 0.468750\n","Batch 20021, Loss 1.514278, Accuracy 0.593750\n","Batch 20022, Loss 1.709426, Accuracy 0.531250\n","Batch 20023, Loss 1.142987, Accuracy 0.562500\n","Batch 20024, Loss 1.208291, Accuracy 0.562500\n","Batch 20025, Loss 1.456594, Accuracy 0.468750\n","Batch 20026, Loss 1.244559, Accuracy 0.437500\n","Batch 20027, Loss 1.609630, Accuracy 0.406250\n","Batch 20028, Loss 1.020380, Accuracy 0.562500\n","Batch 20029, Loss 1.818645, Accuracy 0.375000\n","Batch 20030, Loss 1.387541, Accuracy 0.375000\n","Batch 20031, Loss 3.604012, Accuracy 0.125000\n","Batch 20032, Loss 3.592795, Accuracy 0.000000\n","Batch 20033, Loss 2.167086, Accuracy 0.000000\n","Batch 20034, Loss 1.923875, Accuracy 0.000000\n","Batch 20035, Loss 1.760666, Accuracy 0.468750\n","Batch 20036, Loss 1.657934, Accuracy 0.406250\n","Batch 20037, Loss 1.553717, Accuracy 0.562500\n","Batch 20038, Loss 1.473430, Accuracy 0.531250\n","Batch 20039, Loss 1.408438, Accuracy 0.437500\n","Batch 20040, Loss 1.348690, Accuracy 0.343750\n","Batch 20041, Loss 1.281731, Accuracy 0.531250\n","Batch 20042, Loss 1.235047, Accuracy 0.437500\n","Batch 20043, Loss 1.188304, Accuracy 0.593750\n","Batch 20044, Loss 1.151819, Accuracy 0.593750\n","Batch 20045, Loss 1.121187, Accuracy 0.437500\n","Batch 20046, Loss 1.092634, Accuracy 0.593750\n","Batch 20047, Loss 1.076698, Accuracy 0.250000\n","Batch 20048, Loss 1.048783, Accuracy 0.593750\n","Batch 20049, Loss 1.077672, Accuracy 0.343750\n","Batch 20050, Loss 1.063226, Accuracy 0.468750\n","Batch 20051, Loss 1.171583, Accuracy 0.437500\n","Batch 20052, Loss 1.129940, Accuracy 0.375000\n","Batch 20053, Loss 1.123526, Accuracy 0.343750\n","Batch 20054, Loss 1.238114, Accuracy 0.250000\n","Batch 20055, Loss 1.185141, Accuracy 0.375000\n","Batch 20056, Loss 1.176868, Accuracy 0.375000\n","Batch 20057, Loss 1.169782, Accuracy 0.187500\n","Batch 20058, Loss 1.160967, Accuracy 0.531250\n","Batch 20059, Loss 1.428340, Accuracy 0.343750\n","Batch 20060, Loss 1.257890, Accuracy 0.562500\n","Batch 20061, Loss 1.401452, Accuracy 0.375000\n","Batch 20062, Loss 1.429556, Accuracy 0.187500\n","Batch 20063, Loss 1.465119, Accuracy 0.218750\n","Batch 20064, Loss 1.391141, Accuracy 0.468750\n","Batch 20065, Loss 1.474248, Accuracy 0.250000\n","Batch 20066, Loss 1.349226, Accuracy 0.406250\n","Batch 20067, Loss 1.438211, Accuracy 0.125000\n","Batch 20068, Loss 1.320260, Accuracy 0.375000\n","Batch 20069, Loss 1.358366, Accuracy 0.281250\n","Batch 20070, Loss 1.353851, Accuracy 0.250000\n","Batch 20071, Loss 1.346821, Accuracy 0.343750\n","Batch 20072, Loss 1.302459, Accuracy 0.375000\n","Batch 20073, Loss 1.363868, Accuracy 0.250000\n","Batch 20074, Loss 1.358198, Accuracy 0.218750\n","Batch 20075, Loss 1.330554, Accuracy 0.156250\n","Batch 20076, Loss 1.284206, Accuracy 0.187500\n","Batch 20077, Loss 1.469692, Accuracy 0.125000\n","Batch 20078, Loss 1.345615, Accuracy 0.500000\n","Batch 20079, Loss 1.494196, Accuracy 0.343750\n","Batch 20080, Loss 1.477942, Accuracy 0.437500\n","Batch 20081, Loss 1.415457, Accuracy 0.468750\n","Batch 20082, Loss 1.340051, Accuracy 0.500000\n","Batch 20083, Loss 1.543842, Accuracy 0.437500\n","Batch 20084, Loss 1.562618, Accuracy 0.406250\n","Batch 20085, Loss 1.754310, Accuracy 0.312500\n","Batch 20086, Loss 1.516827, Accuracy 0.406250\n","Batch 20087, Loss 1.641854, Accuracy 0.343750\n","Batch 20088, Loss 1.470999, Accuracy 0.468750\n","Batch 20089, Loss 1.558647, Accuracy 0.375000\n","Batch 20090, Loss 1.601318, Accuracy 0.312500\n","Batch 20091, Loss 1.416854, Accuracy 0.437500\n","Batch 20092, Loss 1.271383, Accuracy 0.593750\n","Batch 20093, Loss 1.481302, Accuracy 0.281250\n","Batch 20094, Loss 1.561250, Accuracy 0.187500\n","Batch 20095, Loss 1.489775, Accuracy 0.125000\n","Batch 20096, Loss 1.438723, Accuracy 0.250000\n","Batch 20097, Loss 1.509279, Accuracy 0.406250\n","Batch 20098, Loss 1.408759, Accuracy 0.500000\n","Batch 20099, Loss 1.301350, Accuracy 0.500000\n","Batch 20100, Loss 1.205652, Accuracy 0.500000\n","Batch 20101, Loss 1.338323, Accuracy 0.593750\n","Batch 20102, Loss 1.264009, Accuracy 0.625000\n","Batch 20103, Loss 1.358565, Accuracy 0.500000\n","Batch 20104, Loss 1.326784, Accuracy 0.468750\n","Batch 20105, Loss 1.414551, Accuracy 0.437500\n","Batch 20106, Loss 1.478846, Accuracy 0.500000\n","Batch 20107, Loss 1.424610, Accuracy 0.500000\n","Batch 20108, Loss 1.736219, Accuracy 0.375000\n","Batch 20109, Loss 1.492808, Accuracy 0.500000\n","Batch 20110, Loss 1.461531, Accuracy 0.437500\n","Batch 20111, Loss 1.605538, Accuracy 0.375000\n","Batch 20112, Loss 1.634455, Accuracy 0.343750\n","Batch 20113, Loss 1.585335, Accuracy 0.343750\n","Batch 20114, Loss 1.388886, Accuracy 0.375000\n","Batch 20115, Loss 1.459581, Accuracy 0.406250\n","Batch 20116, Loss 1.428224, Accuracy 0.343750\n","Batch 20117, Loss 1.465085, Accuracy 0.250000\n","Batch 20118, Loss 1.270705, Accuracy 0.312500\n","Batch 20119, Loss 1.422641, Accuracy 0.250000\n","Batch 20120, Loss 1.520078, Accuracy 0.281250\n","Batch 20121, Loss 1.456907, Accuracy 0.312500\n","Batch 20122, Loss 1.514680, Accuracy 0.531250\n","Batch 20123, Loss 1.212365, Accuracy 0.500000\n","Batch 20124, Loss 1.443757, Accuracy 0.500000\n","Batch 20125, Loss 1.641457, Accuracy 0.312500\n","Batch 20126, Loss 1.429981, Accuracy 0.562500\n","Batch 20127, Loss 1.183906, Accuracy 0.593750\n","Batch 20128, Loss 1.549452, Accuracy 0.406250\n","Batch 20129, Loss 1.506636, Accuracy 0.468750\n","Batch 20130, Loss 2.200948, Accuracy 0.375000\n","Batch 20131, Loss 1.976228, Accuracy 0.312500\n","Batch 20132, Loss 1.695331, Accuracy 0.375000\n","Batch 20133, Loss 2.115800, Accuracy 0.281250\n","Batch 20134, Loss 1.409545, Accuracy 0.500000\n","Batch 20135, Loss 1.575188, Accuracy 0.437500\n","Batch 20136, Loss 1.484828, Accuracy 0.437500\n","Batch 20137, Loss 1.566738, Accuracy 0.281250\n","Batch 20138, Loss 1.591814, Accuracy 0.187500\n","Batch 20139, Loss 1.569013, Accuracy 0.312500\n","Batch 20140, Loss 1.335903, Accuracy 0.531250\n","Batch 20141, Loss 1.639962, Accuracy 0.343750\n","Batch 20142, Loss 1.517925, Accuracy 0.343750\n","Batch 20143, Loss 1.376714, Accuracy 0.437500\n","Batch 20144, Loss 1.292943, Accuracy 0.562500\n","Batch 20145, Loss 1.368359, Accuracy 0.468750\n","Batch 20146, Loss 1.080199, Accuracy 0.718750\n","Batch 20147, Loss 1.365602, Accuracy 0.531250\n","Batch 20148, Loss 1.643376, Accuracy 0.375000\n","Batch 20149, Loss 1.413182, Accuracy 0.500000\n","Batch 20150, Loss 1.808946, Accuracy 0.500000\n","Batch 20151, Loss 1.944549, Accuracy 0.406250\n","Batch 20152, Loss 1.761285, Accuracy 0.468750\n","Batch 20153, Loss 2.051512, Accuracy 0.406250\n","Batch 20154, Loss 2.002602, Accuracy 0.250000\n","Batch 20155, Loss 2.000635, Accuracy 0.343750\n","Batch 20156, Loss 1.800143, Accuracy 0.562500\n","Batch 20157, Loss 1.802222, Accuracy 0.437500\n","Batch 20158, Loss 1.724928, Accuracy 0.375000\n","Batch 20159, Loss 1.708860, Accuracy 0.406250\n","Batch 20160, Loss 1.662483, Accuracy 0.406250\n","Batch 20161, Loss 1.785517, Accuracy 0.375000\n","Batch 20162, Loss 1.674842, Accuracy 0.406250\n","Batch 20163, Loss 1.766307, Accuracy 0.312500\n","Batch 20164, Loss 1.628635, Accuracy 0.281250\n","Batch 20165, Loss 1.330352, Accuracy 0.468750\n","Batch 20166, Loss 1.517405, Accuracy 0.218750\n","Batch 20167, Loss 1.396235, Accuracy 0.281250\n","Batch 20168, Loss 1.352756, Accuracy 0.500000\n","Batch 20169, Loss 1.042894, Accuracy 0.687500\n","Batch 20170, Loss 1.156292, Accuracy 0.593750\n","Batch 20171, Loss 1.764645, Accuracy 0.531250\n","Batch 20172, Loss 1.908908, Accuracy 0.500000\n","Batch 20173, Loss 1.671618, Accuracy 0.468750\n","Batch 20174, Loss 1.749628, Accuracy 0.468750\n","Batch 20175, Loss 1.870467, Accuracy 0.375000\n","Batch 20176, Loss 1.715924, Accuracy 0.437500\n","Batch 20177, Loss 1.647922, Accuracy 0.500000\n","Batch 20178, Loss 1.932553, Accuracy 0.312500\n","Batch 20179, Loss 1.712814, Accuracy 0.312500\n","Batch 20180, Loss 1.554473, Accuracy 0.343750\n","Batch 20181, Loss 1.399734, Accuracy 0.375000\n","Batch 20182, Loss 1.634387, Accuracy 0.250000\n","Batch 20183, Loss 1.646187, Accuracy 0.218750\n","Batch 20184, Loss 1.686638, Accuracy 0.375000\n","Batch 20185, Loss 1.481202, Accuracy 0.406250\n","Batch 20186, Loss 1.199363, Accuracy 0.468750\n","Batch 20187, Loss 1.544336, Accuracy 0.468750\n","Batch 20188, Loss 1.186606, Accuracy 0.687500\n","Batch 20189, Loss 1.196434, Accuracy 0.625000\n","Batch 20190, Loss 1.203918, Accuracy 0.500000\n","Batch 20191, Loss 1.345738, Accuracy 0.531250\n","Batch 20192, Loss 1.103582, Accuracy 0.656250\n","Batch 20193, Loss 1.522863, Accuracy 0.562500\n","Batch 20194, Loss 1.962638, Accuracy 0.406250\n","Batch 20195, Loss 1.196200, Accuracy 0.562500\n","Batch 20196, Loss 2.215859, Accuracy 0.312500\n","Batch 20197, Loss 1.673972, Accuracy 0.468750\n","Batch 20198, Loss 1.543560, Accuracy 0.437500\n","Batch 20199, Loss 1.840492, Accuracy 0.468750\n","Batch 20200, Loss 1.748977, Accuracy 0.500000\n","Batch except\n","Batch except\n","Batch except\n","=================================================\n","Test, Loss 2.722032, Accuracy 0.083333\n","=================================================\n","Batch 20201, Loss 1.795931, Accuracy 0.437500\n","Batch 20202, Loss 1.609432, Accuracy 0.531250\n","Batch 20203, Loss 1.779794, Accuracy 0.250000\n","Batch 20204, Loss 1.712722, Accuracy 0.312500\n","Batch 20205, Loss 1.492390, Accuracy 0.437500\n","Batch 20206, Loss 1.592950, Accuracy 0.375000\n","Batch 20207, Loss 1.876449, Accuracy 0.125000\n","Batch 20208, Loss 1.876025, Accuracy 0.187500\n","Batch 20209, Loss 1.542483, Accuracy 0.218750\n","Batch 20210, Loss 1.572780, Accuracy 0.343750\n","Batch 20211, Loss 1.527196, Accuracy 0.343750\n","Batch 20212, Loss 1.148941, Accuracy 0.500000\n","Batch 20213, Loss 1.308279, Accuracy 0.593750\n","Batch 20214, Loss 1.307209, Accuracy 0.531250\n","Batch 20215, Loss 1.082520, Accuracy 0.562500\n","Batch 20216, Loss 1.761441, Accuracy 0.406250\n","Batch 20217, Loss 1.342654, Accuracy 0.562500\n","Batch 20218, Loss 1.138404, Accuracy 0.687500\n","Batch 20219, Loss 1.854471, Accuracy 0.375000\n","Batch 20220, Loss 1.337977, Accuracy 0.562500\n","Batch 20221, Loss 1.169871, Accuracy 0.656250\n","Batch 20222, Loss 1.494264, Accuracy 0.437500\n","Batch 20223, Loss 1.788074, Accuracy 0.406250\n","Batch 20224, Loss 1.453524, Accuracy 0.468750\n","Batch 20225, Loss 1.508919, Accuracy 0.375000\n","Batch 20226, Loss 1.470538, Accuracy 0.406250\n","Batch 20227, Loss 1.581986, Accuracy 0.437500\n","Batch 20228, Loss 1.401284, Accuracy 0.375000\n","Batch 20229, Loss 1.727794, Accuracy 0.281250\n","Batch 20230, Loss 1.434498, Accuracy 0.406250\n","Batch 20231, Loss 1.291087, Accuracy 0.437500\n","Batch 20232, Loss 1.320694, Accuracy 0.312500\n","Batch 20233, Loss 1.133287, Accuracy 0.500000\n","Batch 20234, Loss 1.385059, Accuracy 0.375000\n","Batch 20235, Loss 1.688246, Accuracy 0.343750\n","Batch 20236, Loss 1.302639, Accuracy 0.500000\n","Batch 20237, Loss 1.304489, Accuracy 0.531250\n","Batch 20238, Loss 1.348140, Accuracy 0.531250\n","Batch 20239, Loss 1.333766, Accuracy 0.531250\n","Batch 20240, Loss 1.513444, Accuracy 0.531250\n","Batch 20241, Loss 1.118333, Accuracy 0.593750\n","Batch 20242, Loss 1.262735, Accuracy 0.468750\n","Batch 20243, Loss 1.268089, Accuracy 0.531250\n","Batch 20244, Loss 1.360368, Accuracy 0.500000\n","Batch 20245, Loss 1.250996, Accuracy 0.437500\n","Batch 20246, Loss 1.285193, Accuracy 0.531250\n","Batch 20247, Loss 1.901124, Accuracy 0.343750\n","Batch 20248, Loss 1.289976, Accuracy 0.531250\n","Batch 20249, Loss 1.413159, Accuracy 0.500000\n","Batch 20250, Loss 1.313083, Accuracy 0.437500\n","Batch 20251, Loss 1.287739, Accuracy 0.406250\n","Batch 20252, Loss 1.288661, Accuracy 0.562500\n","Batch 20253, Loss 1.185143, Accuracy 0.656250\n","Batch 20254, Loss 1.554604, Accuracy 0.531250\n","Batch 20255, Loss 1.487333, Accuracy 0.437500\n","Batch 20256, Loss 1.599955, Accuracy 0.468750\n","Batch 20257, Loss 1.291986, Accuracy 0.468750\n","Batch 20258, Loss 1.529878, Accuracy 0.406250\n","Batch 20259, Loss 1.140508, Accuracy 0.656250\n","Batch 20260, Loss 1.229111, Accuracy 0.531250\n","Batch 20261, Loss 1.090813, Accuracy 0.656250\n","Batch 20262, Loss 1.426034, Accuracy 0.593750\n","Batch 20263, Loss 1.518120, Accuracy 0.437500\n","Batch 20264, Loss 1.685881, Accuracy 0.500000\n","Batch 20265, Loss 1.378577, Accuracy 0.500000\n","Batch 20266, Loss 1.171701, Accuracy 0.562500\n","Batch 20267, Loss 1.424949, Accuracy 0.500000\n","Batch 20268, Loss 1.588857, Accuracy 0.468750\n","Batch 20269, Loss 1.913662, Accuracy 0.437500\n","Batch 20270, Loss 4.486001, Accuracy 0.000000\n","Batch 20271, Loss 3.536697, Accuracy 0.000000\n","Batch 20272, Loss 2.684616, Accuracy 0.000000\n","Batch 20273, Loss 1.990004, Accuracy 0.000000\n","Batch 20274, Loss 1.728402, Accuracy 0.000000\n","Batch 20275, Loss 1.851019, Accuracy 0.000000\n","Batch 20276, Loss 1.826360, Accuracy 0.000000\n","Batch 20277, Loss 1.598404, Accuracy 0.593750\n","Batch 20278, Loss 1.351766, Accuracy 0.500000\n","Batch 20279, Loss 1.200332, Accuracy 0.437500\n","Batch 20280, Loss 1.135146, Accuracy 0.562500\n","Batch 20281, Loss 1.105711, Accuracy 0.562500\n","Batch 20282, Loss 1.087412, Accuracy 0.531250\n","Batch 20283, Loss 1.074707, Accuracy 0.468750\n","Batch 20284, Loss 1.073092, Accuracy 0.343750\n","Batch 20285, Loss 1.059249, Accuracy 0.343750\n","Batch 20286, Loss 1.041034, Accuracy 0.375000\n","Batch 20287, Loss 1.010874, Accuracy 0.531250\n","Batch 20288, Loss 1.188461, Accuracy 0.250000\n","Batch 20289, Loss 1.075919, Accuracy 0.375000\n","Batch 20290, Loss 1.104050, Accuracy 0.375000\n","Batch 20291, Loss 1.043519, Accuracy 0.406250\n","Batch 20292, Loss 1.117476, Accuracy 0.437500\n","Batch 20293, Loss 1.060897, Accuracy 0.437500\n","Batch 20294, Loss 1.234459, Accuracy 0.281250\n","Batch 20295, Loss 1.312853, Accuracy 0.218750\n","Batch 20296, Loss 1.165053, Accuracy 0.406250\n","Batch 20297, Loss 1.540136, Accuracy 0.250000\n","Batch 20298, Loss 1.217928, Accuracy 0.500000\n","Batch 20299, Loss 1.312976, Accuracy 0.406250\n","Batch 20300, Loss 1.419333, Accuracy 0.312500\n","Batch 20301, Loss 1.233792, Accuracy 0.375000\n","Batch 20302, Loss 1.189310, Accuracy 0.562500\n","Batch 20303, Loss 1.208083, Accuracy 0.312500\n","Batch 20304, Loss 1.229608, Accuracy 0.343750\n","Batch 20305, Loss 1.218487, Accuracy 0.281250\n","Batch 20306, Loss 1.160319, Accuracy 0.343750\n","Batch 20307, Loss 1.184850, Accuracy 0.437500\n","Batch 20308, Loss 1.095054, Accuracy 0.500000\n","Batch 20309, Loss 1.006467, Accuracy 0.625000\n","Batch 20310, Loss 1.104225, Accuracy 0.500000\n","Batch 20311, Loss 1.104928, Accuracy 0.531250\n","Batch 20312, Loss 1.034204, Accuracy 0.531250\n","Batch 20313, Loss 0.982092, Accuracy 0.687500\n","Batch 20314, Loss 0.907686, Accuracy 0.625000\n","Batch 20315, Loss 1.574236, Accuracy 0.437500\n","Batch 20316, Loss 1.094927, Accuracy 0.562500\n","Batch 20317, Loss 1.245134, Accuracy 0.500000\n","Batch 20318, Loss 1.413222, Accuracy 0.500000\n","Batch 20319, Loss 1.739192, Accuracy 0.375000\n","Batch 20320, Loss 1.897510, Accuracy 0.312500\n","Batch 20321, Loss 1.734822, Accuracy 0.406250\n","Batch 20322, Loss 1.550034, Accuracy 0.468750\n","Batch 20323, Loss 1.532970, Accuracy 0.468750\n","Batch 20324, Loss 1.422678, Accuracy 0.406250\n","Batch 20325, Loss 1.441358, Accuracy 0.406250\n","Batch 20326, Loss 1.558627, Accuracy 0.312500\n","Batch 20327, Loss 1.385251, Accuracy 0.437500\n","Batch 20328, Loss 1.357268, Accuracy 0.375000\n","Batch 20329, Loss 1.586211, Accuracy 0.406250\n","Batch 20330, Loss 1.348287, Accuracy 0.406250\n","Batch 20331, Loss 1.346955, Accuracy 0.343750\n","Batch 20332, Loss 1.412532, Accuracy 0.250000\n","Batch 20333, Loss 1.483314, Accuracy 0.343750\n","Batch 20334, Loss 1.331798, Accuracy 0.281250\n","Batch 20335, Loss 1.433628, Accuracy 0.250000\n","Batch 20336, Loss 1.338711, Accuracy 0.250000\n","Batch 20337, Loss 1.309275, Accuracy 0.156250\n","Batch 20338, Loss 1.261283, Accuracy 0.468750\n","Batch 20339, Loss 1.216041, Accuracy 0.625000\n","Batch 20340, Loss 1.426670, Accuracy 0.500000\n","Batch 20341, Loss 1.347037, Accuracy 0.468750\n","Batch 20342, Loss 1.193614, Accuracy 0.562500\n","Batch 20343, Loss 1.069636, Accuracy 0.656250\n","Batch 20344, Loss 1.507926, Accuracy 0.500000\n","Batch 20345, Loss 1.378078, Accuracy 0.531250\n","Batch 20346, Loss 1.544449, Accuracy 0.437500\n","Batch 20347, Loss 1.733874, Accuracy 0.343750\n","Batch 20348, Loss 1.739686, Accuracy 0.281250\n","Batch 20349, Loss 1.610286, Accuracy 0.375000\n","Batch 20350, Loss 1.545866, Accuracy 0.406250\n","Batch 20351, Loss 1.876223, Accuracy 0.343750\n","Batch 20352, Loss 1.782958, Accuracy 0.312500\n","Batch 20353, Loss 1.498752, Accuracy 0.375000\n","Batch 20354, Loss 1.697311, Accuracy 0.312500\n","Batch 20355, Loss 1.508605, Accuracy 0.375000\n","Batch 20356, Loss 1.525389, Accuracy 0.312500\n","Batch 20357, Loss 1.552129, Accuracy 0.250000\n","Batch 20358, Loss 1.595219, Accuracy 0.250000\n","Batch 20359, Loss 1.463299, Accuracy 0.343750\n","Batch 20360, Loss 1.535606, Accuracy 0.125000\n","Batch 20361, Loss 1.145707, Accuracy 0.250000\n","Batch 20362, Loss 1.624500, Accuracy 0.187500\n","Batch 20363, Loss 1.715434, Accuracy 0.437500\n","Batch 20364, Loss 1.401089, Accuracy 0.437500\n","Batch 20365, Loss 1.701086, Accuracy 0.312500\n","Batch 20366, Loss 1.636478, Accuracy 0.468750\n","Batch 20367, Loss 1.650623, Accuracy 0.343750\n","Batch 20368, Loss 1.583877, Accuracy 0.531250\n","Batch 20369, Loss 1.570045, Accuracy 0.468750\n","Batch 20370, Loss 1.846523, Accuracy 0.343750\n","Batch 20371, Loss 1.754901, Accuracy 0.437500\n","Batch 20372, Loss 1.874753, Accuracy 0.312500\n","Batch 20373, Loss 1.343801, Accuracy 0.531250\n","Batch 20374, Loss 1.503979, Accuracy 0.468750\n","Batch 20375, Loss 1.731361, Accuracy 0.281250\n","Batch 20376, Loss 1.735910, Accuracy 0.250000\n","Batch 20377, Loss 1.412292, Accuracy 0.375000\n","Batch 20378, Loss 1.392860, Accuracy 0.218750\n","Batch 20379, Loss 1.566878, Accuracy 0.343750\n","Batch 20380, Loss 1.442383, Accuracy 0.437500\n","Batch 20381, Loss 1.405825, Accuracy 0.468750\n","Batch 20382, Loss 1.232734, Accuracy 0.531250\n","Batch 20383, Loss 1.362548, Accuracy 0.531250\n","Batch 20384, Loss 1.534317, Accuracy 0.375000\n","Batch 20385, Loss 1.034048, Accuracy 0.687500\n","Batch 20386, Loss 1.386478, Accuracy 0.562500\n","Batch 20387, Loss 1.485119, Accuracy 0.562500\n","Batch 20388, Loss 1.411630, Accuracy 0.562500\n","Batch 20389, Loss 1.693567, Accuracy 0.468750\n","Batch 20390, Loss 1.619701, Accuracy 0.406250\n","Batch 20391, Loss 1.711172, Accuracy 0.406250\n","Batch 20392, Loss 1.565106, Accuracy 0.500000\n","Batch 20393, Loss 1.653449, Accuracy 0.406250\n","Batch 20394, Loss 1.718958, Accuracy 0.343750\n","Batch 20395, Loss 1.605720, Accuracy 0.375000\n","Batch 20396, Loss 1.479439, Accuracy 0.468750\n","Batch 20397, Loss 1.432941, Accuracy 0.406250\n","Batch 20398, Loss 1.490198, Accuracy 0.375000\n","Batch 20399, Loss 1.434517, Accuracy 0.281250\n","Batch 20400, Loss 1.275251, Accuracy 0.468750\n","Batch except\n","Batch except\n","Batch except\n","=================================================\n","Test, Loss 6.380991, Accuracy 0.072917\n","=================================================\n","Batch 20401, Loss 1.434209, Accuracy 0.406250\n","Batch 20402, Loss 1.629327, Accuracy 0.375000\n","Batch 20403, Loss 1.438273, Accuracy 0.281250\n","Batch 20404, Loss 1.371553, Accuracy 0.500000\n","Batch 20405, Loss 1.296336, Accuracy 0.500000\n","Batch 20406, Loss 1.404002, Accuracy 0.625000\n","Batch 20407, Loss 1.347905, Accuracy 0.468750\n","Batch 20408, Loss 1.007761, Accuracy 0.750000\n","Batch 20409, Loss 2.166375, Accuracy 0.343750\n","Batch 20410, Loss 1.727770, Accuracy 0.406250\n","Batch 20411, Loss 1.679348, Accuracy 0.437500\n","Batch 20412, Loss 1.491539, Accuracy 0.531250\n","Batch 20413, Loss 1.856209, Accuracy 0.406250\n","Batch 20414, Loss 1.892584, Accuracy 0.218750\n","Batch 20415, Loss 1.520690, Accuracy 0.593750\n","Batch 20416, Loss 1.667659, Accuracy 0.375000\n","Batch 20417, Loss 1.476652, Accuracy 0.468750\n","Batch 20418, Loss 1.720729, Accuracy 0.343750\n","Batch 20419, Loss 1.605242, Accuracy 0.343750\n","Batch 20420, Loss 1.258373, Accuracy 0.562500\n","Batch 20421, Loss 1.690202, Accuracy 0.281250\n","Batch 20422, Loss 1.285829, Accuracy 0.343750\n","Batch 20423, Loss 1.716352, Accuracy 0.343750\n","Batch 20424, Loss 1.334042, Accuracy 0.375000\n","Batch 20425, Loss 1.200832, Accuracy 0.562500\n","Batch 20426, Loss 1.733469, Accuracy 0.406250\n","Batch 20427, Loss 1.185704, Accuracy 0.562500\n","Batch 20428, Loss 1.276898, Accuracy 0.500000\n","Batch 20429, Loss 1.327483, Accuracy 0.500000\n","Batch 20430, Loss 1.571163, Accuracy 0.406250\n","Batch 20431, Loss 1.492972, Accuracy 0.531250\n","Batch 20432, Loss 1.523041, Accuracy 0.531250\n","Batch 20433, Loss 1.377266, Accuracy 0.531250\n","Batch 20434, Loss 1.582470, Accuracy 0.468750\n","Batch 20435, Loss 1.501673, Accuracy 0.531250\n","Batch 20436, Loss 1.910732, Accuracy 0.468750\n","Batch 20437, Loss 1.981642, Accuracy 0.343750\n","Batch 20438, Loss 2.068716, Accuracy 0.375000\n","Batch 20439, Loss 1.654116, Accuracy 0.437500\n","Batch 20440, Loss 1.658383, Accuracy 0.437500\n","Batch 20441, Loss 1.740862, Accuracy 0.437500\n","Batch 20442, Loss 1.735733, Accuracy 0.343750\n","Batch 20443, Loss 1.628627, Accuracy 0.312500\n","Batch 20444, Loss 1.802032, Accuracy 0.343750\n","Batch 20445, Loss 1.699862, Accuracy 0.281250\n","Batch 20446, Loss 1.554527, Accuracy 0.437500\n","Batch 20447, Loss 1.530735, Accuracy 0.218750\n","Batch 20448, Loss 1.450341, Accuracy 0.343750\n","Batch 20449, Loss 1.256908, Accuracy 0.343750\n","Batch 20450, Loss 1.577708, Accuracy 0.437500\n","Batch 20451, Loss 1.593873, Accuracy 0.343750\n","Batch 20452, Loss 1.304256, Accuracy 0.500000\n","Batch 20453, Loss 1.483945, Accuracy 0.562500\n","Batch 20454, Loss 1.297471, Accuracy 0.531250\n","Batch 20455, Loss 1.171587, Accuracy 0.593750\n","Batch 20456, Loss 1.930333, Accuracy 0.437500\n","Batch 20457, Loss 1.131347, Accuracy 0.593750\n","Batch 20458, Loss 1.695963, Accuracy 0.531250\n","Batch 20459, Loss 1.336333, Accuracy 0.531250\n","Batch 20460, Loss 1.634146, Accuracy 0.531250\n","Batch 20461, Loss 2.108732, Accuracy 0.375000\n","Batch 20462, Loss 1.661172, Accuracy 0.406250\n","Batch 20463, Loss 1.581193, Accuracy 0.437500\n","Batch 20464, Loss 1.656660, Accuracy 0.406250\n","Batch 20465, Loss 1.551951, Accuracy 0.500000\n","Batch 20466, Loss 1.668178, Accuracy 0.312500\n","Batch 20467, Loss 1.661852, Accuracy 0.281250\n","Batch 20468, Loss 1.397304, Accuracy 0.468750\n","Batch 20469, Loss 1.746607, Accuracy 0.281250\n","Batch 20470, Loss 1.209344, Accuracy 0.531250\n","Batch 20471, Loss 1.790371, Accuracy 0.375000\n","Batch 20472, Loss 1.659672, Accuracy 0.437500\n","Batch 20473, Loss 1.345597, Accuracy 0.500000\n","Batch 20474, Loss 1.375811, Accuracy 0.375000\n","Batch 20475, Loss 1.526719, Accuracy 0.468750\n","Batch 20476, Loss 1.382883, Accuracy 0.531250\n","Batch 20477, Loss 1.400964, Accuracy 0.593750\n","Batch 20478, Loss 1.204811, Accuracy 0.531250\n","Batch 20479, Loss 1.366690, Accuracy 0.500000\n","Batch 20480, Loss 1.057003, Accuracy 0.593750\n","Batch 20481, Loss 1.253120, Accuracy 0.625000\n","Batch 20482, Loss 1.478069, Accuracy 0.343750\n","Batch 20483, Loss 1.575498, Accuracy 0.343750\n","Batch 20484, Loss 1.643511, Accuracy 0.375000\n","Batch 20485, Loss 1.483706, Accuracy 0.406250\n","Batch 20486, Loss 1.320345, Accuracy 0.593750\n","Batch 20487, Loss 1.535192, Accuracy 0.437500\n","Batch 20488, Loss 1.207692, Accuracy 0.593750\n","Batch 20489, Loss 1.476957, Accuracy 0.468750\n","Batch 20490, Loss 1.439399, Accuracy 0.593750\n","Batch 20491, Loss 1.354420, Accuracy 0.468750\n","Batch 20492, Loss 1.690899, Accuracy 0.375000\n","Batch 20493, Loss 1.204873, Accuracy 0.500000\n","Batch 20494, Loss 1.221408, Accuracy 0.468750\n","Batch 20495, Loss 1.144770, Accuracy 0.656250\n","Batch 20496, Loss 1.409274, Accuracy 0.500000\n","Batch 20497, Loss 1.059984, Accuracy 0.687500\n","Batch 20498, Loss 1.591965, Accuracy 0.468750\n","Batch 20499, Loss 1.356810, Accuracy 0.500000\n","Batch 20500, Loss 1.129107, Accuracy 0.500000\n","Batch 20501, Loss 1.279867, Accuracy 0.437500\n","Batch 20502, Loss 1.163347, Accuracy 0.531250\n","Batch 20503, Loss 1.560896, Accuracy 0.437500\n","Batch 20504, Loss 1.048964, Accuracy 0.687500\n","Batch 20505, Loss 1.525200, Accuracy 0.375000\n","Batch 20506, Loss 1.439407, Accuracy 0.468750\n","Batch 20507, Loss 1.257178, Accuracy 0.593750\n","Batch 20508, Loss 4.654261, Accuracy 0.156250\n","Batch 20509, Loss 5.292193, Accuracy 0.000000\n","Batch 20510, Loss 4.145572, Accuracy 0.000000\n","Batch 20511, Loss 3.055496, Accuracy 0.000000\n","Batch 20512, Loss 2.162206, Accuracy 0.000000\n","Batch 20513, Loss 1.505058, Accuracy 0.343750\n","Batch 20514, Loss 1.162843, Accuracy 0.656250\n","Batch 20515, Loss 1.108663, Accuracy 0.500000\n","Batch 20516, Loss 1.129259, Accuracy 0.406250\n","Batch 20517, Loss 1.147774, Accuracy 0.437500\n","Batch 20518, Loss 1.137987, Accuracy 0.343750\n","Batch 20519, Loss 1.110222, Accuracy 0.375000\n","Batch 20520, Loss 1.077280, Accuracy 0.562500\n","Batch 20521, Loss 1.051105, Accuracy 0.562500\n","Batch 20522, Loss 1.030079, Accuracy 0.406250\n","Batch 20523, Loss 1.013621, Accuracy 0.437500\n","Batch 20524, Loss 0.999761, Accuracy 0.406250\n","Batch 20525, Loss 0.990362, Accuracy 0.281250\n","Batch 20526, Loss 1.067992, Accuracy 0.312500\n","Batch 20527, Loss 1.108283, Accuracy 0.281250\n","Batch 20528, Loss 1.011538, Accuracy 0.312500\n","Batch 20529, Loss 1.051334, Accuracy 0.281250\n","Batch 20530, Loss 0.997506, Accuracy 0.562500\n","Batch 20531, Loss 1.324418, Accuracy 0.375000\n","Batch 20532, Loss 1.271797, Accuracy 0.375000\n","Batch 20533, Loss 1.306416, Accuracy 0.531250\n","Batch 20534, Loss 1.299913, Accuracy 0.468750\n","Batch 20535, Loss 1.244067, Accuracy 0.500000\n","Batch 20536, Loss 1.469468, Accuracy 0.343750\n","Batch 20537, Loss 1.360915, Accuracy 0.468750\n","Batch 20538, Loss 1.226451, Accuracy 0.437500\n","Batch 20539, Loss 1.569469, Accuracy 0.250000\n","Batch 20540, Loss 1.519296, Accuracy 0.218750\n","Batch 20541, Loss 1.328311, Accuracy 0.406250\n","Batch 20542, Loss 1.351695, Accuracy 0.437500\n","Batch 20543, Loss 1.478373, Accuracy 0.218750\n","Batch 20544, Loss 1.267237, Accuracy 0.406250\n","Batch 20545, Loss 1.501053, Accuracy 0.312500\n","Batch 20546, Loss 1.519889, Accuracy 0.281250\n","Batch 20547, Loss 1.544825, Accuracy 0.187500\n","Batch 20548, Loss 1.451458, Accuracy 0.281250\n","Batch 20549, Loss 1.329755, Accuracy 0.437500\n","Batch 20550, Loss 1.385249, Accuracy 0.312500\n","Batch 20551, Loss 1.481092, Accuracy 0.218750\n","Batch 20552, Loss 1.341126, Accuracy 0.281250\n","Batch 20553, Loss 1.428952, Accuracy 0.250000\n","Batch 20554, Loss 1.425205, Accuracy 0.281250\n","Batch 20555, Loss 1.504166, Accuracy 0.250000\n","Batch 20556, Loss 1.471829, Accuracy 0.125000\n","Batch 20557, Loss 1.318159, Accuracy 0.656250\n","Batch 20558, Loss 1.439511, Accuracy 0.468750\n","Batch 20559, Loss 1.491827, Accuracy 0.343750\n","Batch 20560, Loss 1.335706, Accuracy 0.562500\n","Batch 20561, Loss 1.431181, Accuracy 0.437500\n","Batch 20562, Loss 1.373811, Accuracy 0.500000\n","Batch 20563, Loss 1.318610, Accuracy 0.531250\n","Batch 20564, Loss 1.418950, Accuracy 0.406250\n","Batch 20565, Loss 1.433250, Accuracy 0.375000\n","Batch 20566, Loss 1.704731, Accuracy 0.343750\n","Batch 20567, Loss 1.354849, Accuracy 0.437500\n","Batch 20568, Loss 1.246413, Accuracy 0.500000\n","Batch 20569, Loss 1.348490, Accuracy 0.406250\n","Batch 20570, Loss 1.523611, Accuracy 0.281250\n","Batch 20571, Loss 1.285456, Accuracy 0.437500\n","Batch 20572, Loss 1.654906, Accuracy 0.187500\n","Batch 20573, Loss 1.439403, Accuracy 0.156250\n","Batch 20574, Loss 1.301139, Accuracy 0.312500\n","Batch 20575, Loss 1.195598, Accuracy 0.375000\n","Batch 20576, Loss 1.161268, Accuracy 0.625000\n","Batch 20577, Loss 1.104067, Accuracy 0.687500\n","Batch 20578, Loss 1.257719, Accuracy 0.531250\n","Batch 20579, Loss 1.921050, Accuracy 0.281250\n","Batch 20580, Loss 1.476298, Accuracy 0.468750\n","Batch 20581, Loss 1.571042, Accuracy 0.343750\n","Batch 20582, Loss 1.430855, Accuracy 0.562500\n","Batch 20583, Loss 1.976140, Accuracy 0.406250\n","Batch 20584, Loss 1.506041, Accuracy 0.593750\n","Batch 20585, Loss 1.406458, Accuracy 0.500000\n","Batch 20586, Loss 1.693348, Accuracy 0.406250\n","Batch 20587, Loss 1.488421, Accuracy 0.500000\n","Batch 20588, Loss 1.697861, Accuracy 0.343750\n","Batch 20589, Loss 2.134920, Accuracy 0.187500\n","Batch 20590, Loss 1.777675, Accuracy 0.343750\n","Batch 20591, Loss 1.557956, Accuracy 0.343750\n","Batch 20592, Loss 1.584242, Accuracy 0.250000\n","Batch 20593, Loss 1.534630, Accuracy 0.312500\n","Batch 20594, Loss 1.459992, Accuracy 0.343750\n","Batch 20595, Loss 1.536878, Accuracy 0.281250\n","Batch 20596, Loss 1.377513, Accuracy 0.375000\n","Batch 20597, Loss 1.498007, Accuracy 0.187500\n","Batch 20598, Loss 1.563542, Accuracy 0.218750\n","Batch 20599, Loss 1.131433, Accuracy 0.343750\n","Batch 20600, Loss 1.392741, Accuracy 0.468750\n","Batch except\n","Batch except\n","Batch except\n","=================================================\n","Test, Loss 8.459006, Accuracy 0.072917\n","=================================================\n","Batch 20601, Loss 1.555191, Accuracy 0.281250\n","Batch 20602, Loss 1.585719, Accuracy 0.375000\n","Batch 20603, Loss 1.644326, Accuracy 0.406250\n","Batch 20604, Loss 1.389726, Accuracy 0.531250\n","Batch 20605, Loss 1.551542, Accuracy 0.375000\n","Batch 20606, Loss 1.506711, Accuracy 0.531250\n","Batch 20607, Loss 1.873766, Accuracy 0.250000\n","Batch 20608, Loss 1.674380, Accuracy 0.375000\n","Batch 20609, Loss 1.753538, Accuracy 0.343750\n","Batch 20610, Loss 1.955727, Accuracy 0.281250\n","Batch 20611, Loss 1.640632, Accuracy 0.375000\n","Batch 20612, Loss 1.583591, Accuracy 0.437500\n","Batch 20613, Loss 1.709091, Accuracy 0.250000\n","Batch 20614, Loss 1.604960, Accuracy 0.312500\n","Batch 20615, Loss 1.534723, Accuracy 0.281250\n","Batch 20616, Loss 1.354753, Accuracy 0.406250\n","Batch 20617, Loss 1.512141, Accuracy 0.406250\n","Batch 20618, Loss 1.348459, Accuracy 0.343750\n","Batch 20619, Loss 1.293170, Accuracy 0.437500\n","Batch 20620, Loss 1.135005, Accuracy 0.625000\n","Batch 20621, Loss 1.503184, Accuracy 0.500000\n","Batch 20622, Loss 1.614850, Accuracy 0.406250\n","Batch 20623, Loss 1.490478, Accuracy 0.468750\n","Batch 20624, Loss 1.528092, Accuracy 0.468750\n","Batch 20625, Loss 1.095328, Accuracy 0.531250\n","Batch 20626, Loss 1.764110, Accuracy 0.437500\n","Batch 20627, Loss 1.866510, Accuracy 0.437500\n","Batch 20628, Loss 1.587898, Accuracy 0.437500\n","Batch 20629, Loss 1.951954, Accuracy 0.437500\n","Batch 20630, Loss 1.683149, Accuracy 0.500000\n","Batch 20631, Loss 2.098484, Accuracy 0.375000\n","Batch 20632, Loss 1.721428, Accuracy 0.375000\n","Batch 20633, Loss 1.634396, Accuracy 0.468750\n","Batch 20634, Loss 1.820307, Accuracy 0.468750\n","Batch 20635, Loss 1.771491, Accuracy 0.500000\n","Batch 20636, Loss 1.823725, Accuracy 0.406250\n","Batch 20637, Loss 1.902998, Accuracy 0.343750\n","Batch 20638, Loss 1.874065, Accuracy 0.281250\n","Batch 20639, Loss 1.922384, Accuracy 0.187500\n","Batch 20640, Loss 1.590865, Accuracy 0.375000\n","Batch 20641, Loss 1.773048, Accuracy 0.250000\n","Batch 20642, Loss 1.361624, Accuracy 0.468750\n","Batch 20643, Loss 1.452330, Accuracy 0.343750\n","Batch 20644, Loss 1.369129, Accuracy 0.375000\n","Batch 20645, Loss 1.222246, Accuracy 0.406250\n","Batch 20646, Loss 1.619965, Accuracy 0.343750\n","Batch 20647, Loss 2.049474, Accuracy 0.156250\n","Batch 20648, Loss 1.842252, Accuracy 0.562500\n","Batch 20649, Loss 1.748204, Accuracy 0.406250\n","Batch 20650, Loss 2.186832, Accuracy 0.406250\n","Batch 20651, Loss 1.349115, Accuracy 0.625000\n","Batch 20652, Loss 1.989791, Accuracy 0.468750\n","Batch 20653, Loss 1.954098, Accuracy 0.343750\n","Batch 20654, Loss 2.007614, Accuracy 0.312500\n","Batch 20655, Loss 1.403304, Accuracy 0.531250\n","Batch 20656, Loss 1.594221, Accuracy 0.437500\n","Batch 20657, Loss 1.338903, Accuracy 0.500000\n","Batch 20658, Loss 1.559680, Accuracy 0.437500\n","Batch 20659, Loss 1.340204, Accuracy 0.406250\n","Batch 20660, Loss 1.700020, Accuracy 0.187500\n","Batch 20661, Loss 1.726770, Accuracy 0.343750\n","Batch 20662, Loss 1.474128, Accuracy 0.343750\n","Batch 20663, Loss 1.706290, Accuracy 0.312500\n","Batch 20664, Loss 1.490910, Accuracy 0.500000\n","Batch 20665, Loss 1.481021, Accuracy 0.406250\n","Batch 20666, Loss 1.413400, Accuracy 0.468750\n","Batch 20667, Loss 1.807589, Accuracy 0.312500\n","Batch 20668, Loss 1.140378, Accuracy 0.625000\n","Batch 20669, Loss 1.323352, Accuracy 0.562500\n","Batch 20670, Loss 1.813227, Accuracy 0.437500\n","Batch 20671, Loss 1.539326, Accuracy 0.406250\n","Batch 20672, Loss 2.109788, Accuracy 0.406250\n","Batch 20673, Loss 1.248107, Accuracy 0.625000\n","Batch 20674, Loss 2.068513, Accuracy 0.437500\n","Batch 20675, Loss 1.903392, Accuracy 0.312500\n","Batch 20676, Loss 1.961650, Accuracy 0.437500\n","Batch 20677, Loss 2.361389, Accuracy 0.250000\n","Batch 20678, Loss 1.937371, Accuracy 0.437500\n","Batch 20679, Loss 1.715024, Accuracy 0.562500\n","Batch 20680, Loss 2.059020, Accuracy 0.343750\n","Batch 20681, Loss 1.719599, Accuracy 0.500000\n","Batch 20682, Loss 1.709623, Accuracy 0.437500\n","Batch 20683, Loss 1.464516, Accuracy 0.500000\n","Batch 20684, Loss 1.482915, Accuracy 0.406250\n","Batch 20685, Loss 1.629182, Accuracy 0.312500\n","Batch 20686, Loss 1.775774, Accuracy 0.281250\n","Batch 20687, Loss 1.800048, Accuracy 0.343750\n","Batch 20688, Loss 1.623658, Accuracy 0.156250\n","Batch 20689, Loss 1.916831, Accuracy 0.250000\n","Batch 20690, Loss 1.491042, Accuracy 0.281250\n","Batch 20691, Loss 1.221970, Accuracy 0.468750\n","Batch 20692, Loss 1.128691, Accuracy 0.312500\n","Batch 20693, Loss 1.288024, Accuracy 0.593750\n","Batch 20694, Loss 1.717655, Accuracy 0.562500\n","Batch 20695, Loss 1.323407, Accuracy 0.625000\n","Batch 20696, Loss 1.482716, Accuracy 0.625000\n","Batch 20697, Loss 1.305009, Accuracy 0.531250\n","Batch 20698, Loss 1.472710, Accuracy 0.375000\n","Batch 20699, Loss 1.891029, Accuracy 0.343750\n","Batch 20700, Loss 1.676859, Accuracy 0.375000\n","Batch 20701, Loss 1.898980, Accuracy 0.281250\n","Batch 20702, Loss 1.736300, Accuracy 0.343750\n","Batch 20703, Loss 1.731811, Accuracy 0.312500\n","Batch 20704, Loss 1.627083, Accuracy 0.468750\n","Batch 20705, Loss 1.664798, Accuracy 0.406250\n","Batch 20706, Loss 1.711334, Accuracy 0.312500\n","Batch 20707, Loss 1.609098, Accuracy 0.375000\n","Batch 20708, Loss 1.457401, Accuracy 0.250000\n","Batch 20709, Loss 1.493424, Accuracy 0.406250\n","Batch 20710, Loss 1.481847, Accuracy 0.406250\n","Batch 20711, Loss 1.239237, Accuracy 0.531250\n","Batch 20712, Loss 1.441992, Accuracy 0.437500\n","Batch 20713, Loss 1.209385, Accuracy 0.531250\n","Batch 20714, Loss 1.356032, Accuracy 0.531250\n","Batch 20715, Loss 1.374407, Accuracy 0.500000\n","Batch 20716, Loss 1.513009, Accuracy 0.468750\n","Batch 20717, Loss 1.361584, Accuracy 0.437500\n","Batch 20718, Loss 1.160720, Accuracy 0.562500\n","Batch 20719, Loss 1.016960, Accuracy 0.656250\n","Batch 20720, Loss 1.414538, Accuracy 0.531250\n","Batch 20721, Loss 1.256290, Accuracy 0.500000\n","Batch 20722, Loss 1.071882, Accuracy 0.531250\n","Batch 20723, Loss 1.473738, Accuracy 0.531250\n","Batch 20724, Loss 1.514295, Accuracy 0.468750\n","Batch 20725, Loss 1.555343, Accuracy 0.312500\n","Batch 20726, Loss 1.237207, Accuracy 0.562500\n","Batch 20727, Loss 1.376320, Accuracy 0.468750\n","Batch 20728, Loss 1.517796, Accuracy 0.437500\n","Batch 20729, Loss 1.374479, Accuracy 0.531250\n","Batch 20730, Loss 1.356504, Accuracy 0.468750\n","Batch 20731, Loss 1.254608, Accuracy 0.562500\n","Batch 20732, Loss 1.452134, Accuracy 0.375000\n","Batch 20733, Loss 1.398558, Accuracy 0.562500\n","Batch 20734, Loss 1.299134, Accuracy 0.562500\n","Batch 20735, Loss 0.978180, Accuracy 0.687500\n","Batch 20736, Loss 1.295078, Accuracy 0.468750\n","Batch 20737, Loss 1.203132, Accuracy 0.562500\n","Batch 20738, Loss 1.117315, Accuracy 0.593750\n","Batch 20739, Loss 1.508563, Accuracy 0.375000\n","Batch 20740, Loss 1.286284, Accuracy 0.468750\n","Batch 20741, Loss 1.329724, Accuracy 0.468750\n","Batch 20742, Loss 1.987789, Accuracy 0.218750\n","Batch 20743, Loss 1.486630, Accuracy 0.468750\n","Batch 20744, Loss 1.266064, Accuracy 0.625000\n","Batch 20745, Loss 1.564534, Accuracy 0.500000\n","Batch 20746, Loss 2.485108, Accuracy 0.406250\n","Batch 20747, Loss 5.661057, Accuracy 0.000000\n","Batch 20748, Loss 4.662006, Accuracy 0.000000\n","Batch 20749, Loss 3.625520, Accuracy 0.000000\n","Batch 20750, Loss 2.687378, Accuracy 0.000000\n","Batch 20751, Loss 1.965338, Accuracy 0.000000\n","Batch 20752, Loss 1.548720, Accuracy 0.625000\n","Batch 20753, Loss 1.260088, Accuracy 0.656250\n","Batch 20754, Loss 1.154273, Accuracy 0.468750\n","Batch 20755, Loss 1.106415, Accuracy 0.500000\n","Batch 20756, Loss 1.078148, Accuracy 0.437500\n","Batch 20757, Loss 1.055457, Accuracy 0.593750\n","Batch 20758, Loss 1.050721, Accuracy 0.437500\n","Batch 20759, Loss 1.041606, Accuracy 0.500000\n","Batch 20760, Loss 1.030927, Accuracy 0.625000\n","Batch 20761, Loss 1.029382, Accuracy 0.531250\n","Batch 20762, Loss 1.015065, Accuracy 0.750000\n","Batch 20763, Loss 1.009191, Accuracy 0.687500\n","Batch 20764, Loss 1.008391, Accuracy 0.500000\n","Batch 20765, Loss 1.079540, Accuracy 0.406250\n","Batch 20766, Loss 0.993252, Accuracy 0.468750\n","Batch 20767, Loss 1.177249, Accuracy 0.500000\n","Batch 20768, Loss 1.164711, Accuracy 0.625000\n","Batch 20769, Loss 1.163841, Accuracy 0.562500\n","Batch 20770, Loss 1.251777, Accuracy 0.406250\n","Batch 20771, Loss 1.207538, Accuracy 0.406250\n","Batch 20772, Loss 1.361547, Accuracy 0.468750\n","Batch 20773, Loss 1.229060, Accuracy 0.531250\n","Batch 20774, Loss 1.324751, Accuracy 0.343750\n","Batch 20775, Loss 1.310190, Accuracy 0.437500\n","Batch 20776, Loss 1.486328, Accuracy 0.250000\n","Batch 20777, Loss 1.553623, Accuracy 0.281250\n","Batch 20778, Loss 1.347148, Accuracy 0.312500\n","Batch 20779, Loss 1.398656, Accuracy 0.437500\n","Batch 20780, Loss 1.434877, Accuracy 0.375000\n","Batch 20781, Loss 1.540450, Accuracy 0.312500\n","Batch 20782, Loss 1.317409, Accuracy 0.343750\n","Batch 20783, Loss 1.440238, Accuracy 0.375000\n","Batch 20784, Loss 1.424418, Accuracy 0.406250\n","Batch 20785, Loss 1.561963, Accuracy 0.250000\n","Batch 20786, Loss 1.259538, Accuracy 0.531250\n","Batch 20787, Loss 1.231085, Accuracy 0.343750\n","Batch 20788, Loss 1.540094, Accuracy 0.218750\n","Batch 20789, Loss 1.652692, Accuracy 0.156250\n","Batch 20790, Loss 1.442098, Accuracy 0.250000\n","Batch 20791, Loss 1.358556, Accuracy 0.343750\n","Batch 20792, Loss 1.560606, Accuracy 0.156250\n","Batch 20793, Loss 1.433917, Accuracy 0.343750\n","Batch 20794, Loss 1.512640, Accuracy 0.218750\n","Batch 20795, Loss 1.445524, Accuracy 0.218750\n","Batch 20796, Loss 1.372690, Accuracy 0.218750\n","Batch 20797, Loss 1.433542, Accuracy 0.500000\n","Batch 20798, Loss 1.585808, Accuracy 0.312500\n","Batch 20799, Loss 1.422297, Accuracy 0.531250\n","Batch 20800, Loss 1.549006, Accuracy 0.343750\n","Batch except\n","Batch except\n","Batch except\n","=================================================\n","Test, Loss 7.162893, Accuracy 0.093750\n","=================================================\n","Batch 20801, Loss 1.408291, Accuracy 0.500000\n","Batch 20802, Loss 1.328446, Accuracy 0.500000\n","Batch 20803, Loss 1.449827, Accuracy 0.406250\n","Batch 20804, Loss 1.402024, Accuracy 0.437500\n","Batch 20805, Loss 1.399935, Accuracy 0.406250\n","Batch 20806, Loss 1.488749, Accuracy 0.343750\n","Batch 20807, Loss 1.290865, Accuracy 0.468750\n","Batch 20808, Loss 1.409506, Accuracy 0.375000\n","Batch 20809, Loss 1.736701, Accuracy 0.156250\n","Batch 20810, Loss 1.468939, Accuracy 0.187500\n","Batch 20811, Loss 1.296369, Accuracy 0.312500\n","Batch 20812, Loss 1.408922, Accuracy 0.281250\n","Batch 20813, Loss 1.398895, Accuracy 0.250000\n","Batch 20814, Loss 1.668192, Accuracy 0.406250\n","Batch 20815, Loss 1.327166, Accuracy 0.656250\n","Batch 20816, Loss 1.296621, Accuracy 0.625000\n","Batch 20817, Loss 1.243463, Accuracy 0.625000\n","Batch 20818, Loss 1.082312, Accuracy 0.625000\n","Batch 20819, Loss 1.424899, Accuracy 0.468750\n","Batch 20820, Loss 1.465668, Accuracy 0.406250\n","Batch 20821, Loss 1.617308, Accuracy 0.406250\n","Batch 20822, Loss 1.704707, Accuracy 0.375000\n","Batch 20823, Loss 1.477916, Accuracy 0.500000\n","Batch 20824, Loss 1.370335, Accuracy 0.468750\n","Batch 20825, Loss 1.292255, Accuracy 0.625000\n","Batch 20826, Loss 1.584782, Accuracy 0.468750\n","Batch 20827, Loss 1.860963, Accuracy 0.312500\n","Batch 20828, Loss 1.496169, Accuracy 0.468750\n","Batch 20829, Loss 1.664357, Accuracy 0.312500\n","Batch 20830, Loss 1.347122, Accuracy 0.500000\n","Batch 20831, Loss 1.607192, Accuracy 0.312500\n","Batch 20832, Loss 1.538298, Accuracy 0.343750\n","Batch 20833, Loss 1.584861, Accuracy 0.312500\n","Batch 20834, Loss 1.290351, Accuracy 0.437500\n","Batch 20835, Loss 1.512827, Accuracy 0.187500\n","Batch 20836, Loss 1.552292, Accuracy 0.156250\n","Batch 20837, Loss 1.407520, Accuracy 0.343750\n","Batch 20838, Loss 1.420985, Accuracy 0.187500\n","Batch 20839, Loss 1.488451, Accuracy 0.250000\n","Batch 20840, Loss 1.424724, Accuracy 0.375000\n","Batch 20841, Loss 2.024764, Accuracy 0.281250\n","Batch 20842, Loss 1.547858, Accuracy 0.343750\n","Batch 20843, Loss 2.267961, Accuracy 0.218750\n","Batch 20844, Loss 1.643094, Accuracy 0.531250\n","Batch 20845, Loss 1.652885, Accuracy 0.531250\n","Batch 20846, Loss 1.840580, Accuracy 0.437500\n","Batch 20847, Loss 1.626254, Accuracy 0.437500\n","Batch 20848, Loss 1.673368, Accuracy 0.406250\n","Batch 20849, Loss 1.755882, Accuracy 0.312500\n","Batch 20850, Loss 1.795611, Accuracy 0.250000\n","Batch 20851, Loss 1.523011, Accuracy 0.406250\n","Batch 20852, Loss 1.500181, Accuracy 0.406250\n","Batch 20853, Loss 1.475871, Accuracy 0.343750\n","Batch 20854, Loss 1.705590, Accuracy 0.187500\n","Batch 20855, Loss 1.518783, Accuracy 0.156250\n","Batch 20856, Loss 2.029053, Accuracy 0.187500\n","Batch 20857, Loss 1.710771, Accuracy 0.281250\n","Batch 20858, Loss 1.548019, Accuracy 0.343750\n","Batch 20859, Loss 1.596081, Accuracy 0.312500\n","Batch 20860, Loss 1.232359, Accuracy 0.593750\n","Batch 20861, Loss 1.026113, Accuracy 0.781250\n","Batch 20862, Loss 1.207325, Accuracy 0.593750\n","Batch 20863, Loss 1.326494, Accuracy 0.625000\n","Batch 20864, Loss 1.535465, Accuracy 0.500000\n","Batch 20865, Loss 1.487183, Accuracy 0.406250\n","Batch 20866, Loss 1.933520, Accuracy 0.281250\n","Batch 20867, Loss 1.564247, Accuracy 0.531250\n","Batch 20868, Loss 2.007718, Accuracy 0.312500\n","Batch 20869, Loss 1.874782, Accuracy 0.406250\n","Batch 20870, Loss 2.041348, Accuracy 0.281250\n","Batch 20871, Loss 1.964493, Accuracy 0.343750\n","Batch 20872, Loss 1.992233, Accuracy 0.281250\n","Batch 20873, Loss 1.910159, Accuracy 0.406250\n","Batch 20874, Loss 2.156020, Accuracy 0.187500\n","Batch 20875, Loss 1.808887, Accuracy 0.406250\n","Batch 20876, Loss 1.700450, Accuracy 0.468750\n","Batch 20877, Loss 1.842945, Accuracy 0.343750\n","Batch 20878, Loss 1.837568, Accuracy 0.312500\n","Batch 20879, Loss 1.649034, Accuracy 0.375000\n","Batch 20880, Loss 1.840586, Accuracy 0.187500\n","Batch 20881, Loss 1.614035, Accuracy 0.312500\n","Batch 20882, Loss 1.378462, Accuracy 0.406250\n","Batch 20883, Loss 1.650557, Accuracy 0.250000\n","Batch 20884, Loss 1.700615, Accuracy 0.312500\n","Batch 20885, Loss 2.045219, Accuracy 0.218750\n","Batch 20886, Loss 1.763239, Accuracy 0.218750\n","Batch 20887, Loss 2.215609, Accuracy 0.218750\n","Batch 20888, Loss 3.290635, Accuracy 0.187500\n","Batch 20889, Loss 2.852983, Accuracy 0.093750\n","Batch 20890, Loss 2.053137, Accuracy 0.531250\n","Batch 20891, Loss 2.328109, Accuracy 0.625000\n","Batch 20892, Loss 2.292044, Accuracy 0.468750\n","Batch 20893, Loss 1.944525, Accuracy 0.500000\n","Batch 20894, Loss 1.869213, Accuracy 0.375000\n","Batch 20895, Loss 1.560104, Accuracy 0.406250\n","Batch 20896, Loss 1.587793, Accuracy 0.312500\n","Batch 20897, Loss 1.985842, Accuracy 0.250000\n","Batch 20898, Loss 1.317561, Accuracy 0.375000\n","Batch 20899, Loss 1.782791, Accuracy 0.406250\n","Batch 20900, Loss 1.988825, Accuracy 0.468750\n","Batch 20901, Loss 1.369651, Accuracy 0.468750\n","Batch 20902, Loss 1.528801, Accuracy 0.468750\n","Batch 20903, Loss 1.252138, Accuracy 0.437500\n","Batch 20904, Loss 1.322532, Accuracy 0.437500\n","Batch 20905, Loss 1.391167, Accuracy 0.531250\n","Batch 20906, Loss 1.210943, Accuracy 0.500000\n","Batch 20907, Loss 1.604355, Accuracy 0.468750\n","Batch 20908, Loss 1.417675, Accuracy 0.562500\n","Batch 20909, Loss 1.569810, Accuracy 0.531250\n","Batch 20910, Loss 1.196245, Accuracy 0.656250\n","Batch 20911, Loss 1.549026, Accuracy 0.562500\n","Batch 20912, Loss 1.256660, Accuracy 0.656250\n","Batch 20913, Loss 1.749123, Accuracy 0.375000\n","Batch 20914, Loss 1.763822, Accuracy 0.343750\n","Batch 20915, Loss 1.459842, Accuracy 0.562500\n","Batch 20916, Loss 1.721920, Accuracy 0.375000\n","Batch 20917, Loss 1.693157, Accuracy 0.281250\n","Batch 20918, Loss 1.615438, Accuracy 0.343750\n","Batch 20919, Loss 1.731493, Accuracy 0.406250\n","Batch 20920, Loss 1.742159, Accuracy 0.375000\n","Batch 20921, Loss 1.798203, Accuracy 0.312500\n","Batch 20922, Loss 1.613602, Accuracy 0.343750\n","Batch 20923, Loss 1.543716, Accuracy 0.343750\n","Batch 20924, Loss 1.642247, Accuracy 0.312500\n","Batch 20925, Loss 1.535709, Accuracy 0.406250\n","Batch 20926, Loss 1.508696, Accuracy 0.312500\n","Batch 20927, Loss 1.684155, Accuracy 0.312500\n","Batch 20928, Loss 1.278586, Accuracy 0.312500\n","Batch 20929, Loss 1.367326, Accuracy 0.250000\n","Batch 20930, Loss 1.121569, Accuracy 0.562500\n","Batch 20931, Loss 1.442772, Accuracy 0.437500\n","Batch 20932, Loss 1.431114, Accuracy 0.531250\n","Batch 20933, Loss 1.803306, Accuracy 0.406250\n","Batch 20934, Loss 1.553822, Accuracy 0.562500\n","Batch 20935, Loss 1.917000, Accuracy 0.468750\n","Batch 20936, Loss 1.646254, Accuracy 0.500000\n","Batch 20937, Loss 1.549134, Accuracy 0.593750\n","Batch 20938, Loss 1.872320, Accuracy 0.468750\n","Batch 20939, Loss 1.379072, Accuracy 0.500000\n","Batch 20940, Loss 2.057392, Accuracy 0.312500\n","Batch 20941, Loss 1.782661, Accuracy 0.375000\n","Batch 20942, Loss 1.882385, Accuracy 0.218750\n","Batch 20943, Loss 1.617699, Accuracy 0.406250\n","Batch 20944, Loss 1.671796, Accuracy 0.312500\n","Batch 20945, Loss 1.786618, Accuracy 0.343750\n","Batch 20946, Loss 1.580846, Accuracy 0.531250\n","Batch 20947, Loss 1.714054, Accuracy 0.218750\n","Batch 20948, Loss 1.545473, Accuracy 0.343750\n","Batch 20949, Loss 1.472708, Accuracy 0.562500\n","Batch 20950, Loss 1.594096, Accuracy 0.437500\n","Batch 20951, Loss 1.345983, Accuracy 0.437500\n","Batch 20952, Loss 1.439734, Accuracy 0.500000\n","Batch 20953, Loss 1.355582, Accuracy 0.593750\n","Batch 20954, Loss 1.443626, Accuracy 0.500000\n","Batch 20955, Loss 1.767876, Accuracy 0.281250\n","Batch 20956, Loss 1.371071, Accuracy 0.375000\n","Batch 20957, Loss 1.273963, Accuracy 0.531250\n","Batch 20958, Loss 1.323601, Accuracy 0.531250\n","Batch 20959, Loss 1.284635, Accuracy 0.468750\n","Batch 20960, Loss 1.074864, Accuracy 0.531250\n","Batch 20961, Loss 1.422786, Accuracy 0.437500\n","Batch 20962, Loss 1.400964, Accuracy 0.375000\n","Batch 20963, Loss 1.410061, Accuracy 0.500000\n","Batch 20964, Loss 1.219341, Accuracy 0.562500\n","Batch 20965, Loss 1.418970, Accuracy 0.500000\n","Batch 20966, Loss 1.623660, Accuracy 0.343750\n","Batch 20967, Loss 1.341473, Accuracy 0.500000\n","Batch 20968, Loss 1.291652, Accuracy 0.406250\n","Batch 20969, Loss 1.206919, Accuracy 0.437500\n","Batch 20970, Loss 1.120357, Accuracy 0.625000\n","Batch 20971, Loss 1.417361, Accuracy 0.468750\n","Batch 20972, Loss 1.175683, Accuracy 0.562500\n","Batch 20973, Loss 1.460973, Accuracy 0.500000\n","Batch 20974, Loss 1.031081, Accuracy 0.593750\n","Batch 20975, Loss 1.121576, Accuracy 0.531250\n","Batch 20976, Loss 1.251024, Accuracy 0.531250\n","Batch 20977, Loss 1.158856, Accuracy 0.625000\n","Batch 20978, Loss 1.140956, Accuracy 0.562500\n","Batch 20979, Loss 1.218359, Accuracy 0.468750\n","Batch 20980, Loss 1.246658, Accuracy 0.562500\n","Batch 20981, Loss 1.241932, Accuracy 0.593750\n","Batch 20982, Loss 1.546230, Accuracy 0.312500\n","Batch 20983, Loss 1.113857, Accuracy 0.718750\n","Batch 20984, Loss 1.489885, Accuracy 0.500000\n","Batch 20985, Loss 5.807177, Accuracy 0.218750\n","Batch 20986, Loss 6.547914, Accuracy 0.000000\n","Batch 20987, Loss 5.305522, Accuracy 0.000000\n","Batch 20988, Loss 3.970151, Accuracy 0.000000\n","Batch 20989, Loss 2.866796, Accuracy 0.000000\n","Batch 20990, Loss 1.997007, Accuracy 0.000000\n","Batch 20991, Loss 1.531826, Accuracy 0.718750\n","Batch 20992, Loss 1.342701, Accuracy 0.656250\n","Batch 20993, Loss 1.232992, Accuracy 0.625000\n","Batch 20994, Loss 1.165881, Accuracy 0.250000\n","Batch 20995, Loss 1.121543, Accuracy 0.562500\n","Batch 20996, Loss 1.102713, Accuracy 0.531250\n","Batch 20997, Loss 1.084620, Accuracy 0.625000\n","Batch 20998, Loss 1.083343, Accuracy 0.468750\n","Batch 20999, Loss 1.076571, Accuracy 0.468750\n","Batch 21000, Loss 1.063040, Accuracy 0.593750\n","Batch except\n","Batch except\n","Batch except\n","=================================================\n","Test, Loss 3.356192, Accuracy 0.083333\n","=================================================\n","Batch 21001, Loss 1.056362, Accuracy 0.593750\n","Batch 21002, Loss 1.043717, Accuracy 0.687500\n","Batch 21003, Loss 1.113656, Accuracy 0.531250\n","Batch 21004, Loss 1.148400, Accuracy 0.437500\n","Batch 21005, Loss 1.031209, Accuracy 0.531250\n","Batch 21006, Loss 1.203929, Accuracy 0.562500\n","Batch 21007, Loss 1.125207, Accuracy 0.593750\n","Batch 21008, Loss 1.127375, Accuracy 0.500000\n","Batch 21009, Loss 1.431296, Accuracy 0.375000\n","Batch 21010, Loss 1.228537, Accuracy 0.531250\n","Batch 21011, Loss 1.530866, Accuracy 0.437500\n","Batch 21012, Loss 1.424730, Accuracy 0.312500\n","Batch 21013, Loss 1.365825, Accuracy 0.468750\n","Batch 21014, Loss 1.263027, Accuracy 0.375000\n","Batch 21015, Loss 1.314228, Accuracy 0.500000\n","Batch 21016, Loss 1.546813, Accuracy 0.250000\n","Batch 21017, Loss 1.428998, Accuracy 0.312500\n","Batch 21018, Loss 1.538170, Accuracy 0.187500\n","Batch 21019, Loss 1.473723, Accuracy 0.343750\n","Batch 21020, Loss 1.500147, Accuracy 0.312500\n","Batch 21021, Loss 1.425849, Accuracy 0.343750\n","Batch 21022, Loss 1.394697, Accuracy 0.312500\n","Batch 21023, Loss 1.575226, Accuracy 0.187500\n","Batch 21024, Loss 1.507526, Accuracy 0.187500\n","Batch 21025, Loss 1.461926, Accuracy 0.375000\n","Batch 21026, Loss 1.352030, Accuracy 0.375000\n","Batch 21027, Loss 1.517231, Accuracy 0.281250\n","Batch 21028, Loss 1.408310, Accuracy 0.312500\n","Batch 21029, Loss 1.488610, Accuracy 0.218750\n","Batch 21030, Loss 1.439727, Accuracy 0.250000\n","Batch 21031, Loss 1.457908, Accuracy 0.250000\n","Batch 21032, Loss 1.315312, Accuracy 0.375000\n","Batch 21033, Loss 1.496111, Accuracy 0.062500\n","Batch 21034, Loss 1.847752, Accuracy 0.187500\n","Batch 21035, Loss 1.601594, Accuracy 0.250000\n","Batch 21036, Loss 1.569481, Accuracy 0.093750\n","Batch 21037, Loss 1.651369, Accuracy 0.218750\n","Batch 21038, Loss 1.784539, Accuracy 0.312500\n","Batch 21039, Loss 1.605916, Accuracy 0.062500\n","Batch 21040, Loss 1.656761, Accuracy 0.218750\n","Batch 21041, Loss 1.611266, Accuracy 0.531250\n","Batch 21042, Loss 1.627499, Accuracy 0.281250\n","Batch 21043, Loss 1.539524, Accuracy 0.468750\n","Batch 21044, Loss 1.523016, Accuracy 0.406250\n","Batch 21045, Loss 1.681569, Accuracy 0.218750\n","Batch 21046, Loss 1.608459, Accuracy 0.281250\n","Batch 21047, Loss 1.662556, Accuracy 0.156250\n","Batch 21048, Loss 1.544163, Accuracy 0.250000\n","Batch 21049, Loss 1.562887, Accuracy 0.281250\n","Batch 21050, Loss 1.576551, Accuracy 0.250000\n","Batch 21051, Loss 1.335768, Accuracy 0.312500\n","Batch 21052, Loss 1.431199, Accuracy 0.312500\n","Batch 21053, Loss 1.244996, Accuracy 0.281250\n","Batch 21054, Loss 1.249451, Accuracy 0.500000\n","Batch 21055, Loss 1.430260, Accuracy 0.500000\n","Batch 21056, Loss 1.446094, Accuracy 0.468750\n","Batch 21057, Loss 1.325652, Accuracy 0.562500\n","Batch 21058, Loss 1.438557, Accuracy 0.406250\n","Batch 21059, Loss 1.285756, Accuracy 0.500000\n","Batch 21060, Loss 1.587115, Accuracy 0.250000\n","Batch 21061, Loss 1.390352, Accuracy 0.593750\n","Batch 21062, Loss 1.243989, Accuracy 0.531250\n","Batch 21063, Loss 1.622041, Accuracy 0.375000\n","Batch 21064, Loss 1.457204, Accuracy 0.437500\n","Batch 21065, Loss 1.681322, Accuracy 0.281250\n","Batch 21066, Loss 1.318832, Accuracy 0.531250\n","Batch 21067, Loss 1.406946, Accuracy 0.406250\n","Batch 21068, Loss 1.472503, Accuracy 0.375000\n","Batch 21069, Loss 1.295883, Accuracy 0.281250\n","Batch 21070, Loss 1.182002, Accuracy 0.437500\n","Batch 21071, Loss 1.426582, Accuracy 0.250000\n","Batch 21072, Loss 1.279788, Accuracy 0.437500\n","Batch 21073, Loss 1.274624, Accuracy 0.500000\n","Batch 21074, Loss 1.409781, Accuracy 0.500000\n","Batch 21075, Loss 1.192314, Accuracy 0.593750\n","Batch 21076, Loss 1.423169, Accuracy 0.437500\n","Batch 21077, Loss 1.311485, Accuracy 0.468750\n","Batch 21078, Loss 1.650172, Accuracy 0.375000\n","Batch 21079, Loss 1.290987, Accuracy 0.687500\n","Batch 21080, Loss 1.509071, Accuracy 0.500000\n","Batch 21081, Loss 1.964311, Accuracy 0.375000\n","Batch 21082, Loss 1.940466, Accuracy 0.531250\n","Batch 21083, Loss 2.050433, Accuracy 0.375000\n","Batch 21084, Loss 2.239726, Accuracy 0.312500\n","Batch 21085, Loss 1.982233, Accuracy 0.406250\n","Batch 21086, Loss 1.885182, Accuracy 0.375000\n","Batch 21087, Loss 1.847809, Accuracy 0.437500\n","Batch 21088, Loss 1.941731, Accuracy 0.343750\n","Batch 21089, Loss 2.019245, Accuracy 0.281250\n","Batch 21090, Loss 2.010902, Accuracy 0.250000\n","Batch 21091, Loss 1.699260, Accuracy 0.437500\n","Batch 21092, Loss 1.708489, Accuracy 0.312500\n","Batch 21093, Loss 1.744163, Accuracy 0.187500\n","Batch 21094, Loss 1.771889, Accuracy 0.218750\n","Batch 21095, Loss 1.464103, Accuracy 0.312500\n","Batch 21096, Loss 1.727616, Accuracy 0.156250\n","Batch 21097, Loss 1.408416, Accuracy 0.312500\n","Batch 21098, Loss 1.449709, Accuracy 0.531250\n","Batch 21099, Loss 1.213980, Accuracy 0.593750\n","Batch 21100, Loss 1.474389, Accuracy 0.562500\n","Batch 21101, Loss 1.139729, Accuracy 0.593750\n","Batch 21102, Loss 1.392987, Accuracy 0.562500\n","Batch 21103, Loss 1.547759, Accuracy 0.500000\n","Batch 21104, Loss 1.586200, Accuracy 0.500000\n","Batch 21105, Loss 1.702268, Accuracy 0.375000\n","Batch 21106, Loss 1.269090, Accuracy 0.562500\n","Batch 21107, Loss 1.565335, Accuracy 0.500000\n","Batch 21108, Loss 1.426454, Accuracy 0.468750\n","Batch 21109, Loss 1.627447, Accuracy 0.375000\n","Batch 21110, Loss 1.608304, Accuracy 0.375000\n","Batch 21111, Loss 1.627198, Accuracy 0.343750\n","Batch 21112, Loss 1.744596, Accuracy 0.250000\n","Batch 21113, Loss 1.640177, Accuracy 0.218750\n","Batch 21114, Loss 1.571174, Accuracy 0.281250\n","Batch 21115, Loss 1.340219, Accuracy 0.375000\n","Batch 21116, Loss 1.461192, Accuracy 0.312500\n","Batch 21117, Loss 1.571245, Accuracy 0.531250\n","Batch 21118, Loss 1.445555, Accuracy 0.468750\n","Batch 21119, Loss 1.561298, Accuracy 0.343750\n","Batch 21120, Loss 1.306963, Accuracy 0.406250\n","Batch 21121, Loss 1.459420, Accuracy 0.437500\n","Batch 21122, Loss 1.412305, Accuracy 0.281250\n","Batch 21123, Loss 1.205897, Accuracy 0.625000\n","Batch 21124, Loss 2.926092, Accuracy 0.343750\n","Batch 21125, Loss 1.432313, Accuracy 0.562500\n","Batch 21126, Loss 2.690564, Accuracy 0.343750\n","Batch 21127, Loss 2.624838, Accuracy 0.406250\n","Batch 21128, Loss 2.205593, Accuracy 0.468750\n","Batch 21129, Loss 2.457974, Accuracy 0.468750\n","Batch 21130, Loss 2.164773, Accuracy 0.375000\n","Batch 21131, Loss 1.840575, Accuracy 0.437500\n","Batch 21132, Loss 2.080422, Accuracy 0.437500\n","Batch 21133, Loss 1.968276, Accuracy 0.437500\n","Batch 21134, Loss 2.027547, Accuracy 0.343750\n","Batch 21135, Loss 1.756329, Accuracy 0.406250\n","Batch 21136, Loss 1.732328, Accuracy 0.312500\n","Batch 21137, Loss 1.373022, Accuracy 0.500000\n","Batch 21138, Loss 1.806653, Accuracy 0.218750\n","Batch 21139, Loss 1.583070, Accuracy 0.406250\n","Batch 21140, Loss 1.804667, Accuracy 0.312500\n","Batch 21141, Loss 1.553243, Accuracy 0.500000\n","Batch 21142, Loss 1.258785, Accuracy 0.531250\n","Batch 21143, Loss 1.676555, Accuracy 0.468750\n","Batch 21144, Loss 1.355030, Accuracy 0.562500\n","Batch 21145, Loss 1.606610, Accuracy 0.406250\n","Batch 21146, Loss 1.238770, Accuracy 0.562500\n","Batch 21147, Loss 1.702332, Accuracy 0.375000\n","Batch 21148, Loss 1.270858, Accuracy 0.593750\n","Batch 21149, Loss 1.901339, Accuracy 0.437500\n","Batch 21150, Loss 1.888791, Accuracy 0.375000\n","Batch 21151, Loss 1.610439, Accuracy 0.437500\n","Batch 21152, Loss 2.091778, Accuracy 0.468750\n","Batch 21153, Loss 1.406193, Accuracy 0.625000\n","Batch 21154, Loss 1.889578, Accuracy 0.343750\n","Batch 21155, Loss 1.855105, Accuracy 0.375000\n","Batch 21156, Loss 1.784344, Accuracy 0.468750\n","Batch 21157, Loss 1.791077, Accuracy 0.406250\n","Batch 21158, Loss 1.735827, Accuracy 0.343750\n","Batch 21159, Loss 1.599043, Accuracy 0.375000\n","Batch 21160, Loss 1.704697, Accuracy 0.375000\n","Batch 21161, Loss 1.415456, Accuracy 0.468750\n","Batch 21162, Loss 1.642171, Accuracy 0.312500\n","Batch 21163, Loss 1.511216, Accuracy 0.375000\n","Batch 21164, Loss 1.528331, Accuracy 0.312500\n","Batch 21165, Loss 1.628193, Accuracy 0.250000\n","Batch 21166, Loss 1.463071, Accuracy 0.437500\n","Batch 21167, Loss 1.406268, Accuracy 0.531250\n","Batch 21168, Loss 1.180166, Accuracy 0.593750\n","Batch 21169, Loss 1.303160, Accuracy 0.593750\n","Batch 21170, Loss 1.120234, Accuracy 0.562500\n","Batch 21171, Loss 1.355502, Accuracy 0.531250\n","Batch 21172, Loss 1.706839, Accuracy 0.437500\n","Batch 21173, Loss 1.714925, Accuracy 0.500000\n","Batch 21174, Loss 1.545759, Accuracy 0.656250\n","Batch 21175, Loss 1.629039, Accuracy 0.562500\n","Batch 21176, Loss 1.493332, Accuracy 0.531250\n","Batch 21177, Loss 2.024668, Accuracy 0.281250\n","Batch 21178, Loss 2.020081, Accuracy 0.406250\n","Batch 21179, Loss 1.794848, Accuracy 0.375000\n","Batch 21180, Loss 2.008104, Accuracy 0.312500\n","Batch 21181, Loss 1.808833, Accuracy 0.312500\n","Batch 21182, Loss 1.736675, Accuracy 0.406250\n","Batch 21183, Loss 1.711461, Accuracy 0.343750\n","Batch 21184, Loss 1.773821, Accuracy 0.250000\n","Batch 21185, Loss 1.563721, Accuracy 0.406250\n","Batch 21186, Loss 1.618279, Accuracy 0.406250\n","Batch 21187, Loss 1.605971, Accuracy 0.312500\n","Batch 21188, Loss 1.666132, Accuracy 0.281250\n","Batch 21189, Loss 1.507640, Accuracy 0.500000\n","Batch 21190, Loss 1.385251, Accuracy 0.593750\n","Batch 21191, Loss 1.360674, Accuracy 0.468750\n","Batch 21192, Loss 1.394283, Accuracy 0.500000\n","Batch 21193, Loss 1.400740, Accuracy 0.468750\n","Batch 21194, Loss 1.436690, Accuracy 0.468750\n","Batch 21195, Loss 1.063409, Accuracy 0.687500\n","Batch 21196, Loss 1.539834, Accuracy 0.375000\n","Batch 21197, Loss 1.256951, Accuracy 0.500000\n","Batch 21198, Loss 1.697005, Accuracy 0.437500\n","Batch 21199, Loss 1.400640, Accuracy 0.468750\n","Batch 21200, Loss 1.693121, Accuracy 0.437500\n","Batch except\n","Batch except\n","Batch except\n","=================================================\n","Test, Loss 3.575318, Accuracy 0.166667\n","=================================================\n","Batch 21201, Loss 1.676823, Accuracy 0.343750\n","Batch 21202, Loss 1.278599, Accuracy 0.406250\n","Batch 21203, Loss 1.273208, Accuracy 0.562500\n","Batch 21204, Loss 1.357947, Accuracy 0.562500\n","Batch 21205, Loss 1.432325, Accuracy 0.468750\n","Batch 21206, Loss 1.530850, Accuracy 0.437500\n","Batch 21207, Loss 1.478916, Accuracy 0.500000\n","Batch 21208, Loss 1.429554, Accuracy 0.500000\n","Batch 21209, Loss 1.519240, Accuracy 0.437500\n","Batch 21210, Loss 1.352301, Accuracy 0.656250\n","Batch 21211, Loss 1.500746, Accuracy 0.468750\n","Batch 21212, Loss 1.422086, Accuracy 0.406250\n","Batch 21213, Loss 1.379362, Accuracy 0.531250\n","Batch 21214, Loss 1.407539, Accuracy 0.437500\n","Batch 21215, Loss 1.352689, Accuracy 0.625000\n","Batch 21216, Loss 1.412032, Accuracy 0.468750\n","Batch 21217, Loss 1.433540, Accuracy 0.468750\n","Batch 21218, Loss 1.560905, Accuracy 0.500000\n","Batch 21219, Loss 0.965168, Accuracy 0.718750\n","Batch 21220, Loss 1.162280, Accuracy 0.531250\n","Batch 21221, Loss 1.586497, Accuracy 0.343750\n","Batch 21222, Loss 1.364339, Accuracy 0.500000\n","Batch 21223, Loss 2.264022, Accuracy 0.375000\n","Batch 21224, Loss 4.883620, Accuracy 0.000000\n","Batch 21225, Loss 4.383230, Accuracy 0.000000\n","Batch 21226, Loss 3.615406, Accuracy 0.000000\n","Batch 21227, Loss 2.984233, Accuracy 0.000000\n","Batch 21228, Loss 2.292687, Accuracy 0.000000\n","Batch 21229, Loss 1.770129, Accuracy 0.000000\n","Batch 21230, Loss 1.462081, Accuracy 0.531250\n","Batch 21231, Loss 1.331762, Accuracy 0.562500\n","Batch 21232, Loss 1.246426, Accuracy 0.406250\n","Batch 21233, Loss 1.182759, Accuracy 0.500000\n","Batch 21234, Loss 1.140436, Accuracy 0.468750\n","Batch 21235, Loss 1.118682, Accuracy 0.437500\n","Batch 21236, Loss 1.106827, Accuracy 0.406250\n","Batch 21237, Loss 1.073038, Accuracy 0.562500\n","Batch 21238, Loss 1.057286, Accuracy 0.593750\n","Batch 21239, Loss 1.052446, Accuracy 0.562500\n","Batch 21240, Loss 1.042334, Accuracy 0.562500\n","Batch 21241, Loss 1.013951, Accuracy 0.656250\n","Batch 21242, Loss 1.073845, Accuracy 0.406250\n","Batch 21243, Loss 1.055271, Accuracy 0.437500\n","Batch 21244, Loss 1.072474, Accuracy 0.437500\n","Batch 21245, Loss 0.974546, Accuracy 0.718750\n","Batch 21246, Loss 1.166416, Accuracy 0.531250\n","Batch 21247, Loss 1.124719, Accuracy 0.531250\n","Batch 21248, Loss 1.199372, Accuracy 0.500000\n","Batch 21249, Loss 1.278136, Accuracy 0.468750\n","Batch 21250, Loss 1.294640, Accuracy 0.375000\n","Batch 21251, Loss 1.372436, Accuracy 0.343750\n","Batch 21252, Loss 1.490358, Accuracy 0.281250\n","Batch 21253, Loss 1.208000, Accuracy 0.468750\n","Batch 21254, Loss 1.070386, Accuracy 0.562500\n","Batch 21255, Loss 1.364689, Accuracy 0.312500\n","Batch 21256, Loss 1.292908, Accuracy 0.406250\n","Batch 21257, Loss 1.250725, Accuracy 0.406250\n","Batch 21258, Loss 1.284285, Accuracy 0.437500\n","Batch 21259, Loss 1.208293, Accuracy 0.468750\n","Batch 21260, Loss 1.374016, Accuracy 0.343750\n","Batch 21261, Loss 1.376829, Accuracy 0.312500\n","Batch 21262, Loss 1.414886, Accuracy 0.156250\n","Batch 21263, Loss 1.320114, Accuracy 0.250000\n","Batch 21264, Loss 1.250717, Accuracy 0.312500\n","Batch 21265, Loss 1.263518, Accuracy 0.281250\n","Batch 21266, Loss 1.283679, Accuracy 0.156250\n","Batch 21267, Loss 1.228830, Accuracy 0.218750\n","Batch 21268, Loss 1.175859, Accuracy 0.281250\n","Batch 21269, Loss 1.243014, Accuracy 0.562500\n","Batch 21270, Loss 1.385194, Accuracy 0.406250\n","Batch 21271, Loss 1.299514, Accuracy 0.406250\n","Batch 21272, Loss 1.103056, Accuracy 0.687500\n","Batch 21273, Loss 1.133319, Accuracy 0.656250\n","Batch 21274, Loss 1.401372, Accuracy 0.468750\n","Batch 21275, Loss 1.285207, Accuracy 0.531250\n","Batch 21276, Loss 1.414111, Accuracy 0.468750\n","Batch 21277, Loss 1.335677, Accuracy 0.500000\n","Batch 21278, Loss 1.697854, Accuracy 0.312500\n","Batch 21279, Loss 1.559030, Accuracy 0.375000\n","Batch 21280, Loss 1.801576, Accuracy 0.218750\n","Batch 21281, Loss 1.477853, Accuracy 0.375000\n","Batch 21282, Loss 1.569810, Accuracy 0.281250\n","Batch 21283, Loss 1.620333, Accuracy 0.281250\n","Batch 21284, Loss 1.477753, Accuracy 0.343750\n","Batch 21285, Loss 1.293435, Accuracy 0.375000\n","Batch 21286, Loss 1.468170, Accuracy 0.375000\n","Batch 21287, Loss 1.292717, Accuracy 0.343750\n","Batch 21288, Loss 1.171457, Accuracy 0.531250\n","Batch 21289, Loss 1.517275, Accuracy 0.156250\n","Batch 21290, Loss 1.343701, Accuracy 0.218750\n","Batch 21291, Loss 1.214625, Accuracy 0.593750\n","Batch 21292, Loss 1.428862, Accuracy 0.468750\n","Batch 21293, Loss 1.369029, Accuracy 0.468750\n","Batch 21294, Loss 1.512881, Accuracy 0.468750\n","Batch 21295, Loss 1.415711, Accuracy 0.500000\n","Batch 21296, Loss 1.554519, Accuracy 0.375000\n","Batch 21297, Loss 1.298446, Accuracy 0.531250\n","Batch 21298, Loss 1.393567, Accuracy 0.437500\n","Batch 21299, Loss 1.344727, Accuracy 0.500000\n","Batch 21300, Loss 1.267118, Accuracy 0.593750\n","Batch 21301, Loss 1.783968, Accuracy 0.281250\n","Batch 21302, Loss 1.548694, Accuracy 0.437500\n","Batch 21303, Loss 1.530588, Accuracy 0.375000\n","Batch 21304, Loss 1.620312, Accuracy 0.375000\n","Batch 21305, Loss 1.555465, Accuracy 0.437500\n","Batch 21306, Loss 1.497028, Accuracy 0.406250\n","Batch 21307, Loss 1.593752, Accuracy 0.406250\n","Batch 21308, Loss 1.527745, Accuracy 0.375000\n","Batch 21309, Loss 1.664643, Accuracy 0.187500\n","Batch 21310, Loss 1.597249, Accuracy 0.250000\n","Batch 21311, Loss 1.460083, Accuracy 0.312500\n","Batch 21312, Loss 1.399113, Accuracy 0.312500\n","Batch 21313, Loss 1.440575, Accuracy 0.187500\n","Batch 21314, Loss 1.344731, Accuracy 0.281250\n","Batch 21315, Loss 1.281204, Accuracy 0.437500\n","Batch 21316, Loss 1.453794, Accuracy 0.468750\n","Batch 21317, Loss 1.545454, Accuracy 0.406250\n","Batch 21318, Loss 1.341137, Accuracy 0.562500\n","Batch 21319, Loss 1.861151, Accuracy 0.406250\n","Batch 21320, Loss 1.653483, Accuracy 0.531250\n","Batch 21321, Loss 1.910333, Accuracy 0.406250\n","Batch 21322, Loss 1.930383, Accuracy 0.250000\n","Batch 21323, Loss 1.544722, Accuracy 0.531250\n","Batch 21324, Loss 1.638968, Accuracy 0.468750\n","Batch 21325, Loss 1.848349, Accuracy 0.250000\n","Batch 21326, Loss 1.716736, Accuracy 0.375000\n","Batch 21327, Loss 1.847122, Accuracy 0.343750\n","Batch 21328, Loss 1.769649, Accuracy 0.312500\n","Batch 21329, Loss 1.716966, Accuracy 0.343750\n","Batch 21330, Loss 1.611285, Accuracy 0.281250\n","Batch 21331, Loss 1.505621, Accuracy 0.343750\n","Batch 21332, Loss 1.503492, Accuracy 0.218750\n","Batch 21333, Loss 1.467188, Accuracy 0.375000\n","Batch 21334, Loss 1.447432, Accuracy 0.218750\n","Batch 21335, Loss 1.434923, Accuracy 0.312500\n","Batch 21336, Loss 1.770206, Accuracy 0.312500\n","Batch 21337, Loss 1.150113, Accuracy 0.406250\n","Batch 21338, Loss 1.314595, Accuracy 0.562500\n","Batch 21339, Loss 1.532914, Accuracy 0.562500\n","Batch 21340, Loss 1.638611, Accuracy 0.343750\n","Batch 21341, Loss 1.823543, Accuracy 0.343750\n","Batch 21342, Loss 1.315562, Accuracy 0.437500\n","Batch 21343, Loss 1.403801, Accuracy 0.531250\n","Batch 21344, Loss 1.702601, Accuracy 0.500000\n","Batch 21345, Loss 1.772602, Accuracy 0.406250\n","Batch 21346, Loss 1.510210, Accuracy 0.500000\n","Batch 21347, Loss 1.598305, Accuracy 0.406250\n","Batch 21348, Loss 1.693668, Accuracy 0.343750\n","Batch 21349, Loss 1.614743, Accuracy 0.375000\n","Batch 21350, Loss 1.756680, Accuracy 0.281250\n","Batch 21351, Loss 1.532487, Accuracy 0.500000\n","Batch 21352, Loss 1.590821, Accuracy 0.343750\n","Batch 21353, Loss 1.445670, Accuracy 0.406250\n","Batch 21354, Loss 1.625890, Accuracy 0.250000\n","Batch 21355, Loss 1.509994, Accuracy 0.406250\n","Batch 21356, Loss 1.380086, Accuracy 0.312500\n","Batch 21357, Loss 1.501448, Accuracy 0.281250\n","Batch 21358, Loss 1.536690, Accuracy 0.187500\n","Batch 21359, Loss 1.439824, Accuracy 0.218750\n","Batch 21360, Loss 1.254987, Accuracy 0.218750\n","Batch 21361, Loss 1.251185, Accuracy 0.406250\n","Batch 21362, Loss 1.618448, Accuracy 0.250000\n","Batch 21363, Loss 1.691416, Accuracy 0.562500\n","Batch 21364, Loss 1.431878, Accuracy 0.500000\n","Batch 21365, Loss 1.382260, Accuracy 0.593750\n","Batch 21366, Loss 1.993517, Accuracy 0.593750\n","Batch 21367, Loss 2.446211, Accuracy 0.437500\n","Batch 21368, Loss 3.578890, Accuracy 0.312500\n","Batch 21369, Loss 3.196686, Accuracy 0.312500\n","Batch 21370, Loss 2.901909, Accuracy 0.312500\n","Batch 21371, Loss 2.681160, Accuracy 0.406250\n","Batch 21372, Loss 2.936018, Accuracy 0.281250\n","Batch 21373, Loss 2.402825, Accuracy 0.312500\n","Batch 21374, Loss 2.342889, Accuracy 0.312500\n","Batch 21375, Loss 2.306645, Accuracy 0.343750\n","Batch 21376, Loss 2.327321, Accuracy 0.281250\n","Batch 21377, Loss 2.347990, Accuracy 0.218750\n","Batch 21378, Loss 2.241538, Accuracy 0.218750\n","Batch 21379, Loss 2.181453, Accuracy 0.187500\n","Batch 21380, Loss 2.026194, Accuracy 0.125000\n","Batch 21381, Loss 1.638043, Accuracy 0.625000\n","Batch 21382, Loss 1.960939, Accuracy 0.437500\n","Batch 21383, Loss 1.638594, Accuracy 0.593750\n","Batch 21384, Loss 1.193537, Accuracy 0.656250\n","Batch 21385, Loss 1.361580, Accuracy 0.656250\n","Batch 21386, Loss 1.541559, Accuracy 0.562500\n","Batch 21387, Loss 1.755320, Accuracy 0.375000\n","Batch 21388, Loss 1.504624, Accuracy 0.500000\n","Batch 21389, Loss 1.895067, Accuracy 0.437500\n","Batch 21390, Loss 1.422018, Accuracy 0.531250\n","Batch 21391, Loss 2.211325, Accuracy 0.281250\n","Batch 21392, Loss 1.736373, Accuracy 0.437500\n","Batch 21393, Loss 1.638338, Accuracy 0.375000\n","Batch 21394, Loss 1.803841, Accuracy 0.406250\n","Batch 21395, Loss 1.791383, Accuracy 0.281250\n","Batch 21396, Loss 1.543861, Accuracy 0.468750\n","Batch 21397, Loss 1.854656, Accuracy 0.156250\n","Batch 21398, Loss 1.674158, Accuracy 0.343750\n","Batch 21399, Loss 1.340726, Accuracy 0.437500\n","Batch 21400, Loss 1.649450, Accuracy 0.281250\n","Batch except\n","Batch except\n","Batch except\n","=================================================\n","Test, Loss 3.211694, Accuracy 0.083333\n","=================================================\n","Batch 21401, Loss 1.636547, Accuracy 0.218750\n","Batch 21402, Loss 1.417468, Accuracy 0.343750\n","Batch 21403, Loss 1.306578, Accuracy 0.375000\n","Batch 21404, Loss 1.517450, Accuracy 0.406250\n","Batch 21405, Loss 1.666320, Accuracy 0.468750\n","Batch 21406, Loss 1.180194, Accuracy 0.656250\n","Batch 21407, Loss 1.282642, Accuracy 0.468750\n","Batch 21408, Loss 1.559838, Accuracy 0.375000\n","Batch 21409, Loss 1.218664, Accuracy 0.625000\n","Batch 21410, Loss 1.339173, Accuracy 0.468750\n","Batch 21411, Loss 1.918568, Accuracy 0.437500\n","Batch 21412, Loss 2.296043, Accuracy 0.343750\n","Batch 21413, Loss 1.663966, Accuracy 0.437500\n","Batch 21414, Loss 1.928667, Accuracy 0.437500\n","Batch 21415, Loss 1.607402, Accuracy 0.500000\n","Batch 21416, Loss 1.851235, Accuracy 0.343750\n","Batch 21417, Loss 1.580602, Accuracy 0.437500\n","Batch 21418, Loss 1.983174, Accuracy 0.281250\n","Batch 21419, Loss 1.834425, Accuracy 0.343750\n","Batch 21420, Loss 1.705204, Accuracy 0.437500\n","Batch 21421, Loss 1.837572, Accuracy 0.375000\n","Batch 21422, Loss 1.630488, Accuracy 0.406250\n","Batch 21423, Loss 1.740177, Accuracy 0.343750\n","Batch 21424, Loss 1.688864, Accuracy 0.312500\n","Batch 21425, Loss 1.654550, Accuracy 0.281250\n","Batch 21426, Loss 1.760205, Accuracy 0.250000\n","Batch 21427, Loss 1.751655, Accuracy 0.218750\n","Batch 21428, Loss 1.458830, Accuracy 0.312500\n","Batch 21429, Loss 1.829804, Accuracy 0.187500\n","Batch 21430, Loss 1.385145, Accuracy 0.218750\n","Batch 21431, Loss 1.514325, Accuracy 0.187500\n","Batch 21432, Loss 1.628080, Accuracy 0.156250\n","Batch 21433, Loss 1.421207, Accuracy 0.437500\n","Batch 21434, Loss 1.375469, Accuracy 0.625000\n","Batch 21435, Loss 1.449872, Accuracy 0.406250\n","Batch 21436, Loss 1.533069, Accuracy 0.468750\n","Batch 21437, Loss 1.469228, Accuracy 0.406250\n","Batch 21438, Loss 1.392265, Accuracy 0.375000\n","Batch 21439, Loss 1.215289, Accuracy 0.593750\n","Batch 21440, Loss 1.318898, Accuracy 0.468750\n","Batch 21441, Loss 1.657893, Accuracy 0.281250\n","Batch 21442, Loss 1.104340, Accuracy 0.593750\n","Batch 21443, Loss 1.328681, Accuracy 0.437500\n","Batch 21444, Loss 1.573732, Accuracy 0.375000\n","Batch 21445, Loss 1.464102, Accuracy 0.500000\n","Batch 21446, Loss 1.221264, Accuracy 0.531250\n","Batch 21447, Loss 1.473343, Accuracy 0.437500\n","Batch 21448, Loss 1.499280, Accuracy 0.500000\n","Batch 21449, Loss 1.509412, Accuracy 0.468750\n","Batch 21450, Loss 1.169377, Accuracy 0.562500\n","Batch 21451, Loss 1.324873, Accuracy 0.531250\n","Batch 21452, Loss 1.712943, Accuracy 0.406250\n","Batch 21453, Loss 1.139736, Accuracy 0.593750\n","Batch 21454, Loss 1.552367, Accuracy 0.468750\n","Batch 21455, Loss 1.387718, Accuracy 0.531250\n","Batch 21456, Loss 1.294570, Accuracy 0.500000\n","Batch 21457, Loss 1.200832, Accuracy 0.593750\n","Batch 21458, Loss 1.159222, Accuracy 0.531250\n","Batch 21459, Loss 1.223692, Accuracy 0.562500\n","Batch 21460, Loss 1.049655, Accuracy 0.593750\n","Batch 21461, Loss 1.298933, Accuracy 0.500000\n","Batch 21462, Loss 4.516658, Accuracy 0.093750\n","Batch 21463, Loss 4.954653, Accuracy 0.000000\n","Batch 21464, Loss 4.235960, Accuracy 0.000000\n","Batch 21465, Loss 3.605466, Accuracy 0.000000\n","Batch 21466, Loss 2.979225, Accuracy 0.000000\n","Batch 21467, Loss 2.489112, Accuracy 0.000000\n","Batch 21468, Loss 2.129605, Accuracy 0.000000\n","Batch 21469, Loss 1.770157, Accuracy 0.000000\n","Batch 21470, Loss 1.548788, Accuracy 0.500000\n","Batch 21471, Loss 1.385505, Accuracy 0.562500\n","Batch 21472, Loss 1.287779, Accuracy 0.500000\n","Batch 21473, Loss 1.221986, Accuracy 0.562500\n","Batch 21474, Loss 1.183434, Accuracy 0.281250\n","Batch 21475, Loss 1.148468, Accuracy 0.500000\n","Batch 21476, Loss 1.113013, Accuracy 0.718750\n","Batch 21477, Loss 1.114223, Accuracy 0.500000\n","Batch 21478, Loss 1.077349, Accuracy 0.718750\n","Batch 21479, Loss 1.083267, Accuracy 0.531250\n","Batch 21480, Loss 1.136241, Accuracy 0.531250\n","Batch 21481, Loss 1.165559, Accuracy 0.468750\n","Batch 21482, Loss 1.117924, Accuracy 0.531250\n","Batch 21483, Loss 1.129900, Accuracy 0.406250\n","Batch 21484, Loss 1.219486, Accuracy 0.562500\n","Batch 21485, Loss 1.148449, Accuracy 0.593750\n","Batch 21486, Loss 1.365680, Accuracy 0.312500\n","Batch 21487, Loss 1.262618, Accuracy 0.375000\n","Batch 21488, Loss 1.286285, Accuracy 0.375000\n","Batch 21489, Loss 1.275563, Accuracy 0.406250\n","Batch 21490, Loss 1.215866, Accuracy 0.406250\n","Batch 21491, Loss 1.376121, Accuracy 0.406250\n","Batch 21492, Loss 1.343447, Accuracy 0.406250\n","Batch 21493, Loss 1.272366, Accuracy 0.468750\n","Batch 21494, Loss 1.371826, Accuracy 0.343750\n","Batch 21495, Loss 1.461936, Accuracy 0.250000\n","Batch 21496, Loss 1.392503, Accuracy 0.312500\n","Batch 21497, Loss 1.449012, Accuracy 0.250000\n","Batch 21498, Loss 1.564048, Accuracy 0.218750\n","Batch 21499, Loss 1.382779, Accuracy 0.375000\n","Batch 21500, Loss 1.411895, Accuracy 0.312500\n","Batch 21501, Loss 1.424227, Accuracy 0.312500\n","Batch 21502, Loss 1.457385, Accuracy 0.218750\n","Batch 21503, Loss 1.392552, Accuracy 0.218750\n","Batch 21504, Loss 1.587239, Accuracy 0.093750\n","Batch 21505, Loss 1.455453, Accuracy 0.218750\n","Batch 21506, Loss 1.454240, Accuracy 0.218750\n","Batch 21507, Loss 1.344453, Accuracy 0.281250\n","Batch 21508, Loss 1.469126, Accuracy 0.281250\n","Batch 21509, Loss 1.429855, Accuracy 0.312500\n","Batch 21510, Loss 1.548218, Accuracy 0.187500\n","Batch 21511, Loss 1.636245, Accuracy 0.125000\n","Batch 21512, Loss 1.627991, Accuracy 0.187500\n","Batch 21513, Loss 1.760140, Accuracy 0.156250\n","Batch 21514, Loss 1.852127, Accuracy 0.125000\n","Batch 21515, Loss 1.728954, Accuracy 0.312500\n","Batch 21516, Loss 1.672016, Accuracy 0.281250\n","Batch 21517, Loss 1.623282, Accuracy 0.218750\n","Batch 21518, Loss 1.815973, Accuracy 0.250000\n","Batch 21519, Loss 1.861488, Accuracy 0.093750\n","Batch 21520, Loss 1.678944, Accuracy 0.406250\n","Batch 21521, Loss 1.593147, Accuracy 0.437500\n","Batch 21522, Loss 1.743817, Accuracy 0.375000\n","Batch 21523, Loss 1.893029, Accuracy 0.156250\n","Batch 21524, Loss 1.685636, Accuracy 0.312500\n","Batch 21525, Loss 1.751443, Accuracy 0.250000\n","Batch 21526, Loss 1.629814, Accuracy 0.312500\n","Batch 21527, Loss 1.654334, Accuracy 0.250000\n","Batch 21528, Loss 1.564241, Accuracy 0.250000\n","Batch 21529, Loss 1.438684, Accuracy 0.406250\n","Batch 21530, Loss 1.499725, Accuracy 0.281250\n","Batch 21531, Loss 1.567199, Accuracy 0.312500\n","Batch 21532, Loss 1.484401, Accuracy 0.312500\n","Batch 21533, Loss 1.551127, Accuracy 0.218750\n","Batch 21534, Loss 1.648681, Accuracy 0.375000\n","Batch 21535, Loss 1.459744, Accuracy 0.468750\n","Batch 21536, Loss 1.603439, Accuracy 0.500000\n","Batch 21537, Loss 1.504748, Accuracy 0.406250\n","Batch 21538, Loss 1.578936, Accuracy 0.375000\n","Batch 21539, Loss 1.668585, Accuracy 0.218750\n","Batch 21540, Loss 1.582490, Accuracy 0.406250\n","Batch 21541, Loss 1.773613, Accuracy 0.406250\n","Batch 21542, Loss 1.611750, Accuracy 0.281250\n","Batch 21543, Loss 1.460292, Accuracy 0.500000\n","Batch 21544, Loss 1.637310, Accuracy 0.281250\n","Batch 21545, Loss 1.748307, Accuracy 0.281250\n","Batch 21546, Loss 1.391392, Accuracy 0.437500\n","Batch 21547, Loss 1.688110, Accuracy 0.218750\n","Batch 21548, Loss 1.515173, Accuracy 0.406250\n","Batch 21549, Loss 1.563990, Accuracy 0.312500\n","Batch 21550, Loss 1.339555, Accuracy 0.375000\n","Batch 21551, Loss 1.271757, Accuracy 0.312500\n","Batch 21552, Loss 1.355105, Accuracy 0.312500\n","Batch 21553, Loss 1.387146, Accuracy 0.281250\n","Batch 21554, Loss 1.355590, Accuracy 0.218750\n","Batch 21555, Loss 1.387408, Accuracy 0.343750\n","Batch 21556, Loss 1.344823, Accuracy 0.562500\n","Batch 21557, Loss 1.487026, Accuracy 0.468750\n","Batch 21558, Loss 1.750725, Accuracy 0.250000\n","Batch 21559, Loss 2.100242, Accuracy 0.375000\n","Batch 21560, Loss 1.810581, Accuracy 0.312500\n","Batch 21561, Loss 2.016366, Accuracy 0.281250\n","Batch 21562, Loss 1.699956, Accuracy 0.437500\n","Batch 21563, Loss 1.619153, Accuracy 0.468750\n","Batch 21564, Loss 1.997813, Accuracy 0.250000\n","Batch 21565, Loss 1.908158, Accuracy 0.156250\n","Batch 21566, Loss 1.733680, Accuracy 0.375000\n","Batch 21567, Loss 1.706591, Accuracy 0.312500\n","Batch 21568, Loss 1.612846, Accuracy 0.312500\n","Batch 21569, Loss 1.755332, Accuracy 0.187500\n","Batch 21570, Loss 1.303002, Accuracy 0.500000\n","Batch 21571, Loss 1.587382, Accuracy 0.218750\n","Batch 21572, Loss 1.557617, Accuracy 0.218750\n","Batch 21573, Loss 1.625871, Accuracy 0.250000\n","Batch 21574, Loss 1.393416, Accuracy 0.500000\n","Batch 21575, Loss 1.035403, Accuracy 0.593750\n","Batch 21576, Loss 1.268727, Accuracy 0.625000\n","Batch 21577, Loss 1.331685, Accuracy 0.562500\n","Batch 21578, Loss 1.419496, Accuracy 0.375000\n","Batch 21579, Loss 1.620130, Accuracy 0.500000\n","Batch 21580, Loss 1.558334, Accuracy 0.406250\n","Batch 21581, Loss 1.520123, Accuracy 0.500000\n","Batch 21582, Loss 1.761478, Accuracy 0.375000\n","Batch 21583, Loss 1.508098, Accuracy 0.468750\n","Batch 21584, Loss 1.662435, Accuracy 0.468750\n","Batch 21585, Loss 1.374944, Accuracy 0.531250\n","Batch 21586, Loss 1.837796, Accuracy 0.218750\n","Batch 21587, Loss 1.548011, Accuracy 0.312500\n","Batch 21588, Loss 1.705818, Accuracy 0.406250\n","Batch 21589, Loss 1.413139, Accuracy 0.343750\n","Batch 21590, Loss 1.772973, Accuracy 0.250000\n","Batch 21591, Loss 1.441828, Accuracy 0.312500\n","Batch 21592, Loss 1.363443, Accuracy 0.500000\n","Batch 21593, Loss 1.353409, Accuracy 0.468750\n","Batch 21594, Loss 1.179868, Accuracy 0.531250\n","Batch 21595, Loss 1.274798, Accuracy 0.437500\n","Batch 21596, Loss 1.553561, Accuracy 0.343750\n","Batch 21597, Loss 1.120698, Accuracy 0.656250\n","Batch 21598, Loss 1.284575, Accuracy 0.531250\n","Batch 21599, Loss 1.635683, Accuracy 0.406250\n","Batch 21600, Loss 1.397012, Accuracy 0.406250\n","Batch except\n","Batch except\n","Batch except\n","=================================================\n","Test, Loss 8.426295, Accuracy 0.072917\n","=================================================\n","Batch 21601, Loss 1.660859, Accuracy 0.468750\n","Batch 21602, Loss 1.773637, Accuracy 0.437500\n","Batch 21603, Loss 1.645918, Accuracy 0.562500\n","Batch 21604, Loss 2.380053, Accuracy 0.375000\n","Batch 21605, Loss 2.963390, Accuracy 0.312500\n","Batch 21606, Loss 1.964403, Accuracy 0.500000\n","Batch 21607, Loss 2.298190, Accuracy 0.343750\n","Batch 21608, Loss 2.026709, Accuracy 0.375000\n","Batch 21609, Loss 2.083293, Accuracy 0.281250\n","Batch 21610, Loss 1.832481, Accuracy 0.312500\n","Batch 21611, Loss 1.971439, Accuracy 0.187500\n","Batch 21612, Loss 1.827988, Accuracy 0.218750\n","Batch 21613, Loss 1.599347, Accuracy 0.406250\n","Batch 21614, Loss 1.371675, Accuracy 0.343750\n","Batch 21615, Loss 1.472230, Accuracy 0.343750\n","Batch 21616, Loss 1.396798, Accuracy 0.343750\n","Batch 21617, Loss 1.267661, Accuracy 0.250000\n","Batch 21618, Loss 1.674325, Accuracy 0.281250\n","Batch 21619, Loss 1.300281, Accuracy 0.281250\n","Batch 21620, Loss 1.861111, Accuracy 0.312500\n","Batch 21621, Loss 0.967587, Accuracy 0.625000\n","Batch 21622, Loss 0.992472, Accuracy 0.656250\n","Batch 21623, Loss 1.104685, Accuracy 0.593750\n","Batch 21624, Loss 2.066823, Accuracy 0.437500\n","Batch 21625, Loss 2.191386, Accuracy 0.406250\n","Batch 21626, Loss 1.909053, Accuracy 0.562500\n","Batch 21627, Loss 1.575567, Accuracy 0.531250\n","Batch 21628, Loss 1.783410, Accuracy 0.375000\n","Batch 21629, Loss 2.356247, Accuracy 0.343750\n","Batch 21630, Loss 2.025185, Accuracy 0.531250\n","Batch 21631, Loss 1.898342, Accuracy 0.500000\n","Batch 21632, Loss 1.906303, Accuracy 0.437500\n","Batch 21633, Loss 2.089753, Accuracy 0.218750\n","Batch 21634, Loss 1.810528, Accuracy 0.343750\n","Batch 21635, Loss 1.927104, Accuracy 0.281250\n","Batch 21636, Loss 1.801837, Accuracy 0.281250\n","Batch 21637, Loss 1.614806, Accuracy 0.375000\n","Batch 21638, Loss 1.564849, Accuracy 0.437500\n","Batch 21639, Loss 1.821752, Accuracy 0.156250\n","Batch 21640, Loss 1.528163, Accuracy 0.312500\n","Batch 21641, Loss 1.723078, Accuracy 0.312500\n","Batch 21642, Loss 1.646754, Accuracy 0.281250\n","Batch 21643, Loss 1.547870, Accuracy 0.375000\n","Batch 21644, Loss 1.411864, Accuracy 0.312500\n","Batch 21645, Loss 1.511488, Accuracy 0.156250\n","Batch 21646, Loss 1.248454, Accuracy 0.625000\n","Batch 21647, Loss 1.338716, Accuracy 0.406250\n","Batch 21648, Loss 1.551674, Accuracy 0.531250\n","Batch 21649, Loss 2.106868, Accuracy 0.468750\n","Batch 21650, Loss 1.601159, Accuracy 0.531250\n","Batch 21651, Loss 1.828494, Accuracy 0.312500\n","Batch 21652, Loss 1.746903, Accuracy 0.500000\n","Batch 21653, Loss 1.864506, Accuracy 0.437500\n","Batch 21654, Loss 2.166901, Accuracy 0.343750\n","Batch 21655, Loss 1.803577, Accuracy 0.437500\n","Batch 21656, Loss 1.585916, Accuracy 0.437500\n","Batch 21657, Loss 1.894038, Accuracy 0.312500\n","Batch 21658, Loss 1.705035, Accuracy 0.406250\n","Batch 21659, Loss 1.686617, Accuracy 0.406250\n","Batch 21660, Loss 1.676044, Accuracy 0.406250\n","Batch 21661, Loss 1.764526, Accuracy 0.218750\n","Batch 21662, Loss 1.781938, Accuracy 0.250000\n","Batch 21663, Loss 1.728827, Accuracy 0.312500\n","Batch 21664, Loss 1.547527, Accuracy 0.343750\n","Batch 21665, Loss 1.549983, Accuracy 0.312500\n","Batch 21666, Loss 1.530215, Accuracy 0.437500\n","Batch 21667, Loss 1.350983, Accuracy 0.406250\n","Batch 21668, Loss 1.675965, Accuracy 0.281250\n","Batch 21669, Loss 1.417094, Accuracy 0.625000\n","Batch 21670, Loss 1.412537, Accuracy 0.437500\n","Batch 21671, Loss 1.363943, Accuracy 0.625000\n","Batch 21672, Loss 1.295359, Accuracy 0.562500\n","Batch 21673, Loss 1.460495, Accuracy 0.562500\n","Batch 21674, Loss 1.255451, Accuracy 0.468750\n","Batch 21675, Loss 1.715728, Accuracy 0.406250\n","Batch 21676, Loss 1.297646, Accuracy 0.500000\n","Batch 21677, Loss 1.321796, Accuracy 0.531250\n","Batch 21678, Loss 1.478624, Accuracy 0.406250\n","Batch 21679, Loss 1.638174, Accuracy 0.468750\n","Batch 21680, Loss 1.374757, Accuracy 0.562500\n","Batch 21681, Loss 1.590677, Accuracy 0.437500\n","Batch 21682, Loss 1.638975, Accuracy 0.468750\n","Batch 21683, Loss 1.672243, Accuracy 0.406250\n","Batch 21684, Loss 1.339938, Accuracy 0.500000\n","Batch 21685, Loss 1.387758, Accuracy 0.437500\n","Batch 21686, Loss 1.390724, Accuracy 0.468750\n","Batch 21687, Loss 1.201127, Accuracy 0.625000\n","Batch 21688, Loss 1.186548, Accuracy 0.687500\n","Batch 21689, Loss 1.274545, Accuracy 0.468750\n","Batch 21690, Loss 1.327657, Accuracy 0.500000\n","Batch 21691, Loss 1.293672, Accuracy 0.593750\n","Batch 21692, Loss 1.205003, Accuracy 0.562500\n","Batch 21693, Loss 1.342177, Accuracy 0.562500\n","Batch 21694, Loss 1.539558, Accuracy 0.406250\n","Batch 21695, Loss 1.644731, Accuracy 0.468750\n","Batch 21696, Loss 1.544712, Accuracy 0.406250\n","Batch 21697, Loss 1.276770, Accuracy 0.531250\n","Batch 21698, Loss 1.482758, Accuracy 0.500000\n","Batch 21699, Loss 1.244087, Accuracy 0.562500\n","Batch 21700, Loss 2.734343, Accuracy 0.281250\n","Batch 21701, Loss 5.100153, Accuracy 0.000000\n","Batch 21702, Loss 4.355025, Accuracy 0.000000\n","Batch 21703, Loss 3.558293, Accuracy 0.000000\n","Batch 21704, Loss 2.807718, Accuracy 0.000000\n","Batch 21705, Loss 2.100758, Accuracy 0.000000\n","Batch 21706, Loss 1.626901, Accuracy 0.687500\n","Batch 21707, Loss 1.359720, Accuracy 0.343750\n","Batch 21708, Loss 1.225953, Accuracy 0.562500\n","Batch 21709, Loss 1.178602, Accuracy 0.437500\n","Batch 21710, Loss 1.172832, Accuracy 0.531250\n","Batch 21711, Loss 1.197255, Accuracy 0.343750\n","Batch 21712, Loss 1.188239, Accuracy 0.406250\n","Batch 21713, Loss 1.172834, Accuracy 0.468750\n","Batch 21714, Loss 1.150955, Accuracy 0.531250\n","Batch 21715, Loss 1.114379, Accuracy 0.718750\n","Batch 21716, Loss 1.112583, Accuracy 0.593750\n","Batch 21717, Loss 1.087129, Accuracy 0.687500\n","Batch 21718, Loss 1.065796, Accuracy 0.750000\n","Batch 21719, Loss 1.067133, Accuracy 0.562500\n","Batch 21720, Loss 1.125780, Accuracy 0.500000\n","Batch 21721, Loss 1.042272, Accuracy 0.500000\n","Batch 21722, Loss 1.162524, Accuracy 0.468750\n","Batch 21723, Loss 1.130686, Accuracy 0.468750\n","Batch 21724, Loss 1.357819, Accuracy 0.468750\n","Batch 21725, Loss 1.169771, Accuracy 0.593750\n","Batch 21726, Loss 1.371713, Accuracy 0.312500\n","Batch 21727, Loss 1.184519, Accuracy 0.375000\n","Batch 21728, Loss 1.132646, Accuracy 0.531250\n","Batch 21729, Loss 1.350556, Accuracy 0.375000\n","Batch 21730, Loss 1.231874, Accuracy 0.375000\n","Batch 21731, Loss 1.302979, Accuracy 0.250000\n","Batch 21732, Loss 1.196700, Accuracy 0.531250\n","Batch 21733, Loss 1.234196, Accuracy 0.437500\n","Batch 21734, Loss 1.450909, Accuracy 0.312500\n","Batch 21735, Loss 1.149212, Accuracy 0.562500\n","Batch 21736, Loss 1.364851, Accuracy 0.281250\n","Batch 21737, Loss 1.384026, Accuracy 0.250000\n","Batch 21738, Loss 1.408740, Accuracy 0.187500\n","Batch 21739, Loss 1.379005, Accuracy 0.187500\n","Batch 21740, Loss 1.374659, Accuracy 0.218750\n","Batch 21741, Loss 1.348201, Accuracy 0.218750\n","Batch 21742, Loss 1.447617, Accuracy 0.218750\n","Batch 21743, Loss 1.385451, Accuracy 0.125000\n","Batch 21744, Loss 1.398122, Accuracy 0.156250\n","Batch 21745, Loss 1.303465, Accuracy 0.250000\n","Batch 21746, Loss 1.298895, Accuracy 0.250000\n","Batch 21747, Loss 1.470717, Accuracy 0.250000\n","Batch 21748, Loss 1.355765, Accuracy 0.250000\n","Batch 21749, Loss 1.477287, Accuracy 0.250000\n","Batch 21750, Loss 1.605474, Accuracy 0.187500\n","Batch 21751, Loss 1.333767, Accuracy 0.156250\n","Batch 21752, Loss 1.449120, Accuracy 0.406250\n","Batch 21753, Loss 1.529555, Accuracy 0.343750\n","Batch 21754, Loss 1.397156, Accuracy 0.500000\n","Batch 21755, Loss 1.541218, Accuracy 0.343750\n","Batch 21756, Loss 1.608370, Accuracy 0.343750\n","Batch 21757, Loss 1.440916, Accuracy 0.500000\n","Batch 21758, Loss 1.450285, Accuracy 0.468750\n","Batch 21759, Loss 1.531940, Accuracy 0.343750\n","Batch 21760, Loss 1.595528, Accuracy 0.250000\n","Batch 21761, Loss 1.618898, Accuracy 0.218750\n","Batch 21762, Loss 1.424261, Accuracy 0.375000\n","Batch 21763, Loss 1.518232, Accuracy 0.375000\n","Batch 21764, Loss 1.386365, Accuracy 0.250000\n","Batch 21765, Loss 1.463028, Accuracy 0.218750\n","Batch 21766, Loss 1.608199, Accuracy 0.312500\n","Batch 21767, Loss 1.333117, Accuracy 0.343750\n","Batch 21768, Loss 1.485815, Accuracy 0.281250\n","Batch 21769, Loss 1.336437, Accuracy 0.156250\n","Batch 21770, Loss 1.536921, Accuracy 0.187500\n","Batch 21771, Loss 1.241780, Accuracy 0.343750\n","Batch 21772, Loss 1.334161, Accuracy 0.281250\n","Batch 21773, Loss 1.388378, Accuracy 0.531250\n","Batch 21774, Loss 1.640215, Accuracy 0.343750\n","Batch 21775, Loss 1.580767, Accuracy 0.406250\n","Batch 21776, Loss 1.497124, Accuracy 0.531250\n","Batch 21777, Loss 1.487926, Accuracy 0.531250\n","Batch 21778, Loss 1.460480, Accuracy 0.406250\n","Batch 21779, Loss 1.369237, Accuracy 0.468750\n","Batch 21780, Loss 1.545931, Accuracy 0.343750\n","Batch 21781, Loss 1.617330, Accuracy 0.343750\n","Batch 21782, Loss 1.525067, Accuracy 0.343750\n","Batch 21783, Loss 1.675443, Accuracy 0.281250\n","Batch 21784, Loss 1.597427, Accuracy 0.343750\n","Batch 21785, Loss 1.677198, Accuracy 0.281250\n","Batch 21786, Loss 1.403955, Accuracy 0.406250\n","Batch 21787, Loss 1.556592, Accuracy 0.312500\n","Batch 21788, Loss 1.434186, Accuracy 0.312500\n","Batch 21789, Loss 1.265170, Accuracy 0.437500\n","Batch 21790, Loss 1.483765, Accuracy 0.312500\n","Batch 21791, Loss 1.250294, Accuracy 0.343750\n","Batch 21792, Loss 1.608872, Accuracy 0.187500\n","Batch 21793, Loss 1.402853, Accuracy 0.343750\n","Batch 21794, Loss 1.352780, Accuracy 0.343750\n","Batch 21795, Loss 1.615844, Accuracy 0.250000\n","Batch 21796, Loss 1.856237, Accuracy 0.281250\n","Batch 21797, Loss 1.897803, Accuracy 0.312500\n","Batch 21798, Loss 1.991932, Accuracy 0.312500\n","Batch 21799, Loss 1.589347, Accuracy 0.593750\n","Batch 21800, Loss 1.636676, Accuracy 0.500000\n","Batch except\n","Batch except\n","Batch except\n","=================================================\n","Test, Loss 7.533623, Accuracy 0.072917\n","=================================================\n","Batch 21801, Loss 1.778897, Accuracy 0.312500\n","Batch 21802, Loss 1.817311, Accuracy 0.343750\n","Batch 21803, Loss 1.951280, Accuracy 0.312500\n","Batch 21804, Loss 1.654175, Accuracy 0.468750\n","Batch 21805, Loss 1.819072, Accuracy 0.406250\n","Batch 21806, Loss 2.252847, Accuracy 0.125000\n","Batch 21807, Loss 1.939685, Accuracy 0.187500\n","Batch 21808, Loss 1.515180, Accuracy 0.468750\n","Batch 21809, Loss 1.904610, Accuracy 0.218750\n","Batch 21810, Loss 1.662050, Accuracy 0.281250\n","Batch 21811, Loss 1.477479, Accuracy 0.343750\n","Batch 21812, Loss 1.776421, Accuracy 0.156250\n","Batch 21813, Loss 1.368803, Accuracy 0.343750\n","Batch 21814, Loss 1.639398, Accuracy 0.187500\n","Batch 21815, Loss 1.403641, Accuracy 0.437500\n","Batch 21816, Loss 1.468936, Accuracy 0.562500\n","Batch 21817, Loss 1.469799, Accuracy 0.500000\n","Batch 21818, Loss 1.445181, Accuracy 0.531250\n","Batch 21819, Loss 1.689099, Accuracy 0.437500\n","Batch 21820, Loss 1.464890, Accuracy 0.500000\n","Batch 21821, Loss 2.176591, Accuracy 0.312500\n","Batch 21822, Loss 1.546912, Accuracy 0.375000\n","Batch 21823, Loss 1.814366, Accuracy 0.375000\n","Batch 21824, Loss 1.656499, Accuracy 0.375000\n","Batch 21825, Loss 1.596220, Accuracy 0.406250\n","Batch 21826, Loss 1.365006, Accuracy 0.531250\n","Batch 21827, Loss 1.558984, Accuracy 0.437500\n","Batch 21828, Loss 1.620629, Accuracy 0.375000\n","Batch 21829, Loss 1.734886, Accuracy 0.218750\n","Batch 21830, Loss 1.671795, Accuracy 0.250000\n","Batch 21831, Loss 1.576752, Accuracy 0.312500\n","Batch 21832, Loss 1.459848, Accuracy 0.281250\n","Batch 21833, Loss 1.304883, Accuracy 0.375000\n","Batch 21834, Loss 1.276383, Accuracy 0.343750\n","Batch 21835, Loss 1.338558, Accuracy 0.437500\n","Batch 21836, Loss 1.461117, Accuracy 0.562500\n","Batch 21837, Loss 1.536889, Accuracy 0.562500\n","Batch 21838, Loss 1.459066, Accuracy 0.500000\n","Batch 21839, Loss 1.791208, Accuracy 0.375000\n","Batch 21840, Loss 1.686514, Accuracy 0.531250\n","Batch 21841, Loss 2.218551, Accuracy 0.593750\n","Batch 21842, Loss 2.254241, Accuracy 0.375000\n","Batch 21843, Loss 2.135856, Accuracy 0.406250\n","Batch 21844, Loss 1.928353, Accuracy 0.500000\n","Batch 21845, Loss 2.163765, Accuracy 0.562500\n","Batch 21846, Loss 2.299885, Accuracy 0.500000\n","Batch 21847, Loss 1.917205, Accuracy 0.531250\n","Batch 21848, Loss 3.079800, Accuracy 0.187500\n","Batch 21849, Loss 2.099722, Accuracy 0.468750\n","Batch 21850, Loss 2.769975, Accuracy 0.187500\n","Batch 21851, Loss 2.056826, Accuracy 0.437500\n","Batch 21852, Loss 2.160282, Accuracy 0.281250\n","Batch 21853, Loss 1.940532, Accuracy 0.343750\n","Batch 21854, Loss 1.978575, Accuracy 0.218750\n","Batch 21855, Loss 1.640691, Accuracy 0.312500\n","Batch 21856, Loss 1.830483, Accuracy 0.218750\n","Batch 21857, Loss 1.479266, Accuracy 0.343750\n","Batch 21858, Loss 1.666372, Accuracy 0.156250\n","Batch 21859, Loss 1.652037, Accuracy 0.281250\n","Batch 21860, Loss 1.634372, Accuracy 0.406250\n","Batch 21861, Loss 1.479001, Accuracy 0.531250\n","Batch 21862, Loss 1.586469, Accuracy 0.468750\n","Batch 21863, Loss 1.611780, Accuracy 0.437500\n","Batch 21864, Loss 1.323408, Accuracy 0.593750\n","Batch 21865, Loss 1.453619, Accuracy 0.500000\n","Batch 21866, Loss 1.438082, Accuracy 0.531250\n","Batch 21867, Loss 1.823022, Accuracy 0.437500\n","Batch 21868, Loss 1.560635, Accuracy 0.468750\n","Batch 21869, Loss 1.575248, Accuracy 0.437500\n","Batch 21870, Loss 1.583562, Accuracy 0.468750\n","Batch 21871, Loss 1.626473, Accuracy 0.437500\n","Batch 21872, Loss 1.663032, Accuracy 0.437500\n","Batch 21873, Loss 1.646827, Accuracy 0.406250\n","Batch 21874, Loss 1.425025, Accuracy 0.312500\n","Batch 21875, Loss 1.645706, Accuracy 0.406250\n","Batch 21876, Loss 1.446243, Accuracy 0.375000\n","Batch 21877, Loss 1.450356, Accuracy 0.375000\n","Batch 21878, Loss 1.580657, Accuracy 0.312500\n","Batch 21879, Loss 1.499511, Accuracy 0.375000\n","Batch 21880, Loss 1.392917, Accuracy 0.406250\n","Batch 21881, Loss 1.744967, Accuracy 0.375000\n","Batch 21882, Loss 1.461220, Accuracy 0.593750\n","Batch 21883, Loss 1.428872, Accuracy 0.531250\n","Batch 21884, Loss 1.303730, Accuracy 0.531250\n","Batch 21885, Loss 1.487716, Accuracy 0.593750\n","Batch 21886, Loss 1.262467, Accuracy 0.531250\n","Batch 21887, Loss 1.721495, Accuracy 0.375000\n","Batch 21888, Loss 1.538689, Accuracy 0.531250\n","Batch 21889, Loss 2.098518, Accuracy 0.281250\n","Batch 21890, Loss 1.934300, Accuracy 0.375000\n","Batch 21891, Loss 1.641510, Accuracy 0.468750\n","Batch 21892, Loss 1.544304, Accuracy 0.562500\n","Batch 21893, Loss 1.593926, Accuracy 0.531250\n","Batch 21894, Loss 1.871336, Accuracy 0.343750\n","Batch 21895, Loss 1.931158, Accuracy 0.468750\n","Batch 21896, Loss 1.809132, Accuracy 0.312500\n","Batch 21897, Loss 1.884842, Accuracy 0.343750\n","Batch 21898, Loss 1.871385, Accuracy 0.343750\n","Batch 21899, Loss 1.949188, Accuracy 0.312500\n","Batch 21900, Loss 1.966119, Accuracy 0.281250\n","Batch 21901, Loss 1.822487, Accuracy 0.343750\n","Batch 21902, Loss 1.690650, Accuracy 0.406250\n","Batch 21903, Loss 1.786283, Accuracy 0.250000\n","Batch 21904, Loss 1.764202, Accuracy 0.250000\n","Batch 21905, Loss 1.579774, Accuracy 0.406250\n","Batch 21906, Loss 1.472094, Accuracy 0.343750\n","Batch 21907, Loss 1.646568, Accuracy 0.281250\n","Batch 21908, Loss 1.398119, Accuracy 0.250000\n","Batch 21909, Loss 1.336743, Accuracy 0.281250\n","Batch 21910, Loss 1.665512, Accuracy 0.375000\n","Batch 21911, Loss 1.465386, Accuracy 0.531250\n","Batch 21912, Loss 1.557620, Accuracy 0.437500\n","Batch 21913, Loss 1.465817, Accuracy 0.468750\n","Batch 21914, Loss 1.526149, Accuracy 0.375000\n","Batch 21915, Loss 1.111485, Accuracy 0.562500\n","Batch 21916, Loss 1.322781, Accuracy 0.500000\n","Batch 21917, Loss 1.549378, Accuracy 0.593750\n","Batch 21918, Loss 1.375172, Accuracy 0.562500\n","Batch 21919, Loss 1.154632, Accuracy 0.656250\n","Batch 21920, Loss 1.383681, Accuracy 0.531250\n","Batch 21921, Loss 0.982903, Accuracy 0.718750\n","Batch 21922, Loss 1.532543, Accuracy 0.500000\n","Batch 21923, Loss 1.641810, Accuracy 0.406250\n","Batch 21924, Loss 1.682790, Accuracy 0.468750\n","Batch 21925, Loss 1.684891, Accuracy 0.406250\n","Batch 21926, Loss 1.658528, Accuracy 0.468750\n","Batch 21927, Loss 1.173239, Accuracy 0.593750\n","Batch 21928, Loss 1.383038, Accuracy 0.468750\n","Batch 21929, Loss 1.245063, Accuracy 0.562500\n","Batch 21930, Loss 1.513583, Accuracy 0.343750\n","Batch 21931, Loss 1.320483, Accuracy 0.562500\n","Batch 21932, Loss 1.159676, Accuracy 0.562500\n","Batch 21933, Loss 1.315693, Accuracy 0.437500\n","Batch 21934, Loss 1.411699, Accuracy 0.562500\n","Batch 21935, Loss 1.210315, Accuracy 0.625000\n","Batch 21936, Loss 1.398368, Accuracy 0.531250\n","Batch 21937, Loss 1.510675, Accuracy 0.500000\n","Batch 21938, Loss 1.262236, Accuracy 0.531250\n","Batch 21939, Loss 4.517819, Accuracy 0.031250\n","Batch 21940, Loss 4.490611, Accuracy 0.000000\n","Batch 21941, Loss 3.637886, Accuracy 0.000000\n","Batch 21942, Loss 2.851916, Accuracy 0.000000\n","Batch 21943, Loss 2.261188, Accuracy 0.000000\n","Batch 21944, Loss 1.877288, Accuracy 0.000000\n","Batch 21945, Loss 1.764266, Accuracy 0.000000\n","Batch 21946, Loss 1.506127, Accuracy 0.562500\n","Batch 21947, Loss 1.346610, Accuracy 0.625000\n","Batch 21948, Loss 1.255532, Accuracy 0.531250\n","Batch 21949, Loss 1.202491, Accuracy 0.343750\n","Batch 21950, Loss 1.130729, Accuracy 0.531250\n","Batch 21951, Loss 1.116213, Accuracy 0.250000\n","Batch 21952, Loss 1.096539, Accuracy 0.406250\n","Batch 21953, Loss 1.092881, Accuracy 0.406250\n","Batch 21954, Loss 1.080709, Accuracy 0.593750\n","Batch 21955, Loss 1.080646, Accuracy 0.437500\n","Batch 21956, Loss 1.065085, Accuracy 0.562500\n","Batch 21957, Loss 1.110063, Accuracy 0.593750\n","Batch 21958, Loss 1.071173, Accuracy 0.625000\n","Batch 21959, Loss 1.160914, Accuracy 0.468750\n","Batch 21960, Loss 1.152318, Accuracy 0.531250\n","Batch 21961, Loss 1.178735, Accuracy 0.531250\n","Batch 21962, Loss 1.201894, Accuracy 0.593750\n","Batch 21963, Loss 1.273689, Accuracy 0.375000\n","Batch 21964, Loss 1.128650, Accuracy 0.500000\n","Batch 21965, Loss 1.244453, Accuracy 0.531250\n","Batch 21966, Loss 1.207164, Accuracy 0.500000\n","Batch 21967, Loss 1.408224, Accuracy 0.437500\n","Batch 21968, Loss 1.298930, Accuracy 0.468750\n","Batch 21969, Loss 1.493504, Accuracy 0.218750\n","Batch 21970, Loss 1.159898, Accuracy 0.468750\n","Batch 21971, Loss 1.261357, Accuracy 0.437500\n","Batch 21972, Loss 1.226079, Accuracy 0.406250\n","Batch 21973, Loss 1.263560, Accuracy 0.312500\n","Batch 21974, Loss 1.382381, Accuracy 0.281250\n","Batch 21975, Loss 1.353473, Accuracy 0.281250\n","Batch 21976, Loss 1.296117, Accuracy 0.312500\n","Batch 21977, Loss 1.264095, Accuracy 0.406250\n","Batch 21978, Loss 1.323343, Accuracy 0.218750\n","Batch 21979, Loss 1.261513, Accuracy 0.375000\n","Batch 21980, Loss 1.264621, Accuracy 0.312500\n","Batch 21981, Loss 1.247104, Accuracy 0.343750\n","Batch 21982, Loss 1.259384, Accuracy 0.281250\n","Batch 21983, Loss 1.296337, Accuracy 0.125000\n","Batch 21984, Loss 1.341474, Accuracy 0.250000\n","Batch 21985, Loss 1.457664, Accuracy 0.312500\n","Batch 21986, Loss 1.290860, Accuracy 0.218750\n","Batch 21987, Loss 1.675159, Accuracy 0.312500\n","Batch 21988, Loss 1.392432, Accuracy 0.562500\n","Batch 21989, Loss 1.425714, Accuracy 0.531250\n","Batch 21990, Loss 1.292925, Accuracy 0.500000\n","Batch 21991, Loss 1.699510, Accuracy 0.218750\n","Batch 21992, Loss 1.242594, Accuracy 0.593750\n","Batch 21993, Loss 1.546697, Accuracy 0.406250\n","Batch 21994, Loss 1.342959, Accuracy 0.500000\n","Batch 21995, Loss 1.451692, Accuracy 0.468750\n","Batch 21996, Loss 1.465546, Accuracy 0.406250\n","Batch 21997, Loss 1.527597, Accuracy 0.343750\n","Batch 21998, Loss 1.720136, Accuracy 0.187500\n","Batch 21999, Loss 1.422090, Accuracy 0.375000\n","Batch 22000, Loss 1.419744, Accuracy 0.375000\n","Batch except\n","Batch except\n","Batch except\n","=================================================\n","Test, Loss 7.964926, Accuracy 0.093750\n","=================================================\n","Batch 22001, Loss 1.712126, Accuracy 0.125000\n","Batch 22002, Loss 1.499186, Accuracy 0.281250\n","Batch 22003, Loss 1.359287, Accuracy 0.406250\n","Batch 22004, Loss 1.310984, Accuracy 0.281250\n","Batch 22005, Loss 1.501465, Accuracy 0.468750\n","Batch 22006, Loss 1.468841, Accuracy 0.437500\n","Batch 22007, Loss 1.007976, Accuracy 0.562500\n","Batch 22008, Loss 1.423167, Accuracy 0.437500\n","Batch 22009, Loss 1.180506, Accuracy 0.562500\n","Batch 22010, Loss 1.310798, Accuracy 0.500000\n","Batch 22011, Loss 1.399282, Accuracy 0.437500\n","Batch 22012, Loss 1.231128, Accuracy 0.531250\n","Batch 22013, Loss 1.560646, Accuracy 0.437500\n","Batch 22014, Loss 1.437865, Accuracy 0.562500\n","Batch 22015, Loss 1.690362, Accuracy 0.375000\n","Batch 22016, Loss 1.520615, Accuracy 0.437500\n","Batch 22017, Loss 1.826784, Accuracy 0.312500\n","Batch 22018, Loss 1.685572, Accuracy 0.375000\n","Batch 22019, Loss 1.452643, Accuracy 0.500000\n","Batch 22020, Loss 1.734483, Accuracy 0.375000\n","Batch 22021, Loss 1.597234, Accuracy 0.406250\n","Batch 22022, Loss 1.477656, Accuracy 0.406250\n","Batch 22023, Loss 1.530856, Accuracy 0.406250\n","Batch 22024, Loss 1.678979, Accuracy 0.125000\n","Batch 22025, Loss 1.265288, Accuracy 0.406250\n","Batch 22026, Loss 1.340168, Accuracy 0.343750\n","Batch 22027, Loss 1.456811, Accuracy 0.218750\n","Batch 22028, Loss 1.481374, Accuracy 0.437500\n","Batch 22029, Loss 1.253618, Accuracy 0.531250\n","Batch 22030, Loss 1.203622, Accuracy 0.562500\n","Batch 22031, Loss 1.326746, Accuracy 0.593750\n","Batch 22032, Loss 1.634876, Accuracy 0.437500\n","Batch 22033, Loss 1.783237, Accuracy 0.468750\n","Batch 22034, Loss 1.586791, Accuracy 0.468750\n","Batch 22035, Loss 2.179087, Accuracy 0.281250\n","Batch 22036, Loss 1.990997, Accuracy 0.437500\n","Batch 22037, Loss 1.786852, Accuracy 0.281250\n","Batch 22038, Loss 2.143338, Accuracy 0.375000\n","Batch 22039, Loss 1.981566, Accuracy 0.343750\n","Batch 22040, Loss 1.966117, Accuracy 0.312500\n","Batch 22041, Loss 1.670855, Accuracy 0.437500\n","Batch 22042, Loss 1.809284, Accuracy 0.218750\n","Batch 22043, Loss 1.874702, Accuracy 0.250000\n","Batch 22044, Loss 1.585615, Accuracy 0.468750\n","Batch 22045, Loss 1.847741, Accuracy 0.187500\n","Batch 22046, Loss 1.694223, Accuracy 0.343750\n","Batch 22047, Loss 1.760761, Accuracy 0.125000\n","Batch 22048, Loss 1.532971, Accuracy 0.281250\n","Batch 22049, Loss 1.444677, Accuracy 0.281250\n","Batch 22050, Loss 1.438587, Accuracy 0.406250\n","Batch 22051, Loss 1.674382, Accuracy 0.187500\n","Batch 22052, Loss 1.137946, Accuracy 0.343750\n","Batch 22053, Loss 1.553721, Accuracy 0.406250\n","Batch 22054, Loss 1.455445, Accuracy 0.437500\n","Batch 22055, Loss 1.285265, Accuracy 0.562500\n","Batch 22056, Loss 1.521310, Accuracy 0.437500\n","Batch 22057, Loss 1.795842, Accuracy 0.343750\n","Batch 22058, Loss 1.617755, Accuracy 0.406250\n","Batch 22059, Loss 1.537463, Accuracy 0.437500\n","Batch 22060, Loss 1.474713, Accuracy 0.500000\n","Batch 22061, Loss 1.877991, Accuracy 0.312500\n","Batch 22062, Loss 1.494474, Accuracy 0.500000\n","Batch 22063, Loss 1.670568, Accuracy 0.375000\n","Batch 22064, Loss 1.543777, Accuracy 0.437500\n","Batch 22065, Loss 1.657544, Accuracy 0.375000\n","Batch 22066, Loss 1.677931, Accuracy 0.281250\n","Batch 22067, Loss 1.465132, Accuracy 0.468750\n","Batch 22068, Loss 1.558971, Accuracy 0.281250\n","Batch 22069, Loss 1.602914, Accuracy 0.250000\n","Batch 22070, Loss 1.550278, Accuracy 0.406250\n","Batch 22071, Loss 1.376922, Accuracy 0.250000\n","Batch 22072, Loss 1.525600, Accuracy 0.218750\n","Batch 22073, Loss 1.399031, Accuracy 0.250000\n","Batch 22074, Loss 1.405684, Accuracy 0.250000\n","Batch 22075, Loss 1.573707, Accuracy 0.375000\n","Batch 22076, Loss 1.454252, Accuracy 0.500000\n","Batch 22077, Loss 2.378453, Accuracy 0.218750\n","Batch 22078, Loss 1.964341, Accuracy 0.531250\n","Batch 22079, Loss 1.981682, Accuracy 0.437500\n","Batch 22080, Loss 2.047085, Accuracy 0.406250\n","Batch 22081, Loss 1.654921, Accuracy 0.500000\n","Batch 22082, Loss 1.787028, Accuracy 0.437500\n","Batch 22083, Loss 1.920267, Accuracy 0.562500\n","Batch 22084, Loss 2.244250, Accuracy 0.375000\n","Batch 22085, Loss 2.579364, Accuracy 0.281250\n","Batch 22086, Loss 1.992452, Accuracy 0.437500\n","Batch 22087, Loss 2.303418, Accuracy 0.375000\n","Batch 22088, Loss 2.163781, Accuracy 0.343750\n","Batch 22089, Loss 2.356617, Accuracy 0.250000\n","Batch 22090, Loss 1.986188, Accuracy 0.343750\n","Batch 22091, Loss 2.141252, Accuracy 0.218750\n","Batch 22092, Loss 1.829770, Accuracy 0.343750\n","Batch 22093, Loss 1.523283, Accuracy 0.468750\n","Batch 22094, Loss 1.811389, Accuracy 0.218750\n","Batch 22095, Loss 1.657800, Accuracy 0.312500\n","Batch 22096, Loss 1.698952, Accuracy 0.218750\n","Batch 22097, Loss 1.394624, Accuracy 0.312500\n","Batch 22098, Loss 1.480210, Accuracy 0.218750\n","Batch 22099, Loss 1.309365, Accuracy 0.468750\n","Batch 22100, Loss 1.169540, Accuracy 0.625000\n","Batch 22101, Loss 1.476379, Accuracy 0.437500\n","Batch 22102, Loss 1.883212, Accuracy 0.468750\n","Batch 22103, Loss 1.843086, Accuracy 0.468750\n","Batch 22104, Loss 1.790659, Accuracy 0.500000\n","Batch 22105, Loss 1.839690, Accuracy 0.406250\n","Batch 22106, Loss 1.834646, Accuracy 0.468750\n","Batch 22107, Loss 1.757671, Accuracy 0.500000\n","Batch 22108, Loss 1.700551, Accuracy 0.531250\n","Batch 22109, Loss 1.928327, Accuracy 0.281250\n","Batch 22110, Loss 1.890707, Accuracy 0.343750\n","Batch 22111, Loss 1.977216, Accuracy 0.343750\n","Batch 22112, Loss 1.811035, Accuracy 0.468750\n","Batch 22113, Loss 1.794364, Accuracy 0.343750\n","Batch 22114, Loss 1.854535, Accuracy 0.406250\n","Batch 22115, Loss 1.549242, Accuracy 0.500000\n","Batch 22116, Loss 1.700421, Accuracy 0.375000\n","Batch 22117, Loss 1.920296, Accuracy 0.281250\n","Batch 22118, Loss 1.606596, Accuracy 0.406250\n","Batch 22119, Loss 1.468898, Accuracy 0.312500\n","Batch 22120, Loss 1.454443, Accuracy 0.312500\n","Batch 22121, Loss 1.431723, Accuracy 0.312500\n","Batch 22122, Loss 1.342718, Accuracy 0.343750\n","Batch 22123, Loss 1.244920, Accuracy 0.593750\n","Batch 22124, Loss 1.390497, Accuracy 0.437500\n","Batch 22125, Loss 1.922573, Accuracy 0.500000\n","Batch 22126, Loss 1.577751, Accuracy 0.500000\n","Batch 22127, Loss 1.679797, Accuracy 0.500000\n","Batch 22128, Loss 1.813229, Accuracy 0.343750\n","Batch 22129, Loss 1.642252, Accuracy 0.562500\n","Batch 22130, Loss 2.060775, Accuracy 0.468750\n","Batch 22131, Loss 2.087799, Accuracy 0.437500\n","Batch 22132, Loss 1.862480, Accuracy 0.500000\n","Batch 22133, Loss 1.924088, Accuracy 0.375000\n","Batch 22134, Loss 2.073743, Accuracy 0.312500\n","Batch 22135, Loss 1.652164, Accuracy 0.562500\n","Batch 22136, Loss 1.913637, Accuracy 0.218750\n","Batch 22137, Loss 1.650050, Accuracy 0.468750\n","Batch 22138, Loss 1.648014, Accuracy 0.343750\n","Batch 22139, Loss 1.660397, Accuracy 0.375000\n","Batch 22140, Loss 1.687194, Accuracy 0.406250\n","Batch 22141, Loss 1.646243, Accuracy 0.437500\n","Batch 22142, Loss 1.776846, Accuracy 0.343750\n","Batch 22143, Loss 1.409886, Accuracy 0.531250\n","Batch 22144, Loss 1.737744, Accuracy 0.218750\n","Batch 22145, Loss 1.526953, Accuracy 0.281250\n","Batch 22146, Loss 1.451730, Accuracy 0.281250\n","Batch 22147, Loss 1.425245, Accuracy 0.187500\n","Batch 22148, Loss 1.328595, Accuracy 0.406250\n","Batch 22149, Loss 1.713345, Accuracy 0.156250\n","Batch 22150, Loss 1.463541, Accuracy 0.468750\n","Batch 22151, Loss 1.335112, Accuracy 0.593750\n","Batch 22152, Loss 1.313724, Accuracy 0.562500\n","Batch 22153, Loss 1.135288, Accuracy 0.500000\n","Batch 22154, Loss 1.285143, Accuracy 0.718750\n","Batch 22155, Loss 1.054964, Accuracy 0.656250\n","Batch 22156, Loss 1.151440, Accuracy 0.656250\n","Batch 22157, Loss 1.376651, Accuracy 0.562500\n","Batch 22158, Loss 1.904449, Accuracy 0.375000\n","Batch 22159, Loss 1.114934, Accuracy 0.562500\n","Batch 22160, Loss 1.243831, Accuracy 0.625000\n","Batch 22161, Loss 1.414241, Accuracy 0.468750\n","Batch 22162, Loss 1.266096, Accuracy 0.437500\n","Batch 22163, Loss 1.810982, Accuracy 0.375000\n","Batch 22164, Loss 1.449090, Accuracy 0.437500\n","Batch 22165, Loss 1.495078, Accuracy 0.406250\n","Batch 22166, Loss 1.612741, Accuracy 0.406250\n","Batch 22167, Loss 1.568908, Accuracy 0.500000\n","Batch 22168, Loss 1.368726, Accuracy 0.437500\n","Batch 22169, Loss 1.184369, Accuracy 0.562500\n","Batch 22170, Loss 1.422714, Accuracy 0.531250\n","Batch 22171, Loss 1.271829, Accuracy 0.656250\n","Batch 22172, Loss 1.245191, Accuracy 0.562500\n","Batch 22173, Loss 1.293566, Accuracy 0.562500\n","Batch 22174, Loss 1.333203, Accuracy 0.312500\n","Batch 22175, Loss 1.388938, Accuracy 0.375000\n","Batch 22176, Loss 1.313573, Accuracy 0.531250\n","Batch 22177, Loss 2.682914, Accuracy 0.343750\n","Batch 22178, Loss 4.680383, Accuracy 0.000000\n","Batch 22179, Loss 4.168683, Accuracy 0.000000\n","Batch 22180, Loss 3.605666, Accuracy 0.000000\n","Batch 22181, Loss 3.123011, Accuracy 0.000000\n","Batch 22182, Loss 2.646019, Accuracy 0.000000\n","Batch 22183, Loss 2.129180, Accuracy 0.000000\n","Batch 22184, Loss 1.713017, Accuracy 0.750000\n","Batch 22185, Loss 1.527975, Accuracy 0.500000\n","Batch 22186, Loss 1.365676, Accuracy 0.468750\n","Batch 22187, Loss 1.263228, Accuracy 0.468750\n","Batch 22188, Loss 1.209134, Accuracy 0.406250\n","Batch 22189, Loss 1.165297, Accuracy 0.437500\n","Batch 22190, Loss 1.145060, Accuracy 0.281250\n","Batch 22191, Loss 1.112674, Accuracy 0.531250\n","Batch 22192, Loss 1.104998, Accuracy 0.562500\n","Batch 22193, Loss 1.097560, Accuracy 0.656250\n","Batch 22194, Loss 1.090255, Accuracy 0.593750\n","Batch 22195, Loss 1.083051, Accuracy 0.562500\n","Batch 22196, Loss 1.136034, Accuracy 0.468750\n","Batch 22197, Loss 1.130225, Accuracy 0.437500\n","Batch 22198, Loss 1.147465, Accuracy 0.500000\n","Batch 22199, Loss 1.164790, Accuracy 0.562500\n","Batch 22200, Loss 1.284931, Accuracy 0.406250\n","Batch except\n","Batch except\n","Batch except\n","=================================================\n","Test, Loss 3.337591, Accuracy 0.083333\n","=================================================\n","Batch 22201, Loss 1.213616, Accuracy 0.500000\n","Batch 22202, Loss 1.182113, Accuracy 0.468750\n","Batch 22203, Loss 1.263166, Accuracy 0.437500\n","Batch 22204, Loss 1.388273, Accuracy 0.250000\n","Batch 22205, Loss 1.186387, Accuracy 0.531250\n","Batch 22206, Loss 1.232495, Accuracy 0.343750\n","Batch 22207, Loss 1.263539, Accuracy 0.468750\n","Batch 22208, Loss 1.433892, Accuracy 0.312500\n","Batch 22209, Loss 1.287591, Accuracy 0.406250\n","Batch 22210, Loss 1.336042, Accuracy 0.218750\n","Batch 22211, Loss 1.212229, Accuracy 0.375000\n","Batch 22212, Loss 1.461951, Accuracy 0.218750\n","Batch 22213, Loss 1.391620, Accuracy 0.312500\n","Batch 22214, Loss 1.293742, Accuracy 0.343750\n","Batch 22215, Loss 1.394264, Accuracy 0.312500\n","Batch 22216, Loss 1.263751, Accuracy 0.343750\n","Batch 22217, Loss 1.379753, Accuracy 0.281250\n","Batch 22218, Loss 1.277419, Accuracy 0.406250\n","Batch 22219, Loss 1.370063, Accuracy 0.312500\n","Batch 22220, Loss 1.298346, Accuracy 0.312500\n","Batch 22221, Loss 1.373271, Accuracy 0.250000\n","Batch 22222, Loss 1.378886, Accuracy 0.281250\n","Batch 22223, Loss 1.612773, Accuracy 0.156250\n","Batch 22224, Loss 1.452089, Accuracy 0.250000\n","Batch 22225, Loss 1.600184, Accuracy 0.156250\n","Batch 22226, Loss 1.610840, Accuracy 0.187500\n","Batch 22227, Loss 1.613408, Accuracy 0.125000\n","Batch 22228, Loss 1.718503, Accuracy 0.125000\n","Batch 22229, Loss 1.703801, Accuracy 0.093750\n","Batch 22230, Loss 1.708910, Accuracy 0.218750\n","Batch 22231, Loss 1.653382, Accuracy 0.375000\n","Batch 22232, Loss 1.800419, Accuracy 0.125000\n","Batch 22233, Loss 1.711961, Accuracy 0.250000\n","Batch 22234, Loss 1.997940, Accuracy 0.125000\n","Batch 22235, Loss 1.965336, Accuracy 0.406250\n","Batch 22236, Loss 1.747904, Accuracy 0.437500\n","Batch 22237, Loss 2.123467, Accuracy 0.250000\n","Batch 22238, Loss 1.632967, Accuracy 0.375000\n","Batch 22239, Loss 1.662684, Accuracy 0.375000\n","Batch 22240, Loss 2.036486, Accuracy 0.156250\n","Batch 22241, Loss 1.918430, Accuracy 0.281250\n","Batch 22242, Loss 1.762239, Accuracy 0.343750\n","Batch 22243, Loss 1.980041, Accuracy 0.187500\n","Batch 22244, Loss 1.921426, Accuracy 0.187500\n","Batch 22245, Loss 1.640450, Accuracy 0.375000\n","Batch 22246, Loss 1.835693, Accuracy 0.187500\n","Batch 22247, Loss 1.497824, Accuracy 0.406250\n","Batch 22248, Loss 1.453907, Accuracy 0.406250\n","Batch 22249, Loss 1.595051, Accuracy 0.312500\n","Batch 22250, Loss 1.747655, Accuracy 0.218750\n","Batch 22251, Loss 1.530836, Accuracy 0.343750\n","Batch 22252, Loss 1.611460, Accuracy 0.375000\n","Batch 22253, Loss 1.620749, Accuracy 0.250000\n","Batch 22254, Loss 1.632794, Accuracy 0.218750\n","Batch 22255, Loss 1.555489, Accuracy 0.218750\n","Batch 22256, Loss 1.892105, Accuracy 0.093750\n","Batch 22257, Loss 1.587888, Accuracy 0.531250\n","Batch 22258, Loss 1.685793, Accuracy 0.343750\n","Batch 22259, Loss 1.568799, Accuracy 0.375000\n","Batch 22260, Loss 1.815189, Accuracy 0.281250\n","Batch 22261, Loss 1.401068, Accuracy 0.437500\n","Batch 22262, Loss 1.788092, Accuracy 0.406250\n","Batch 22263, Loss 1.381715, Accuracy 0.375000\n","Batch 22264, Loss 1.511877, Accuracy 0.437500\n","Batch 22265, Loss 1.282046, Accuracy 0.375000\n","Batch 22266, Loss 1.285043, Accuracy 0.437500\n","Batch 22267, Loss 1.141161, Accuracy 0.281250\n","Batch 22268, Loss 1.247046, Accuracy 0.593750\n","Batch 22269, Loss 1.266012, Accuracy 0.625000\n","Batch 22270, Loss 1.421513, Accuracy 0.437500\n","Batch 22271, Loss 1.196430, Accuracy 0.562500\n","Batch 22272, Loss 1.154318, Accuracy 0.625000\n","Batch 22273, Loss 1.630280, Accuracy 0.468750\n","Batch 22274, Loss 1.763784, Accuracy 0.375000\n","Batch 22275, Loss 1.643754, Accuracy 0.437500\n","Batch 22276, Loss 1.709114, Accuracy 0.406250\n","Batch 22277, Loss 1.944108, Accuracy 0.250000\n","Batch 22278, Loss 1.894337, Accuracy 0.312500\n","Batch 22279, Loss 1.838550, Accuracy 0.281250\n","Batch 22280, Loss 1.780532, Accuracy 0.406250\n","Batch 22281, Loss 1.636332, Accuracy 0.375000\n","Batch 22282, Loss 1.612507, Accuracy 0.312500\n","Batch 22283, Loss 1.601789, Accuracy 0.343750\n","Batch 22284, Loss 1.275009, Accuracy 0.500000\n","Batch 22285, Loss 1.477608, Accuracy 0.406250\n","Batch 22286, Loss 1.496787, Accuracy 0.281250\n","Batch 22287, Loss 1.660089, Accuracy 0.187500\n","Batch 22288, Loss 1.569510, Accuracy 0.281250\n","Batch 22289, Loss 1.220794, Accuracy 0.562500\n","Batch 22290, Loss 1.260031, Accuracy 0.593750\n","Batch 22291, Loss 0.936413, Accuracy 0.687500\n","Batch 22292, Loss 1.377776, Accuracy 0.500000\n","Batch 22293, Loss 1.564929, Accuracy 0.437500\n","Batch 22294, Loss 1.470586, Accuracy 0.531250\n","Batch 22295, Loss 2.182293, Accuracy 0.218750\n","Batch 22296, Loss 1.342563, Accuracy 0.625000\n","Batch 22297, Loss 1.405977, Accuracy 0.562500\n","Batch 22298, Loss 1.830156, Accuracy 0.375000\n","Batch 22299, Loss 1.738642, Accuracy 0.406250\n","Batch 22300, Loss 1.924587, Accuracy 0.312500\n","Batch 22301, Loss 1.803962, Accuracy 0.343750\n","Batch 22302, Loss 1.728704, Accuracy 0.343750\n","Batch 22303, Loss 1.546503, Accuracy 0.437500\n","Batch 22304, Loss 1.641663, Accuracy 0.343750\n","Batch 22305, Loss 1.422582, Accuracy 0.437500\n","Batch 22306, Loss 1.626684, Accuracy 0.343750\n","Batch 22307, Loss 1.403939, Accuracy 0.437500\n","Batch 22308, Loss 1.647948, Accuracy 0.156250\n","Batch 22309, Loss 1.525130, Accuracy 0.281250\n","Batch 22310, Loss 1.377428, Accuracy 0.312500\n","Batch 22311, Loss 1.172856, Accuracy 0.562500\n","Batch 22312, Loss 1.391237, Accuracy 0.531250\n","Batch 22313, Loss 1.171742, Accuracy 0.625000\n","Batch 22314, Loss 1.578547, Accuracy 0.406250\n","Batch 22315, Loss 1.483117, Accuracy 0.406250\n","Batch 22316, Loss 2.197996, Accuracy 0.187500\n","Batch 22317, Loss 1.498645, Accuracy 0.437500\n","Batch 22318, Loss 2.113512, Accuracy 0.375000\n","Batch 22319, Loss 2.520596, Accuracy 0.312500\n","Batch 22320, Loss 1.990729, Accuracy 0.468750\n","Batch 22321, Loss 2.162401, Accuracy 0.375000\n","Batch 22322, Loss 2.245372, Accuracy 0.375000\n","Batch 22323, Loss 2.028484, Accuracy 0.437500\n","Batch 22324, Loss 2.387122, Accuracy 0.312500\n","Batch 22325, Loss 2.335987, Accuracy 0.312500\n","Batch 22326, Loss 2.256851, Accuracy 0.187500\n","Batch 22327, Loss 1.538052, Accuracy 0.593750\n","Batch 22328, Loss 1.847151, Accuracy 0.343750\n","Batch 22329, Loss 1.695353, Accuracy 0.343750\n","Batch 22330, Loss 1.552379, Accuracy 0.312500\n","Batch 22331, Loss 1.602772, Accuracy 0.312500\n","Batch 22332, Loss 1.640016, Accuracy 0.375000\n","Batch 22333, Loss 1.242378, Accuracy 0.500000\n","Batch 22334, Loss 1.393021, Accuracy 0.562500\n","Batch 22335, Loss 1.499556, Accuracy 0.343750\n","Batch 22336, Loss 1.523013, Accuracy 0.375000\n","Batch 22337, Loss 1.508630, Accuracy 0.500000\n","Batch 22338, Loss 1.171100, Accuracy 0.250000\n","Batch 22339, Loss 1.399131, Accuracy 0.250000\n","Batch 22340, Loss 1.588651, Accuracy 0.468750\n","Batch 22341, Loss 1.618639, Accuracy 0.531250\n","Batch 22342, Loss 1.741758, Accuracy 0.406250\n","Batch 22343, Loss 2.558609, Accuracy 0.406250\n","Batch 22344, Loss 1.637236, Accuracy 0.593750\n","Batch 22345, Loss 1.568882, Accuracy 0.562500\n","Batch 22346, Loss 1.653558, Accuracy 0.500000\n","Batch 22347, Loss 1.997627, Accuracy 0.312500\n","Batch 22348, Loss 2.018755, Accuracy 0.312500\n","Batch 22349, Loss 1.944101, Accuracy 0.343750\n","Batch 22350, Loss 1.807534, Accuracy 0.375000\n","Batch 22351, Loss 1.684999, Accuracy 0.437500\n","Batch 22352, Loss 1.731235, Accuracy 0.312500\n","Batch 22353, Loss 1.883676, Accuracy 0.125000\n","Batch 22354, Loss 1.397888, Accuracy 0.593750\n","Batch 22355, Loss 1.736087, Accuracy 0.312500\n","Batch 22356, Loss 1.423643, Accuracy 0.437500\n","Batch 22357, Loss 1.319618, Accuracy 0.500000\n","Batch 22358, Loss 1.811511, Accuracy 0.343750\n","Batch 22359, Loss 1.501927, Accuracy 0.437500\n","Batch 22360, Loss 1.435986, Accuracy 0.531250\n","Batch 22361, Loss 1.353558, Accuracy 0.500000\n","Batch 22362, Loss 1.350845, Accuracy 0.437500\n","Batch 22363, Loss 1.142230, Accuracy 0.562500\n","Batch 22364, Loss 1.817513, Accuracy 0.500000\n","Batch 22365, Loss 1.770830, Accuracy 0.593750\n","Batch 22366, Loss 1.689521, Accuracy 0.468750\n","Batch 22367, Loss 1.983872, Accuracy 0.468750\n","Batch 22368, Loss 1.447009, Accuracy 0.593750\n","Batch 22369, Loss 1.747803, Accuracy 0.468750\n","Batch 22370, Loss 1.485477, Accuracy 0.468750\n","Batch 22371, Loss 1.846845, Accuracy 0.343750\n","Batch 22372, Loss 1.577127, Accuracy 0.375000\n","Batch 22373, Loss 1.683829, Accuracy 0.312500\n","Batch 22374, Loss 1.570863, Accuracy 0.437500\n","Batch 22375, Loss 1.407097, Accuracy 0.375000\n","Batch 22376, Loss 1.413740, Accuracy 0.375000\n","Batch 22377, Loss 1.405687, Accuracy 0.468750\n","Batch 22378, Loss 1.640371, Accuracy 0.312500\n","Batch 22379, Loss 1.903098, Accuracy 0.250000\n","Batch 22380, Loss 1.405161, Accuracy 0.437500\n","Batch 22381, Loss 1.406876, Accuracy 0.343750\n","Batch 22382, Loss 1.500498, Accuracy 0.437500\n","Batch 22383, Loss 1.446592, Accuracy 0.250000\n","Batch 22384, Loss 1.101098, Accuracy 0.656250\n","Batch 22385, Loss 1.641317, Accuracy 0.343750\n","Batch 22386, Loss 1.371055, Accuracy 0.531250\n","Batch 22387, Loss 1.553112, Accuracy 0.562500\n","Batch 22388, Loss 1.107444, Accuracy 0.625000\n","Batch 22389, Loss 1.198883, Accuracy 0.531250\n","Batch 22390, Loss 1.069176, Accuracy 0.656250\n","Batch 22391, Loss 1.404038, Accuracy 0.500000\n","Batch 22392, Loss 1.375057, Accuracy 0.531250\n","Batch 22393, Loss 1.124854, Accuracy 0.593750\n","Batch 22394, Loss 1.149088, Accuracy 0.656250\n","Batch 22395, Loss 1.375066, Accuracy 0.437500\n","Batch 22396, Loss 1.186768, Accuracy 0.656250\n","Batch 22397, Loss 1.263203, Accuracy 0.562500\n","Batch 22398, Loss 1.363867, Accuracy 0.437500\n","Batch 22399, Loss 1.411335, Accuracy 0.406250\n","Batch 22400, Loss 1.224553, Accuracy 0.593750\n","Batch except\n","Batch except\n","Batch except\n","=================================================\n","Test, Loss 3.537443, Accuracy 0.166667\n","=================================================\n","Batch 22401, Loss 1.057949, Accuracy 0.593750\n","Batch 22402, Loss 1.234851, Accuracy 0.500000\n","Batch 22403, Loss 1.279608, Accuracy 0.468750\n","Batch 22404, Loss 1.496646, Accuracy 0.343750\n","Batch 22405, Loss 1.816140, Accuracy 0.468750\n","Batch 22406, Loss 1.538563, Accuracy 0.312500\n","Batch 22407, Loss 1.394853, Accuracy 0.500000\n","Batch 22408, Loss 1.229135, Accuracy 0.562500\n","Batch 22409, Loss 1.288209, Accuracy 0.500000\n","Batch 22410, Loss 1.224494, Accuracy 0.468750\n","Batch 22411, Loss 1.453178, Accuracy 0.625000\n","Batch 22412, Loss 1.274057, Accuracy 0.468750\n","Batch 22413, Loss 1.492084, Accuracy 0.531250\n","Batch 22414, Loss 1.577393, Accuracy 0.375000\n","Batch 22415, Loss 1.445535, Accuracy 0.437500\n","Batch 22416, Loss 5.819007, Accuracy 0.031250\n","Batch 22417, Loss 5.212150, Accuracy 0.000000\n","Batch 22418, Loss 3.995706, Accuracy 0.000000\n","Batch 22419, Loss 2.749500, Accuracy 0.000000\n","Batch 22420, Loss 1.832451, Accuracy 0.656250\n","Batch 22421, Loss 1.446645, Accuracy 0.375000\n","Batch 22422, Loss 1.346372, Accuracy 0.375000\n","Batch 22423, Loss 1.331756, Accuracy 0.500000\n","Batch 22424, Loss 1.372054, Accuracy 0.406250\n","Batch 22425, Loss 1.340083, Accuracy 0.531250\n","Batch 22426, Loss 1.313966, Accuracy 0.500000\n","Batch 22427, Loss 1.283219, Accuracy 0.437500\n","Batch 22428, Loss 1.230860, Accuracy 0.468750\n","Batch 22429, Loss 1.171540, Accuracy 0.593750\n","Batch 22430, Loss 1.142200, Accuracy 0.500000\n","Batch 22431, Loss 1.107779, Accuracy 0.562500\n","Batch 22432, Loss 1.081829, Accuracy 0.500000\n","Batch 22433, Loss 1.057851, Accuracy 0.468750\n","Batch 22434, Loss 1.038001, Accuracy 0.531250\n","Batch 22435, Loss 1.094386, Accuracy 0.437500\n","Batch 22436, Loss 1.166917, Accuracy 0.312500\n","Batch 22437, Loss 1.089285, Accuracy 0.343750\n","Batch 22438, Loss 1.060917, Accuracy 0.593750\n","Batch 22439, Loss 1.193451, Accuracy 0.406250\n","Batch 22440, Loss 1.242148, Accuracy 0.312500\n","Batch 22441, Loss 1.367208, Accuracy 0.281250\n","Batch 22442, Loss 1.495320, Accuracy 0.187500\n","Batch 22443, Loss 1.352147, Accuracy 0.250000\n","Batch 22444, Loss 1.292444, Accuracy 0.343750\n","Batch 22445, Loss 1.322088, Accuracy 0.312500\n","Batch 22446, Loss 1.581590, Accuracy 0.218750\n","Batch 22447, Loss 1.369319, Accuracy 0.406250\n","Batch 22448, Loss 1.423937, Accuracy 0.312500\n","Batch 22449, Loss 1.264081, Accuracy 0.468750\n","Batch 22450, Loss 1.446067, Accuracy 0.312500\n","Batch 22451, Loss 1.303238, Accuracy 0.375000\n","Batch 22452, Loss 1.311248, Accuracy 0.406250\n","Batch 22453, Loss 1.218531, Accuracy 0.437500\n","Batch 22454, Loss 1.453853, Accuracy 0.281250\n","Batch 22455, Loss 1.323612, Accuracy 0.406250\n","Batch 22456, Loss 1.330661, Accuracy 0.281250\n","Batch 22457, Loss 1.307979, Accuracy 0.312500\n","Batch 22458, Loss 1.221487, Accuracy 0.375000\n","Batch 22459, Loss 1.288961, Accuracy 0.406250\n","Batch 22460, Loss 1.312076, Accuracy 0.312500\n","Batch 22461, Loss 1.390047, Accuracy 0.218750\n","Batch 22462, Loss 1.308654, Accuracy 0.187500\n","Batch 22463, Loss 1.420282, Accuracy 0.281250\n","Batch 22464, Loss 1.381008, Accuracy 0.343750\n","Batch 22465, Loss 1.569508, Accuracy 0.093750\n","Batch 22466, Loss 1.444597, Accuracy 0.187500\n","Batch 22467, Loss 1.631980, Accuracy 0.218750\n","Batch 22468, Loss 1.532253, Accuracy 0.281250\n","Batch 22469, Loss 1.925932, Accuracy 0.125000\n","Batch 22470, Loss 1.668088, Accuracy 0.468750\n","Batch 22471, Loss 1.669278, Accuracy 0.468750\n","Batch 22472, Loss 1.923834, Accuracy 0.343750\n","Batch 22473, Loss 1.926477, Accuracy 0.343750\n","Batch 22474, Loss 2.085936, Accuracy 0.250000\n","Batch 22475, Loss 1.649882, Accuracy 0.437500\n","Batch 22476, Loss 2.094266, Accuracy 0.312500\n","Batch 22477, Loss 1.684172, Accuracy 0.312500\n","Batch 22478, Loss 1.728768, Accuracy 0.375000\n","Batch 22479, Loss 2.020329, Accuracy 0.156250\n","Batch 22480, Loss 1.416383, Accuracy 0.468750\n","Batch 22481, Loss 1.717604, Accuracy 0.281250\n","Batch 22482, Loss 1.924160, Accuracy 0.156250\n","Batch 22483, Loss 1.714529, Accuracy 0.250000\n","Batch 22484, Loss 1.461718, Accuracy 0.343750\n","Batch 22485, Loss 1.335678, Accuracy 0.406250\n","Batch 22486, Loss 1.612536, Accuracy 0.187500\n","Batch 22487, Loss 1.541202, Accuracy 0.218750\n","Batch 22488, Loss 1.484836, Accuracy 0.375000\n","Batch 22489, Loss 1.856088, Accuracy 0.187500\n","Batch 22490, Loss 1.544183, Accuracy 0.187500\n","Batch 22491, Loss 1.463644, Accuracy 0.250000\n","Batch 22492, Loss 1.226590, Accuracy 0.500000\n","Batch 22493, Loss 1.756223, Accuracy 0.437500\n","Batch 22494, Loss 1.853443, Accuracy 0.343750\n","Batch 22495, Loss 1.902120, Accuracy 0.312500\n","Batch 22496, Loss 2.040142, Accuracy 0.375000\n","Batch 22497, Loss 1.993124, Accuracy 0.312500\n","Batch 22498, Loss 2.001868, Accuracy 0.312500\n","Batch 22499, Loss 1.659726, Accuracy 0.406250\n","Batch 22500, Loss 1.877238, Accuracy 0.312500\n","Batch 22501, Loss 1.747449, Accuracy 0.406250\n","Batch 22502, Loss 1.787107, Accuracy 0.343750\n","Batch 22503, Loss 1.875260, Accuracy 0.250000\n","Batch 22504, Loss 1.818040, Accuracy 0.218750\n","Batch 22505, Loss 1.626987, Accuracy 0.343750\n","Batch 22506, Loss 1.613573, Accuracy 0.312500\n","Batch 22507, Loss 1.556751, Accuracy 0.281250\n","Batch 22508, Loss 1.818661, Accuracy 0.218750\n","Batch 22509, Loss 1.606378, Accuracy 0.281250\n","Batch 22510, Loss 1.485685, Accuracy 0.281250\n","Batch 22511, Loss 1.509236, Accuracy 0.187500\n","Batch 22512, Loss 1.541447, Accuracy 0.218750\n","Batch 22513, Loss 1.867651, Accuracy 0.406250\n","Batch 22514, Loss 1.486728, Accuracy 0.468750\n","Batch 22515, Loss 1.912392, Accuracy 0.375000\n","Batch 22516, Loss 1.632459, Accuracy 0.343750\n","Batch 22517, Loss 1.492119, Accuracy 0.437500\n","Batch 22518, Loss 1.816142, Accuracy 0.281250\n","Batch 22519, Loss 1.829524, Accuracy 0.281250\n","Batch 22520, Loss 1.350678, Accuracy 0.500000\n","Batch 22521, Loss 1.952307, Accuracy 0.250000\n","Batch 22522, Loss 1.860907, Accuracy 0.281250\n","Batch 22523, Loss 1.579924, Accuracy 0.406250\n","Batch 22524, Loss 1.495203, Accuracy 0.375000\n","Batch 22525, Loss 1.581326, Accuracy 0.343750\n","Batch 22526, Loss 1.750572, Accuracy 0.156250\n","Batch 22527, Loss 1.574138, Accuracy 0.281250\n","Batch 22528, Loss 1.656923, Accuracy 0.187500\n","Batch 22529, Loss 1.514784, Accuracy 0.312500\n","Batch 22530, Loss 1.504022, Accuracy 0.187500\n","Batch 22531, Loss 1.674621, Accuracy 0.281250\n","Batch 22532, Loss 1.549849, Accuracy 0.093750\n","Batch 22533, Loss 1.734419, Accuracy 0.187500\n","Batch 22534, Loss 1.546307, Accuracy 0.187500\n","Batch 22535, Loss 1.774228, Accuracy 0.468750\n","Batch 22536, Loss 1.623769, Accuracy 0.562500\n","Batch 22537, Loss 1.906051, Accuracy 0.468750\n","Batch 22538, Loss 1.525308, Accuracy 0.437500\n","Batch 22539, Loss 1.953889, Accuracy 0.343750\n","Batch 22540, Loss 1.818225, Accuracy 0.312500\n","Batch 22541, Loss 1.935396, Accuracy 0.312500\n","Batch 22542, Loss 1.932311, Accuracy 0.187500\n","Batch 22543, Loss 1.670426, Accuracy 0.375000\n","Batch 22544, Loss 1.789326, Accuracy 0.312500\n","Batch 22545, Loss 1.721877, Accuracy 0.312500\n","Batch 22546, Loss 1.732074, Accuracy 0.218750\n","Batch 22547, Loss 1.639813, Accuracy 0.250000\n","Batch 22548, Loss 1.479403, Accuracy 0.312500\n","Batch 22549, Loss 1.626361, Accuracy 0.312500\n","Batch 22550, Loss 1.551817, Accuracy 0.281250\n","Batch 22551, Loss 1.403888, Accuracy 0.156250\n","Batch 22552, Loss 1.501901, Accuracy 0.406250\n","Batch 22553, Loss 1.262538, Accuracy 0.562500\n","Batch 22554, Loss 1.766010, Accuracy 0.562500\n","Batch 22555, Loss 1.280964, Accuracy 0.500000\n","Batch 22556, Loss 1.730417, Accuracy 0.468750\n","Batch 22557, Loss 1.666825, Accuracy 0.468750\n","Batch 22558, Loss 2.106254, Accuracy 0.406250\n","Batch 22559, Loss 2.286824, Accuracy 0.406250\n","Batch 22560, Loss 2.248407, Accuracy 0.406250\n","Batch 22561, Loss 1.987394, Accuracy 0.468750\n","Batch 22562, Loss 2.211135, Accuracy 0.281250\n","Batch 22563, Loss 2.190534, Accuracy 0.281250\n","Batch 22564, Loss 2.166975, Accuracy 0.375000\n","Batch 22565, Loss 1.511638, Accuracy 0.531250\n","Batch 22566, Loss 2.197993, Accuracy 0.250000\n","Batch 22567, Loss 1.931987, Accuracy 0.468750\n","Batch 22568, Loss 2.126613, Accuracy 0.281250\n","Batch 22569, Loss 2.053151, Accuracy 0.343750\n","Batch 22570, Loss 2.158042, Accuracy 0.250000\n","Batch 22571, Loss 1.928211, Accuracy 0.281250\n","Batch 22572, Loss 1.998590, Accuracy 0.156250\n","Batch 22573, Loss 1.743430, Accuracy 0.343750\n","Batch 22574, Loss 1.806144, Accuracy 0.281250\n","Batch 22575, Loss 1.576971, Accuracy 0.312500\n","Batch 22576, Loss 1.679344, Accuracy 0.156250\n","Batch 22577, Loss 1.610680, Accuracy 0.312500\n","Batch 22578, Loss 1.438148, Accuracy 0.250000\n","Batch 22579, Loss 1.926647, Accuracy 0.500000\n","Batch 22580, Loss 1.966032, Accuracy 0.343750\n","Batch 22581, Loss 1.804518, Accuracy 0.343750\n","Batch 22582, Loss 2.194822, Accuracy 0.375000\n","Batch 22583, Loss 1.803232, Accuracy 0.500000\n","Batch 22584, Loss 1.747710, Accuracy 0.531250\n","Batch 22585, Loss 1.577352, Accuracy 0.500000\n","Batch 22586, Loss 1.777189, Accuracy 0.343750\n","Batch 22587, Loss 1.369304, Accuracy 0.562500\n","Batch 22588, Loss 1.682963, Accuracy 0.375000\n","Batch 22589, Loss 1.302783, Accuracy 0.562500\n","Batch 22590, Loss 1.576729, Accuracy 0.281250\n","Batch 22591, Loss 1.398024, Accuracy 0.500000\n","Batch 22592, Loss 1.383541, Accuracy 0.562500\n","Batch 22593, Loss 1.494254, Accuracy 0.375000\n","Batch 22594, Loss 1.512544, Accuracy 0.406250\n","Batch 22595, Loss 1.316679, Accuracy 0.406250\n","Batch 22596, Loss 1.614471, Accuracy 0.437500\n","Batch 22597, Loss 1.273868, Accuracy 0.531250\n","Batch 22598, Loss 1.628002, Accuracy 0.375000\n","Batch 22599, Loss 1.506102, Accuracy 0.500000\n","Batch 22600, Loss 1.138734, Accuracy 0.531250\n","Batch except\n","Batch except\n","Batch except\n","=================================================\n","Test, Loss 3.632286, Accuracy 0.177083\n","=================================================\n","Batch 22601, Loss 1.528116, Accuracy 0.406250\n","Batch 22602, Loss 1.432209, Accuracy 0.531250\n","Batch 22603, Loss 1.316621, Accuracy 0.593750\n","Batch 22604, Loss 1.685717, Accuracy 0.406250\n","Batch 22605, Loss 1.992710, Accuracy 0.343750\n","Batch 22606, Loss 2.479363, Accuracy 0.343750\n","Batch 22607, Loss 2.142222, Accuracy 0.437500\n","Batch 22608, Loss 2.015887, Accuracy 0.406250\n","Batch 22609, Loss 1.772312, Accuracy 0.437500\n","Batch 22610, Loss 1.648328, Accuracy 0.500000\n","Batch 22611, Loss 1.493474, Accuracy 0.500000\n","Batch 22612, Loss 1.614352, Accuracy 0.375000\n","Batch 22613, Loss 1.633488, Accuracy 0.406250\n","Batch 22614, Loss 1.512990, Accuracy 0.562500\n","Batch 22615, Loss 1.717499, Accuracy 0.375000\n","Batch 22616, Loss 1.604617, Accuracy 0.281250\n","Batch 22617, Loss 1.754145, Accuracy 0.250000\n","Batch 22618, Loss 1.600518, Accuracy 0.343750\n","Batch 22619, Loss 1.452407, Accuracy 0.281250\n","Batch 22620, Loss 1.468770, Accuracy 0.406250\n","Batch 22621, Loss 1.336192, Accuracy 0.593750\n","Batch 22622, Loss 1.488349, Accuracy 0.500000\n","Batch 22623, Loss 1.504789, Accuracy 0.593750\n","Batch 22624, Loss 1.535368, Accuracy 0.562500\n","Batch 22625, Loss 1.299572, Accuracy 0.468750\n","Batch 22626, Loss 1.056475, Accuracy 0.625000\n","Batch 22627, Loss 1.534988, Accuracy 0.343750\n","Batch 22628, Loss 1.149424, Accuracy 0.562500\n","Batch 22629, Loss 1.236860, Accuracy 0.500000\n","Batch 22630, Loss 1.688511, Accuracy 0.437500\n","Batch 22631, Loss 1.234366, Accuracy 0.500000\n","Batch 22632, Loss 1.033827, Accuracy 0.687500\n","Batch 22633, Loss 1.527466, Accuracy 0.531250\n","Batch 22634, Loss 1.134060, Accuracy 0.656250\n","Batch 22635, Loss 1.590172, Accuracy 0.468750\n","Batch 22636, Loss 1.431276, Accuracy 0.406250\n","Batch 22637, Loss 1.452154, Accuracy 0.437500\n","Batch 22638, Loss 1.357754, Accuracy 0.468750\n","Batch 22639, Loss 1.146666, Accuracy 0.625000\n","Batch 22640, Loss 0.985272, Accuracy 0.593750\n","Batch 22641, Loss 1.607972, Accuracy 0.468750\n","Batch 22642, Loss 1.244052, Accuracy 0.375000\n","Batch 22643, Loss 1.342662, Accuracy 0.468750\n","Batch 22644, Loss 1.319802, Accuracy 0.593750\n","Batch 22645, Loss 1.384849, Accuracy 0.468750\n","Batch 22646, Loss 1.416572, Accuracy 0.531250\n","Batch 22647, Loss 1.208967, Accuracy 0.593750\n","Batch 22648, Loss 1.486352, Accuracy 0.468750\n","Batch 22649, Loss 1.293120, Accuracy 0.531250\n","Batch 22650, Loss 1.244003, Accuracy 0.562500\n","Batch 22651, Loss 1.197600, Accuracy 0.500000\n","Batch 22652, Loss 1.321451, Accuracy 0.500000\n","Batch 22653, Loss 1.338076, Accuracy 0.500000\n","Batch 22654, Loss 3.167479, Accuracy 0.250000\n","Batch 22655, Loss 5.111496, Accuracy 0.000000\n","Batch 22656, Loss 4.492219, Accuracy 0.000000\n","Batch 22657, Loss 3.813940, Accuracy 0.000000\n","Batch 22658, Loss 3.173472, Accuracy 0.000000\n","Batch 22659, Loss 2.590278, Accuracy 0.000000\n","Batch 22660, Loss 2.052651, Accuracy 0.000000\n","Batch 22661, Loss 1.690698, Accuracy 0.531250\n","Batch 22662, Loss 1.470127, Accuracy 0.593750\n","Batch 22663, Loss 1.371628, Accuracy 0.562500\n","Batch 22664, Loss 1.344771, Accuracy 0.437500\n","Batch 22665, Loss 1.298172, Accuracy 0.531250\n","Batch 22666, Loss 1.283969, Accuracy 0.406250\n","Batch 22667, Loss 1.256979, Accuracy 0.500000\n","Batch 22668, Loss 1.240808, Accuracy 0.500000\n","Batch 22669, Loss 1.220134, Accuracy 0.531250\n","Batch 22670, Loss 1.199598, Accuracy 0.468750\n","Batch 22671, Loss 1.171840, Accuracy 0.531250\n","Batch 22672, Loss 1.142286, Accuracy 0.531250\n","Batch 22673, Loss 1.142185, Accuracy 0.437500\n","Batch 22674, Loss 1.169530, Accuracy 0.437500\n","Batch 22675, Loss 1.187725, Accuracy 0.375000\n","Batch 22676, Loss 1.106038, Accuracy 0.406250\n","Batch 22677, Loss 1.266416, Accuracy 0.187500\n","Batch 22678, Loss 1.253550, Accuracy 0.531250\n","Batch 22679, Loss 1.237143, Accuracy 0.343750\n","Batch 22680, Loss 1.358331, Accuracy 0.312500\n","Batch 22681, Loss 1.312803, Accuracy 0.281250\n","Batch 22682, Loss 1.428685, Accuracy 0.250000\n","Batch 22683, Loss 1.317082, Accuracy 0.375000\n","Batch 22684, Loss 1.405462, Accuracy 0.187500\n","Batch 22685, Loss 1.381044, Accuracy 0.250000\n","Batch 22686, Loss 1.427694, Accuracy 0.343750\n","Batch 22687, Loss 1.449308, Accuracy 0.218750\n","Batch 22688, Loss 1.707179, Accuracy 0.218750\n","Batch 22689, Loss 1.369950, Accuracy 0.281250\n","Batch 22690, Loss 1.401481, Accuracy 0.218750\n","Batch 22691, Loss 1.373538, Accuracy 0.343750\n","Batch 22692, Loss 1.288488, Accuracy 0.406250\n","Batch 22693, Loss 1.393528, Accuracy 0.343750\n","Batch 22694, Loss 1.361425, Accuracy 0.187500\n","Batch 22695, Loss 1.344984, Accuracy 0.218750\n","Batch 22696, Loss 1.281954, Accuracy 0.406250\n","Batch 22697, Loss 1.279103, Accuracy 0.343750\n","Batch 22698, Loss 1.257750, Accuracy 0.312500\n","Batch 22699, Loss 1.288835, Accuracy 0.281250\n","Batch 22700, Loss 1.329888, Accuracy 0.125000\n","Batch 22701, Loss 1.217020, Accuracy 0.562500\n","Batch 22702, Loss 1.314216, Accuracy 0.593750\n","Batch 22703, Loss 1.320951, Accuracy 0.406250\n","Batch 22704, Loss 1.506920, Accuracy 0.468750\n","Batch 22705, Loss 1.590012, Accuracy 0.281250\n","Batch 22706, Loss 1.504819, Accuracy 0.375000\n","Batch 22707, Loss 1.610138, Accuracy 0.312500\n","Batch 22708, Loss 1.578002, Accuracy 0.437500\n","Batch 22709, Loss 1.587679, Accuracy 0.281250\n","Batch 22710, Loss 1.468888, Accuracy 0.406250\n","Batch 22711, Loss 1.366518, Accuracy 0.437500\n","Batch 22712, Loss 1.571251, Accuracy 0.250000\n","Batch 22713, Loss 1.418522, Accuracy 0.437500\n","Batch 22714, Loss 1.748909, Accuracy 0.156250\n","Batch 22715, Loss 1.487804, Accuracy 0.343750\n","Batch 22716, Loss 1.444432, Accuracy 0.375000\n","Batch 22717, Loss 1.422330, Accuracy 0.343750\n","Batch 22718, Loss 1.416966, Accuracy 0.312500\n","Batch 22719, Loss 1.335962, Accuracy 0.406250\n","Batch 22720, Loss 1.375200, Accuracy 0.312500\n","Batch 22721, Loss 1.474550, Accuracy 0.218750\n","Batch 22722, Loss 1.428628, Accuracy 0.218750\n","Batch 22723, Loss 1.297454, Accuracy 0.343750\n","Batch 22724, Loss 1.465966, Accuracy 0.218750\n","Batch 22725, Loss 1.495984, Accuracy 0.218750\n","Batch 22726, Loss 1.509010, Accuracy 0.468750\n","Batch 22727, Loss 1.399587, Accuracy 0.562500\n","Batch 22728, Loss 1.366759, Accuracy 0.468750\n","Batch 22729, Loss 1.347440, Accuracy 0.562500\n","Batch 22730, Loss 1.601797, Accuracy 0.500000\n","Batch 22731, Loss 1.548461, Accuracy 0.468750\n","Batch 22732, Loss 1.675042, Accuracy 0.437500\n","Batch 22733, Loss 1.544930, Accuracy 0.375000\n","Batch 22734, Loss 1.625752, Accuracy 0.406250\n","Batch 22735, Loss 1.730052, Accuracy 0.312500\n","Batch 22736, Loss 1.706568, Accuracy 0.375000\n","Batch 22737, Loss 1.390493, Accuracy 0.500000\n","Batch 22738, Loss 1.629214, Accuracy 0.312500\n","Batch 22739, Loss 1.519286, Accuracy 0.437500\n","Batch 22740, Loss 1.390314, Accuracy 0.343750\n","Batch 22741, Loss 1.432359, Accuracy 0.375000\n","Batch 22742, Loss 1.281253, Accuracy 0.437500\n","Batch 22743, Loss 1.446028, Accuracy 0.250000\n","Batch 22744, Loss 1.519004, Accuracy 0.281250\n","Batch 22745, Loss 1.438449, Accuracy 0.156250\n","Batch 22746, Loss 1.596369, Accuracy 0.218750\n","Batch 22747, Loss 1.343004, Accuracy 0.250000\n","Batch 22748, Loss 1.082129, Accuracy 0.593750\n","Batch 22749, Loss 1.759042, Accuracy 0.406250\n","Batch 22750, Loss 1.333591, Accuracy 0.625000\n","Batch 22751, Loss 1.721746, Accuracy 0.500000\n","Batch 22752, Loss 1.314663, Accuracy 0.562500\n","Batch 22753, Loss 1.725074, Accuracy 0.468750\n","Batch 22754, Loss 1.758742, Accuracy 0.468750\n","Batch 22755, Loss 2.099502, Accuracy 0.312500\n","Batch 22756, Loss 1.931686, Accuracy 0.312500\n","Batch 22757, Loss 2.090560, Accuracy 0.125000\n","Batch 22758, Loss 1.514896, Accuracy 0.468750\n","Batch 22759, Loss 1.673532, Accuracy 0.312500\n","Batch 22760, Loss 1.464544, Accuracy 0.375000\n","Batch 22761, Loss 1.551366, Accuracy 0.406250\n","Batch 22762, Loss 1.613370, Accuracy 0.250000\n","Batch 22763, Loss 1.739832, Accuracy 0.187500\n","Batch 22764, Loss 1.675816, Accuracy 0.187500\n","Batch 22765, Loss 1.516435, Accuracy 0.281250\n","Batch 22766, Loss 1.642785, Accuracy 0.312500\n","Batch 22767, Loss 1.463120, Accuracy 0.437500\n","Batch 22768, Loss 1.703622, Accuracy 0.375000\n","Batch 22769, Loss 1.278074, Accuracy 0.562500\n","Batch 22770, Loss 1.621568, Accuracy 0.281250\n","Batch 22771, Loss 1.571352, Accuracy 0.437500\n","Batch 22772, Loss 1.612710, Accuracy 0.375000\n","Batch 22773, Loss 1.547834, Accuracy 0.531250\n","Batch 22774, Loss 1.679549, Accuracy 0.312500\n","Batch 22775, Loss 1.570627, Accuracy 0.468750\n","Batch 22776, Loss 1.788812, Accuracy 0.343750\n","Batch 22777, Loss 1.337473, Accuracy 0.593750\n","Batch 22778, Loss 1.388599, Accuracy 0.531250\n","Batch 22779, Loss 1.515047, Accuracy 0.468750\n","Batch 22780, Loss 1.765549, Accuracy 0.250000\n","Batch 22781, Loss 1.855439, Accuracy 0.312500\n","Batch 22782, Loss 1.529701, Accuracy 0.406250\n","Batch 22783, Loss 1.550261, Accuracy 0.218750\n","Batch 22784, Loss 1.524646, Accuracy 0.250000\n","Batch 22785, Loss 1.552315, Accuracy 0.281250\n","Batch 22786, Loss 1.447476, Accuracy 0.281250\n","Batch 22787, Loss 1.419174, Accuracy 0.312500\n","Batch 22788, Loss 1.531839, Accuracy 0.250000\n","Batch 22789, Loss 1.447126, Accuracy 0.187500\n","Batch 22790, Loss 1.392883, Accuracy 0.312500\n","Batch 22791, Loss 1.524199, Accuracy 0.156250\n","Batch 22792, Loss 1.472098, Accuracy 0.250000\n","Batch 22793, Loss 1.896107, Accuracy 0.250000\n","Batch 22794, Loss 1.701087, Accuracy 0.531250\n","Batch 22795, Loss 1.910214, Accuracy 0.562500\n","Batch 22796, Loss 2.082251, Accuracy 0.343750\n","Batch 22797, Loss 2.116222, Accuracy 0.500000\n","Batch 22798, Loss 2.649035, Accuracy 0.312500\n","Batch 22799, Loss 2.260115, Accuracy 0.343750\n","Batch 22800, Loss 1.685884, Accuracy 0.437500\n","Batch except\n","Batch except\n","Batch except\n","=================================================\n","Test, Loss 5.528260, Accuracy 0.072917\n","=================================================\n","Batch 22801, Loss 2.266471, Accuracy 0.343750\n","Batch 22802, Loss 2.017804, Accuracy 0.375000\n","Batch 22803, Loss 1.733166, Accuracy 0.531250\n","Batch 22804, Loss 2.267263, Accuracy 0.375000\n","Batch 22805, Loss 2.029013, Accuracy 0.281250\n","Batch 22806, Loss 1.986853, Accuracy 0.281250\n","Batch 22807, Loss 2.080227, Accuracy 0.281250\n","Batch 22808, Loss 2.098019, Accuracy 0.281250\n","Batch 22809, Loss 1.778658, Accuracy 0.468750\n","Batch 22810, Loss 2.177386, Accuracy 0.156250\n","Batch 22811, Loss 1.864100, Accuracy 0.281250\n","Batch 22812, Loss 1.878143, Accuracy 0.281250\n","Batch 22813, Loss 1.933003, Accuracy 0.218750\n","Batch 22814, Loss 1.761467, Accuracy 0.281250\n","Batch 22815, Loss 1.731913, Accuracy 0.281250\n","Batch 22816, Loss 1.987745, Accuracy 0.187500\n","Batch 22817, Loss 1.695655, Accuracy 0.343750\n","Batch 22818, Loss 1.764893, Accuracy 0.250000\n","Batch 22819, Loss 1.785524, Accuracy 0.187500\n","Batch 22820, Loss 2.071308, Accuracy 0.187500\n","Batch 22821, Loss 1.999336, Accuracy 0.187500\n","Batch 22822, Loss 2.047365, Accuracy 0.093750\n","Batch 22823, Loss 1.969427, Accuracy 0.375000\n","Batch 22824, Loss 1.845060, Accuracy 0.500000\n","Batch 22825, Loss 2.031151, Accuracy 0.218750\n","Batch 22826, Loss 2.036493, Accuracy 0.375000\n","Batch 22827, Loss 1.987145, Accuracy 0.312500\n","Batch 22828, Loss 1.692238, Accuracy 0.437500\n","Batch 22829, Loss 1.693164, Accuracy 0.468750\n","Batch 22830, Loss 1.986725, Accuracy 0.250000\n","Batch 22831, Loss 2.059510, Accuracy 0.250000\n","Batch 22832, Loss 1.946311, Accuracy 0.343750\n","Batch 22833, Loss 1.474009, Accuracy 0.531250\n","Batch 22834, Loss 1.720942, Accuracy 0.375000\n","Batch 22835, Loss 1.852894, Accuracy 0.218750\n","Batch 22836, Loss 1.668908, Accuracy 0.343750\n","Batch 22837, Loss 1.495023, Accuracy 0.500000\n","Batch 22838, Loss 1.743641, Accuracy 0.250000\n","Batch 22839, Loss 1.734097, Accuracy 0.281250\n","Batch 22840, Loss 1.577373, Accuracy 0.406250\n","Batch 22841, Loss 1.743057, Accuracy 0.187500\n","Batch 22842, Loss 1.727238, Accuracy 0.218750\n","Batch 22843, Loss 1.424891, Accuracy 0.187500\n","Batch 22844, Loss 1.529100, Accuracy 0.250000\n","Batch 22845, Loss 1.687933, Accuracy 0.500000\n","Batch 22846, Loss 1.411092, Accuracy 0.562500\n","Batch 22847, Loss 2.245779, Accuracy 0.312500\n","Batch 22848, Loss 1.695763, Accuracy 0.500000\n","Batch 22849, Loss 1.745362, Accuracy 0.343750\n","Batch 22850, Loss 1.809139, Accuracy 0.312500\n","Batch 22851, Loss 1.605376, Accuracy 0.406250\n","Batch 22852, Loss 2.004062, Accuracy 0.125000\n","Batch 22853, Loss 1.498971, Accuracy 0.375000\n","Batch 22854, Loss 1.565128, Accuracy 0.406250\n","Batch 22855, Loss 1.499944, Accuracy 0.312500\n","Batch 22856, Loss 1.368400, Accuracy 0.437500\n","Batch 22857, Loss 1.582714, Accuracy 0.500000\n","Batch 22858, Loss 1.515750, Accuracy 0.531250\n","Batch 22859, Loss 1.462612, Accuracy 0.437500\n","Batch 22860, Loss 1.164776, Accuracy 0.468750\n","Batch 22861, Loss 1.390954, Accuracy 0.500000\n","Batch 22862, Loss 1.387749, Accuracy 0.562500\n","Batch 22863, Loss 1.429917, Accuracy 0.500000\n","Batch 22864, Loss 1.390136, Accuracy 0.531250\n","Batch 22865, Loss 1.359770, Accuracy 0.468750\n","Batch 22866, Loss 1.423396, Accuracy 0.468750\n","Batch 22867, Loss 1.088132, Accuracy 0.625000\n","Batch 22868, Loss 1.056116, Accuracy 0.593750\n","Batch 22869, Loss 1.606942, Accuracy 0.437500\n","Batch 22870, Loss 1.054070, Accuracy 0.687500\n","Batch 22871, Loss 1.431338, Accuracy 0.468750\n","Batch 22872, Loss 1.108162, Accuracy 0.625000\n","Batch 22873, Loss 1.437970, Accuracy 0.468750\n","Batch 22874, Loss 1.550037, Accuracy 0.437500\n","Batch 22875, Loss 1.432609, Accuracy 0.500000\n","Batch 22876, Loss 1.370711, Accuracy 0.500000\n","Batch 22877, Loss 1.356441, Accuracy 0.437500\n","Batch 22878, Loss 1.314634, Accuracy 0.531250\n","Batch 22879, Loss 1.271822, Accuracy 0.531250\n","Batch 22880, Loss 1.558236, Accuracy 0.437500\n","Batch 22881, Loss 1.318368, Accuracy 0.406250\n","Batch 22882, Loss 1.264154, Accuracy 0.531250\n","Batch 22883, Loss 1.350638, Accuracy 0.531250\n","Batch 22884, Loss 1.232523, Accuracy 0.562500\n","Batch 22885, Loss 1.226896, Accuracy 0.625000\n","Batch 22886, Loss 1.508686, Accuracy 0.312500\n","Batch 22887, Loss 1.502368, Accuracy 0.406250\n","Batch 22888, Loss 1.415778, Accuracy 0.437500\n","Batch 22889, Loss 1.415761, Accuracy 0.500000\n","Batch 22890, Loss 1.236814, Accuracy 0.468750\n","Batch 22891, Loss 0.980342, Accuracy 0.718750\n","Batch 22892, Loss 1.372071, Accuracy 0.406250\n","Batch 22893, Loss 6.006327, Accuracy 0.000000\n","Batch 22894, Loss 5.383355, Accuracy 0.000000\n","Batch 22895, Loss 4.544214, Accuracy 0.000000\n","Batch 22896, Loss 3.883089, Accuracy 0.000000\n","Batch 22897, Loss 3.122463, Accuracy 0.000000\n","Batch 22898, Loss 2.623543, Accuracy 0.000000\n","Batch 22899, Loss 2.118170, Accuracy 0.000000\n","Batch 22900, Loss 1.931757, Accuracy 0.000000\n","Batch 22901, Loss 1.772369, Accuracy 0.375000\n","Batch 22902, Loss 1.596343, Accuracy 0.437500\n","Batch 22903, Loss 1.459588, Accuracy 0.593750\n","Batch 22904, Loss 1.404469, Accuracy 0.468750\n","Batch 22905, Loss 1.348558, Accuracy 0.562500\n","Batch 22906, Loss 1.315639, Accuracy 0.500000\n","Batch 22907, Loss 1.288059, Accuracy 0.531250\n","Batch 22908, Loss 1.251199, Accuracy 0.687500\n","Batch 22909, Loss 1.262435, Accuracy 0.437500\n","Batch 22910, Loss 1.203788, Accuracy 0.750000\n","Batch 22911, Loss 1.214645, Accuracy 0.593750\n","Batch 22912, Loss 1.242387, Accuracy 0.500000\n","Batch 22913, Loss 1.330344, Accuracy 0.343750\n","Batch 22914, Loss 1.451436, Accuracy 0.250000\n","Batch 22915, Loss 1.275705, Accuracy 0.406250\n","Batch 22916, Loss 1.302109, Accuracy 0.343750\n","Batch 22917, Loss 1.344096, Accuracy 0.406250\n","Batch 22918, Loss 1.226662, Accuracy 0.500000\n","Batch 22919, Loss 1.441276, Accuracy 0.281250\n","Batch 22920, Loss 1.380524, Accuracy 0.312500\n","Batch 22921, Loss 1.241400, Accuracy 0.500000\n","Batch 22922, Loss 1.366227, Accuracy 0.375000\n","Batch 22923, Loss 1.491560, Accuracy 0.406250\n","Batch 22924, Loss 1.484273, Accuracy 0.375000\n","Batch 22925, Loss 1.446505, Accuracy 0.312500\n","Batch 22926, Loss 1.431658, Accuracy 0.250000\n","Batch 22927, Loss 1.326219, Accuracy 0.343750\n","Batch 22928, Loss 1.394242, Accuracy 0.312500\n","Batch 22929, Loss 1.295678, Accuracy 0.406250\n","Batch 22930, Loss 1.434290, Accuracy 0.218750\n","Batch 22931, Loss 1.298505, Accuracy 0.406250\n","Batch 22932, Loss 1.506226, Accuracy 0.156250\n","Batch 22933, Loss 1.399177, Accuracy 0.343750\n","Batch 22934, Loss 1.452280, Accuracy 0.250000\n","Batch 22935, Loss 1.300682, Accuracy 0.437500\n","Batch 22936, Loss 1.419044, Accuracy 0.187500\n","Batch 22937, Loss 1.378087, Accuracy 0.250000\n","Batch 22938, Loss 1.376746, Accuracy 0.250000\n","Batch 22939, Loss 1.499808, Accuracy 0.093750\n","Batch 22940, Loss 1.512157, Accuracy 0.156250\n","Batch 22941, Loss 1.581068, Accuracy 0.312500\n","Batch 22942, Loss 1.450224, Accuracy 0.281250\n","Batch 22943, Loss 1.618289, Accuracy 0.187500\n","Batch 22944, Loss 1.692619, Accuracy 0.312500\n","Batch 22945, Loss 1.838329, Accuracy 0.125000\n","Batch 22946, Loss 1.920239, Accuracy 0.093750\n","Batch 22947, Loss 1.851126, Accuracy 0.250000\n","Batch 22948, Loss 1.586293, Accuracy 0.156250\n","Batch 22949, Loss 1.682622, Accuracy 0.281250\n","Batch 22950, Loss 1.741218, Accuracy 0.156250\n","Batch 22951, Loss 1.660700, Accuracy 0.093750\n","Batch 22952, Loss 1.814749, Accuracy 0.125000\n","Batch 22953, Loss 1.723638, Accuracy 0.343750\n","Batch 22954, Loss 1.682271, Accuracy 0.375000\n","Batch 22955, Loss 1.725565, Accuracy 0.250000\n","Batch 22956, Loss 1.858630, Accuracy 0.156250\n","Batch 22957, Loss 1.697603, Accuracy 0.375000\n","Batch 22958, Loss 1.791039, Accuracy 0.250000\n","Batch 22959, Loss 1.655041, Accuracy 0.125000\n","Batch 22960, Loss 1.536888, Accuracy 0.312500\n","Batch 22961, Loss 1.535890, Accuracy 0.250000\n","Batch 22962, Loss 1.536975, Accuracy 0.218750\n","Batch 22963, Loss 1.518122, Accuracy 0.281250\n","Batch 22964, Loss 1.480119, Accuracy 0.250000\n","Batch 22965, Loss 1.548152, Accuracy 0.187500\n","Batch 22966, Loss 1.342684, Accuracy 0.312500\n","Batch 22967, Loss 1.323559, Accuracy 0.656250\n","Batch 22968, Loss 1.381673, Accuracy 0.468750\n","Batch 22969, Loss 1.318518, Accuracy 0.593750\n","Batch 22970, Loss 1.639702, Accuracy 0.343750\n","Batch 22971, Loss 1.504071, Accuracy 0.437500\n","Batch 22972, Loss 1.502310, Accuracy 0.375000\n","Batch 22973, Loss 2.156700, Accuracy 0.218750\n","Batch 22974, Loss 1.184113, Accuracy 0.562500\n","Batch 22975, Loss 1.686262, Accuracy 0.375000\n","Batch 22976, Loss 1.546702, Accuracy 0.281250\n","Batch 22977, Loss 1.550960, Accuracy 0.281250\n","Batch 22978, Loss 1.531735, Accuracy 0.250000\n","Batch 22979, Loss 1.524131, Accuracy 0.187500\n","Batch 22980, Loss 1.366323, Accuracy 0.343750\n","Batch 22981, Loss 1.607416, Accuracy 0.125000\n","Batch 22982, Loss 1.367438, Accuracy 0.281250\n","Batch 22983, Loss 1.342741, Accuracy 0.281250\n","Batch 22984, Loss 1.377362, Accuracy 0.250000\n","Batch 22985, Loss 1.335575, Accuracy 0.500000\n","Batch 22986, Loss 1.642161, Accuracy 0.500000\n","Batch 22987, Loss 1.467517, Accuracy 0.406250\n","Batch 22988, Loss 1.603546, Accuracy 0.343750\n","Batch 22989, Loss 1.559397, Accuracy 0.468750\n","Batch 22990, Loss 2.405723, Accuracy 0.218750\n","Batch 22991, Loss 1.894026, Accuracy 0.468750\n","Batch 22992, Loss 1.774520, Accuracy 0.500000\n","Batch 22993, Loss 1.850190, Accuracy 0.312500\n","Batch 22994, Loss 1.729886, Accuracy 0.406250\n","Batch 22995, Loss 1.938413, Accuracy 0.343750\n","Batch 22996, Loss 1.889298, Accuracy 0.343750\n","Batch 22997, Loss 1.921041, Accuracy 0.281250\n","Batch 22998, Loss 1.790723, Accuracy 0.343750\n","Batch 22999, Loss 1.749648, Accuracy 0.281250\n","Batch 23000, Loss 1.696665, Accuracy 0.281250\n","Batch except\n","Batch except\n","Batch except\n","=================================================\n","Test, Loss 5.273023, Accuracy 0.072917\n","=================================================\n","Batch 23001, Loss 1.798125, Accuracy 0.187500\n","Batch 23002, Loss 1.707857, Accuracy 0.250000\n","Batch 23003, Loss 1.610553, Accuracy 0.250000\n","Batch 23004, Loss 1.463579, Accuracy 0.375000\n","Batch 23005, Loss 1.461402, Accuracy 0.312500\n","Batch 23006, Loss 1.307176, Accuracy 0.187500\n","Batch 23007, Loss 1.143411, Accuracy 0.593750\n","Batch 23008, Loss 1.503675, Accuracy 0.500000\n","Batch 23009, Loss 1.607420, Accuracy 0.437500\n","Batch 23010, Loss 1.469634, Accuracy 0.468750\n","Batch 23011, Loss 1.468775, Accuracy 0.687500\n","Batch 23012, Loss 1.805373, Accuracy 0.437500\n","Batch 23013, Loss 1.818802, Accuracy 0.437500\n","Batch 23014, Loss 1.801272, Accuracy 0.375000\n","Batch 23015, Loss 1.555176, Accuracy 0.500000\n","Batch 23016, Loss 1.537381, Accuracy 0.406250\n","Batch 23017, Loss 1.576125, Accuracy 0.468750\n","Batch 23018, Loss 1.732243, Accuracy 0.312500\n","Batch 23019, Loss 1.540054, Accuracy 0.437500\n","Batch 23020, Loss 1.628209, Accuracy 0.437500\n","Batch 23021, Loss 1.625176, Accuracy 0.281250\n","Batch 23022, Loss 1.459956, Accuracy 0.312500\n","Batch 23023, Loss 1.748924, Accuracy 0.250000\n","Batch 23024, Loss 1.642451, Accuracy 0.281250\n","Batch 23025, Loss 1.344675, Accuracy 0.343750\n","Batch 23026, Loss 1.487131, Accuracy 0.250000\n","Batch 23027, Loss 1.524758, Accuracy 0.187500\n","Batch 23028, Loss 1.538044, Accuracy 0.375000\n","Batch 23029, Loss 1.736578, Accuracy 0.156250\n","Batch 23030, Loss 1.640694, Accuracy 0.437500\n","Batch 23031, Loss 1.344459, Accuracy 0.468750\n","Batch 23032, Loss 1.717678, Accuracy 0.500000\n","Batch 23033, Loss 1.798925, Accuracy 0.343750\n","Batch 23034, Loss 1.346400, Accuracy 0.656250\n","Batch 23035, Loss 1.393209, Accuracy 0.562500\n","Batch 23036, Loss 1.853985, Accuracy 0.312500\n","Batch 23037, Loss 1.658808, Accuracy 0.375000\n","Batch 23038, Loss 1.964661, Accuracy 0.406250\n","Batch 23039, Loss 1.689065, Accuracy 0.437500\n","Batch 23040, Loss 1.788661, Accuracy 0.406250\n","Batch 23041, Loss 1.765616, Accuracy 0.312500\n","Batch 23042, Loss 1.328014, Accuracy 0.593750\n","Batch 23043, Loss 1.692572, Accuracy 0.343750\n","Batch 23044, Loss 1.759882, Accuracy 0.218750\n","Batch 23045, Loss 1.675930, Accuracy 0.281250\n","Batch 23046, Loss 1.618815, Accuracy 0.250000\n","Batch 23047, Loss 1.434917, Accuracy 0.312500\n","Batch 23048, Loss 1.576522, Accuracy 0.343750\n","Batch 23049, Loss 1.433958, Accuracy 0.218750\n","Batch 23050, Loss 1.313694, Accuracy 0.343750\n","Batch 23051, Loss 1.393649, Accuracy 0.437500\n","Batch 23052, Loss 1.224373, Accuracy 0.656250\n","Batch 23053, Loss 1.265773, Accuracy 0.531250\n","Batch 23054, Loss 1.890229, Accuracy 0.406250\n","Batch 23055, Loss 1.362111, Accuracy 0.437500\n","Batch 23056, Loss 1.651623, Accuracy 0.531250\n","Batch 23057, Loss 1.336735, Accuracy 0.593750\n","Batch 23058, Loss 1.379817, Accuracy 0.531250\n","Batch 23059, Loss 1.849141, Accuracy 0.375000\n","Batch 23060, Loss 1.744979, Accuracy 0.375000\n","Batch 23061, Loss 1.718107, Accuracy 0.343750\n","Batch 23062, Loss 1.757635, Accuracy 0.375000\n","Batch 23063, Loss 1.942302, Accuracy 0.281250\n","Batch 23064, Loss 1.377409, Accuracy 0.406250\n","Batch 23065, Loss 1.619607, Accuracy 0.343750\n","Batch 23066, Loss 1.642633, Accuracy 0.343750\n","Batch 23067, Loss 1.620079, Accuracy 0.406250\n","Batch 23068, Loss 1.502769, Accuracy 0.375000\n","Batch 23069, Loss 1.542954, Accuracy 0.156250\n","Batch 23070, Loss 1.260674, Accuracy 0.468750\n","Batch 23071, Loss 1.398900, Accuracy 0.437500\n","Batch 23072, Loss 1.928470, Accuracy 0.281250\n","Batch 23073, Loss 1.376880, Accuracy 0.468750\n","Batch 23074, Loss 1.263075, Accuracy 0.500000\n","Batch 23075, Loss 1.194958, Accuracy 0.531250\n","Batch 23076, Loss 1.321233, Accuracy 0.531250\n","Batch 23077, Loss 1.179308, Accuracy 0.562500\n","Batch 23078, Loss 1.823107, Accuracy 0.343750\n","Batch 23079, Loss 1.364193, Accuracy 0.562500\n","Batch 23080, Loss 1.708594, Accuracy 0.468750\n","Batch 23081, Loss 2.204796, Accuracy 0.500000\n","Batch 23082, Loss 1.332217, Accuracy 0.656250\n","Batch 23083, Loss 2.166274, Accuracy 0.312500\n","Batch 23084, Loss 1.977773, Accuracy 0.500000\n","Batch 23085, Loss 2.213893, Accuracy 0.343750\n","Batch 23086, Loss 1.891856, Accuracy 0.312500\n","Batch 23087, Loss 2.213840, Accuracy 0.343750\n","Batch 23088, Loss 1.818921, Accuracy 0.406250\n","Batch 23089, Loss 1.893417, Accuracy 0.437500\n","Batch 23090, Loss 1.941557, Accuracy 0.218750\n","Batch 23091, Loss 1.841469, Accuracy 0.406250\n","Batch 23092, Loss 1.757010, Accuracy 0.312500\n","Batch 23093, Loss 1.698716, Accuracy 0.281250\n","Batch 23094, Loss 1.612916, Accuracy 0.468750\n","Batch 23095, Loss 1.553342, Accuracy 0.531250\n","Batch 23096, Loss 1.631972, Accuracy 0.375000\n","Batch 23097, Loss 1.775539, Accuracy 0.437500\n","Batch 23098, Loss 1.879483, Accuracy 0.406250\n","Batch 23099, Loss 1.271273, Accuracy 0.531250\n","Batch 23100, Loss 1.121979, Accuracy 0.718750\n","Batch 23101, Loss 1.492825, Accuracy 0.562500\n","Batch 23102, Loss 1.283468, Accuracy 0.468750\n","Batch 23103, Loss 1.269762, Accuracy 0.593750\n","Batch 23104, Loss 1.609538, Accuracy 0.468750\n","Batch 23105, Loss 1.509734, Accuracy 0.500000\n","Batch 23106, Loss 1.448777, Accuracy 0.406250\n","Batch 23107, Loss 1.815716, Accuracy 0.468750\n","Batch 23108, Loss 1.628964, Accuracy 0.468750\n","Batch 23109, Loss 1.200007, Accuracy 0.500000\n","Batch 23110, Loss 1.496605, Accuracy 0.468750\n","Batch 23111, Loss 1.442150, Accuracy 0.625000\n","Batch 23112, Loss 1.735382, Accuracy 0.406250\n","Batch 23113, Loss 1.248674, Accuracy 0.531250\n","Batch 23114, Loss 1.345790, Accuracy 0.593750\n","Batch 23115, Loss 1.271257, Accuracy 0.593750\n","Batch 23116, Loss 1.603421, Accuracy 0.343750\n","Batch 23117, Loss 1.220665, Accuracy 0.531250\n","Batch 23118, Loss 1.423420, Accuracy 0.437500\n","Batch 23119, Loss 1.325066, Accuracy 0.406250\n","Batch 23120, Loss 1.369951, Accuracy 0.562500\n","Batch 23121, Loss 1.297209, Accuracy 0.406250\n","Batch 23122, Loss 1.441730, Accuracy 0.500000\n","Batch 23123, Loss 1.840453, Accuracy 0.312500\n","Batch 23124, Loss 1.320879, Accuracy 0.562500\n","Batch 23125, Loss 1.665477, Accuracy 0.343750\n","Batch 23126, Loss 1.237594, Accuracy 0.562500\n","Batch 23127, Loss 1.212797, Accuracy 0.562500\n","Batch 23128, Loss 1.357447, Accuracy 0.468750\n","Batch 23129, Loss 1.366132, Accuracy 0.500000\n","Batch 23130, Loss 1.449705, Accuracy 0.531250\n","Batch 23131, Loss 3.612517, Accuracy 0.250000\n","Batch 23132, Loss 5.410905, Accuracy 0.000000\n","Batch 23133, Loss 4.691207, Accuracy 0.000000\n","Batch 23134, Loss 3.909697, Accuracy 0.000000\n","Batch 23135, Loss 3.220309, Accuracy 0.000000\n","Batch 23136, Loss 2.694007, Accuracy 0.000000\n","Batch 23137, Loss 2.186701, Accuracy 0.000000\n","Batch 23138, Loss 1.906648, Accuracy 0.000000\n","Batch 23139, Loss 1.774227, Accuracy 0.000000\n","Batch 23140, Loss 1.661809, Accuracy 0.593750\n","Batch 23141, Loss 1.590757, Accuracy 0.437500\n","Batch 23142, Loss 1.511773, Accuracy 0.468750\n","Batch 23143, Loss 1.459448, Accuracy 0.281250\n","Batch 23144, Loss 1.360228, Accuracy 0.625000\n","Batch 23145, Loss 1.322980, Accuracy 0.500000\n","Batch 23146, Loss 1.281679, Accuracy 0.656250\n","Batch 23147, Loss 1.262442, Accuracy 0.656250\n","Batch 23148, Loss 1.257965, Accuracy 0.531250\n","Batch 23149, Loss 1.252949, Accuracy 0.625000\n","Batch 23150, Loss 1.243124, Accuracy 0.593750\n","Batch 23151, Loss 1.236761, Accuracy 0.531250\n","Batch 23152, Loss 1.258612, Accuracy 0.656250\n","Batch 23153, Loss 1.287141, Accuracy 0.500000\n","Batch 23154, Loss 1.334161, Accuracy 0.437500\n","Batch 23155, Loss 1.441427, Accuracy 0.312500\n","Batch 23156, Loss 1.338900, Accuracy 0.500000\n","Batch 23157, Loss 1.305238, Accuracy 0.500000\n","Batch 23158, Loss 1.329584, Accuracy 0.437500\n","Batch 23159, Loss 1.284455, Accuracy 0.343750\n","Batch 23160, Loss 1.355206, Accuracy 0.312500\n","Batch 23161, Loss 1.373184, Accuracy 0.468750\n","Batch 23162, Loss 1.396022, Accuracy 0.406250\n","Batch 23163, Loss 1.397425, Accuracy 0.468750\n","Batch 23164, Loss 1.409294, Accuracy 0.437500\n","Batch 23165, Loss 1.441795, Accuracy 0.281250\n","Batch 23166, Loss 1.483268, Accuracy 0.343750\n","Batch 23167, Loss 1.407420, Accuracy 0.406250\n","Batch 23168, Loss 1.442705, Accuracy 0.375000\n","Batch 23169, Loss 1.456578, Accuracy 0.156250\n","Batch 23170, Loss 1.435485, Accuracy 0.281250\n","Batch 23171, Loss 1.387646, Accuracy 0.312500\n","Batch 23172, Loss 1.437791, Accuracy 0.156250\n","Batch 23173, Loss 1.407707, Accuracy 0.187500\n","Batch 23174, Loss 1.455052, Accuracy 0.125000\n","Batch 23175, Loss 1.402889, Accuracy 0.187500\n","Batch 23176, Loss 1.477420, Accuracy 0.218750\n","Batch 23177, Loss 1.492529, Accuracy 0.250000\n","Batch 23178, Loss 1.493314, Accuracy 0.218750\n","Batch 23179, Loss 1.531703, Accuracy 0.187500\n","Batch 23180, Loss 1.397633, Accuracy 0.375000\n","Batch 23181, Loss 1.451053, Accuracy 0.281250\n","Batch 23182, Loss 1.640539, Accuracy 0.125000\n","Batch 23183, Loss 1.644811, Accuracy 0.187500\n","Batch 23184, Loss 1.466881, Accuracy 0.187500\n","Batch 23185, Loss 1.725656, Accuracy 0.218750\n","Batch 23186, Loss 1.681332, Accuracy 0.093750\n","Batch 23187, Loss 1.635662, Accuracy 0.406250\n","Batch 23188, Loss 1.591259, Accuracy 0.500000\n","Batch 23189, Loss 1.726780, Accuracy 0.343750\n","Batch 23190, Loss 1.507062, Accuracy 0.562500\n","Batch 23191, Loss 1.689150, Accuracy 0.343750\n","Batch 23192, Loss 1.775907, Accuracy 0.312500\n","Batch 23193, Loss 1.596071, Accuracy 0.375000\n","Batch 23194, Loss 1.703277, Accuracy 0.312500\n","Batch 23195, Loss 1.812670, Accuracy 0.250000\n","Batch 23196, Loss 1.682889, Accuracy 0.312500\n","Batch 23197, Loss 1.773794, Accuracy 0.250000\n","Batch 23198, Loss 1.674220, Accuracy 0.281250\n","Batch 23199, Loss 1.501869, Accuracy 0.406250\n","Batch 23200, Loss 1.682822, Accuracy 0.218750\n","Batch except\n","Batch except\n","Batch except\n","=================================================\n","Test, Loss 5.059492, Accuracy 0.093750\n","=================================================\n","Batch 23201, Loss 1.652875, Accuracy 0.218750\n","Batch 23202, Loss 1.653502, Accuracy 0.218750\n","Batch 23203, Loss 1.547304, Accuracy 0.343750\n","Batch 23204, Loss 1.626409, Accuracy 0.187500\n","Batch 23205, Loss 1.695895, Accuracy 0.093750\n","Batch 23206, Loss 1.733210, Accuracy 0.156250\n","Batch 23207, Loss 1.712112, Accuracy 0.125000\n","Batch 23208, Loss 1.678452, Accuracy 0.343750\n","Batch 23209, Loss 1.648359, Accuracy 0.500000\n","Batch 23210, Loss 1.725840, Accuracy 0.312500\n","Batch 23211, Loss 1.655883, Accuracy 0.312500\n","Batch 23212, Loss 1.439887, Accuracy 0.437500\n","Batch 23213, Loss 1.641215, Accuracy 0.406250\n","Batch 23214, Loss 1.562938, Accuracy 0.250000\n","Batch 23215, Loss 1.397995, Accuracy 0.312500\n","Batch 23216, Loss 1.606453, Accuracy 0.437500\n","Batch 23217, Loss 1.338857, Accuracy 0.312500\n","Batch 23218, Loss 1.514167, Accuracy 0.250000\n","Batch 23219, Loss 1.497902, Accuracy 0.250000\n","Batch 23220, Loss 1.263216, Accuracy 0.406250\n","Batch 23221, Loss 1.518949, Accuracy 0.406250\n","Batch 23222, Loss 1.407519, Accuracy 0.406250\n","Batch 23223, Loss 1.358775, Accuracy 0.406250\n","Batch 23224, Loss 1.332521, Accuracy 0.562500\n","Batch 23225, Loss 1.621700, Accuracy 0.437500\n","Batch 23226, Loss 1.866370, Accuracy 0.312500\n","Batch 23227, Loss 1.606934, Accuracy 0.406250\n","Batch 23228, Loss 1.695921, Accuracy 0.468750\n","Batch 23229, Loss 1.964268, Accuracy 0.281250\n","Batch 23230, Loss 1.337559, Accuracy 0.531250\n","Batch 23231, Loss 1.612095, Accuracy 0.437500\n","Batch 23232, Loss 1.589803, Accuracy 0.468750\n","Batch 23233, Loss 1.856799, Accuracy 0.343750\n","Batch 23234, Loss 1.690805, Accuracy 0.375000\n","Batch 23235, Loss 1.498368, Accuracy 0.437500\n","Batch 23236, Loss 1.319141, Accuracy 0.500000\n","Batch 23237, Loss 1.573773, Accuracy 0.375000\n","Batch 23238, Loss 1.605779, Accuracy 0.375000\n","Batch 23239, Loss 1.763629, Accuracy 0.218750\n","Batch 23240, Loss 1.742886, Accuracy 0.125000\n","Batch 23241, Loss 1.443224, Accuracy 0.218750\n","Batch 23242, Loss 1.697654, Accuracy 0.125000\n","Batch 23243, Loss 1.528268, Accuracy 0.343750\n","Batch 23244, Loss 1.319612, Accuracy 0.250000\n","Batch 23245, Loss 1.385699, Accuracy 0.312500\n","Batch 23246, Loss 1.448849, Accuracy 0.375000\n","Batch 23247, Loss 1.733348, Accuracy 0.437500\n","Batch 23248, Loss 1.185879, Accuracy 0.468750\n","Batch 23249, Loss 1.748270, Accuracy 0.406250\n","Batch 23250, Loss 1.424640, Accuracy 0.562500\n","Batch 23251, Loss 1.543996, Accuracy 0.500000\n","Batch 23252, Loss 1.621314, Accuracy 0.406250\n","Batch 23253, Loss 1.562665, Accuracy 0.500000\n","Batch 23254, Loss 1.587212, Accuracy 0.468750\n","Batch 23255, Loss 1.783813, Accuracy 0.437500\n","Batch 23256, Loss 1.787801, Accuracy 0.437500\n","Batch 23257, Loss 1.718122, Accuracy 0.375000\n","Batch 23258, Loss 1.903137, Accuracy 0.312500\n","Batch 23259, Loss 1.651179, Accuracy 0.343750\n","Batch 23260, Loss 1.589069, Accuracy 0.343750\n","Batch 23261, Loss 1.686827, Accuracy 0.218750\n","Batch 23262, Loss 1.499198, Accuracy 0.281250\n","Batch 23263, Loss 1.482817, Accuracy 0.343750\n","Batch 23264, Loss 1.636363, Accuracy 0.218750\n","Batch 23265, Loss 1.437116, Accuracy 0.406250\n","Batch 23266, Loss 1.491405, Accuracy 0.312500\n","Batch 23267, Loss 1.261819, Accuracy 0.500000\n","Batch 23268, Loss 1.294149, Accuracy 0.593750\n","Batch 23269, Loss 1.457407, Accuracy 0.437500\n","Batch 23270, Loss 1.562012, Accuracy 0.406250\n","Batch 23271, Loss 2.489256, Accuracy 0.406250\n","Batch 23272, Loss 2.558042, Accuracy 0.375000\n","Batch 23273, Loss 1.555761, Accuracy 0.687500\n","Batch 23274, Loss 1.304235, Accuracy 0.656250\n","Batch 23275, Loss 2.826404, Accuracy 0.250000\n","Batch 23276, Loss 2.539567, Accuracy 0.343750\n","Batch 23277, Loss 2.651329, Accuracy 0.343750\n","Batch 23278, Loss 2.435455, Accuracy 0.375000\n","Batch 23279, Loss 2.301806, Accuracy 0.375000\n","Batch 23280, Loss 2.453352, Accuracy 0.343750\n","Batch 23281, Loss 2.366652, Accuracy 0.406250\n","Batch 23282, Loss 2.396098, Accuracy 0.343750\n","Batch 23283, Loss 2.565016, Accuracy 0.187500\n","Batch 23284, Loss 2.392198, Accuracy 0.281250\n","Batch 23285, Loss 2.240402, Accuracy 0.250000\n","Batch 23286, Loss 2.203958, Accuracy 0.312500\n","Batch 23287, Loss 2.394813, Accuracy 0.062500\n","Batch 23288, Loss 2.116770, Accuracy 0.218750\n","Batch 23289, Loss 2.005360, Accuracy 0.187500\n","Batch 23290, Loss 2.076321, Accuracy 0.125000\n","Batch 23291, Loss 1.718605, Accuracy 0.156250\n","Batch 23292, Loss 1.509988, Accuracy 0.187500\n","Batch 23293, Loss 1.634112, Accuracy 0.406250\n","Batch 23294, Loss 1.768450, Accuracy 0.437500\n","Batch 23295, Loss 1.450987, Accuracy 0.531250\n","Batch 23296, Loss 1.360791, Accuracy 0.593750\n","Batch 23297, Loss 1.861726, Accuracy 0.468750\n","Batch 23298, Loss 1.612135, Accuracy 0.500000\n","Batch 23299, Loss 2.094036, Accuracy 0.437500\n","Batch 23300, Loss 2.119381, Accuracy 0.375000\n","Batch 23301, Loss 2.190749, Accuracy 0.343750\n","Batch 23302, Loss 2.443623, Accuracy 0.281250\n","Batch 23303, Loss 1.788467, Accuracy 0.406250\n","Batch 23304, Loss 1.564732, Accuracy 0.531250\n","Batch 23305, Loss 1.954149, Accuracy 0.343750\n","Batch 23306, Loss 2.072454, Accuracy 0.312500\n","Batch 23307, Loss 1.718215, Accuracy 0.343750\n","Batch 23308, Loss 1.729463, Accuracy 0.437500\n","Batch 23309, Loss 1.524600, Accuracy 0.531250\n","Batch 23310, Loss 1.487906, Accuracy 0.468750\n","Batch 23311, Loss 1.616039, Accuracy 0.218750\n","Batch 23312, Loss 1.762077, Accuracy 0.218750\n","Batch 23313, Loss 1.685162, Accuracy 0.187500\n","Batch 23314, Loss 1.396486, Accuracy 0.500000\n","Batch 23315, Loss 1.551833, Accuracy 0.468750\n","Batch 23316, Loss 1.268777, Accuracy 0.625000\n","Batch 23317, Loss 1.648004, Accuracy 0.343750\n","Batch 23318, Loss 1.410109, Accuracy 0.500000\n","Batch 23319, Loss 1.209768, Accuracy 0.593750\n","Batch 23320, Loss 1.460791, Accuracy 0.500000\n","Batch 23321, Loss 1.138604, Accuracy 0.593750\n","Batch 23322, Loss 2.033531, Accuracy 0.281250\n","Batch 23323, Loss 1.772479, Accuracy 0.406250\n","Batch 23324, Loss 1.796990, Accuracy 0.375000\n","Batch 23325, Loss 1.646260, Accuracy 0.500000\n","Batch 23326, Loss 1.748559, Accuracy 0.437500\n","Batch 23327, Loss 1.659305, Accuracy 0.375000\n","Batch 23328, Loss 1.664047, Accuracy 0.468750\n","Batch 23329, Loss 1.801099, Accuracy 0.375000\n","Batch 23330, Loss 1.627793, Accuracy 0.375000\n","Batch 23331, Loss 1.753635, Accuracy 0.312500\n","Batch 23332, Loss 1.532127, Accuracy 0.406250\n","Batch 23333, Loss 1.678508, Accuracy 0.312500\n","Batch 23334, Loss 1.756868, Accuracy 0.250000\n","Batch 23335, Loss 1.821688, Accuracy 0.343750\n","Batch 23336, Loss 2.003613, Accuracy 0.218750\n","Batch 23337, Loss 1.688134, Accuracy 0.218750\n","Batch 23338, Loss 1.592993, Accuracy 0.375000\n","Batch 23339, Loss 1.663824, Accuracy 0.312500\n","Batch 23340, Loss 1.709756, Accuracy 0.281250\n","Batch 23341, Loss 1.798993, Accuracy 0.187500\n","Batch 23342, Loss 1.659862, Accuracy 0.218750\n","Batch 23343, Loss 1.401600, Accuracy 0.406250\n","Batch 23344, Loss 1.660375, Accuracy 0.218750\n","Batch 23345, Loss 1.640982, Accuracy 0.312500\n","Batch 23346, Loss 1.377050, Accuracy 0.281250\n","Batch 23347, Loss 1.333644, Accuracy 0.562500\n","Batch 23348, Loss 1.390354, Accuracy 0.500000\n","Batch 23349, Loss 1.553463, Accuracy 0.468750\n","Batch 23350, Loss 1.369268, Accuracy 0.500000\n","Batch 23351, Loss 1.397676, Accuracy 0.406250\n","Batch 23352, Loss 1.226983, Accuracy 0.468750\n","Batch 23353, Loss 1.464291, Accuracy 0.562500\n","Batch 23354, Loss 1.302181, Accuracy 0.468750\n","Batch 23355, Loss 1.611225, Accuracy 0.312500\n","Batch 23356, Loss 1.514785, Accuracy 0.281250\n","Batch 23357, Loss 1.144715, Accuracy 0.593750\n","Batch 23358, Loss 1.399470, Accuracy 0.531250\n","Batch 23359, Loss 1.239154, Accuracy 0.562500\n","Batch 23360, Loss 1.142720, Accuracy 0.562500\n","Batch 23361, Loss 1.496263, Accuracy 0.437500\n","Batch 23362, Loss 1.535342, Accuracy 0.593750\n","Batch 23363, Loss 1.247099, Accuracy 0.531250\n","Batch 23364, Loss 1.185189, Accuracy 0.593750\n","Batch 23365, Loss 1.395559, Accuracy 0.625000\n","Batch 23366, Loss 1.226778, Accuracy 0.593750\n","Batch 23367, Loss 1.152571, Accuracy 0.593750\n","Batch 23368, Loss 1.320853, Accuracy 0.531250\n","Batch 23369, Loss 1.685685, Accuracy 0.500000\n","Batch 23370, Loss 6.019984, Accuracy 0.000000\n","Batch 23371, Loss 5.642108, Accuracy 0.000000\n","Batch 23372, Loss 4.812816, Accuracy 0.000000\n","Batch 23373, Loss 4.126402, Accuracy 0.000000\n","Batch 23374, Loss 3.395228, Accuracy 0.000000\n","Batch 23375, Loss 2.912809, Accuracy 0.000000\n","Batch 23376, Loss 2.308062, Accuracy 0.000000\n","Batch 23377, Loss 1.918180, Accuracy 0.000000\n","Batch 23378, Loss 1.734635, Accuracy 0.625000\n","Batch 23379, Loss 1.671607, Accuracy 0.500000\n","Batch 23380, Loss 1.611871, Accuracy 0.437500\n","Batch 23381, Loss 1.558285, Accuracy 0.500000\n","Batch 23382, Loss 1.514905, Accuracy 0.531250\n","Batch 23383, Loss 1.474319, Accuracy 0.562500\n","Batch 23384, Loss 1.451427, Accuracy 0.468750\n","Batch 23385, Loss 1.424074, Accuracy 0.468750\n","Batch 23386, Loss 1.355650, Accuracy 0.750000\n","Batch 23387, Loss 1.347865, Accuracy 0.562500\n","Batch 23388, Loss 1.288837, Accuracy 0.687500\n","Batch 23389, Loss 1.333766, Accuracy 0.468750\n","Batch 23390, Loss 1.313622, Accuracy 0.468750\n","Batch 23391, Loss 1.245895, Accuracy 0.625000\n","Batch 23392, Loss 1.245211, Accuracy 0.593750\n","Batch 23393, Loss 1.283811, Accuracy 0.437500\n","Batch 23394, Loss 1.340091, Accuracy 0.406250\n","Batch 23395, Loss 1.284548, Accuracy 0.500000\n","Batch 23396, Loss 1.445367, Accuracy 0.312500\n","Batch 23397, Loss 1.251776, Accuracy 0.500000\n","Batch 23398, Loss 1.433923, Accuracy 0.312500\n","Batch 23399, Loss 1.368952, Accuracy 0.343750\n","Batch 23400, Loss 1.341296, Accuracy 0.437500\n","Batch except\n","Batch except\n","Batch except\n","=================================================\n","Test, Loss 3.203700, Accuracy 0.083333\n","=================================================\n","Batch 23401, Loss 1.322970, Accuracy 0.406250\n","Batch 23402, Loss 1.253366, Accuracy 0.343750\n","Batch 23403, Loss 1.366143, Accuracy 0.343750\n","Batch 23404, Loss 1.281225, Accuracy 0.375000\n","Batch 23405, Loss 1.380704, Accuracy 0.281250\n","Batch 23406, Loss 1.431650, Accuracy 0.250000\n","Batch 23407, Loss 1.435968, Accuracy 0.187500\n","Batch 23408, Loss 1.367987, Accuracy 0.312500\n","Batch 23409, Loss 1.310622, Accuracy 0.406250\n","Batch 23410, Loss 1.326379, Accuracy 0.343750\n","Batch 23411, Loss 1.291906, Accuracy 0.375000\n","Batch 23412, Loss 1.334278, Accuracy 0.250000\n","Batch 23413, Loss 1.326807, Accuracy 0.312500\n","Batch 23414, Loss 1.332565, Accuracy 0.250000\n","Batch 23415, Loss 1.493217, Accuracy 0.156250\n","Batch 23416, Loss 1.438648, Accuracy 0.156250\n","Batch 23417, Loss 1.332457, Accuracy 0.281250\n","Batch 23418, Loss 1.443553, Accuracy 0.218750\n","Batch 23419, Loss 1.556501, Accuracy 0.156250\n","Batch 23420, Loss 1.731069, Accuracy 0.250000\n","Batch 23421, Loss 1.742245, Accuracy 0.125000\n","Batch 23422, Loss 1.662452, Accuracy 0.156250\n","Batch 23423, Loss 1.613263, Accuracy 0.062500\n","Batch 23424, Loss 1.936936, Accuracy 0.187500\n","Batch 23425, Loss 1.615553, Accuracy 0.187500\n","Batch 23426, Loss 1.855287, Accuracy 0.343750\n","Batch 23427, Loss 1.680167, Accuracy 0.468750\n","Batch 23428, Loss 1.662251, Accuracy 0.343750\n","Batch 23429, Loss 1.844986, Accuracy 0.250000\n","Batch 23430, Loss 1.731280, Accuracy 0.312500\n","Batch 23431, Loss 1.782841, Accuracy 0.343750\n","Batch 23432, Loss 1.671695, Accuracy 0.312500\n","Batch 23433, Loss 1.831517, Accuracy 0.250000\n","Batch 23434, Loss 1.979548, Accuracy 0.187500\n","Batch 23435, Loss 1.718026, Accuracy 0.312500\n","Batch 23436, Loss 1.472317, Accuracy 0.500000\n","Batch 23437, Loss 1.755572, Accuracy 0.218750\n","Batch 23438, Loss 1.605622, Accuracy 0.281250\n","Batch 23439, Loss 1.727834, Accuracy 0.187500\n","Batch 23440, Loss 1.567159, Accuracy 0.375000\n","Batch 23441, Loss 1.888245, Accuracy 0.187500\n","Batch 23442, Loss 1.616619, Accuracy 0.281250\n","Batch 23443, Loss 1.784299, Accuracy 0.187500\n","Batch 23444, Loss 1.761491, Accuracy 0.218750\n","Batch 23445, Loss 1.698661, Accuracy 0.250000\n","Batch 23446, Loss 1.824154, Accuracy 0.281250\n","Batch 23447, Loss 1.713510, Accuracy 0.218750\n","Batch 23448, Loss 1.614411, Accuracy 0.218750\n","Batch 23449, Loss 1.887802, Accuracy 0.093750\n","Batch 23450, Loss 1.934375, Accuracy 0.062500\n","Batch 23451, Loss 1.773636, Accuracy 0.343750\n","Batch 23452, Loss 1.491422, Accuracy 0.437500\n","Batch 23453, Loss 1.423388, Accuracy 0.437500\n","Batch 23454, Loss 1.716296, Accuracy 0.281250\n","Batch 23455, Loss 1.487211, Accuracy 0.281250\n","Batch 23456, Loss 1.416777, Accuracy 0.281250\n","Batch 23457, Loss 1.253495, Accuracy 0.500000\n","Batch 23458, Loss 1.470979, Accuracy 0.281250\n","Batch 23459, Loss 1.338324, Accuracy 0.406250\n","Batch 23460, Loss 1.432611, Accuracy 0.531250\n","Batch 23461, Loss 1.408933, Accuracy 0.562500\n","Batch 23462, Loss 1.256716, Accuracy 0.625000\n","Batch 23463, Loss 1.365503, Accuracy 0.468750\n","Batch 23464, Loss 1.566938, Accuracy 0.437500\n","Batch 23465, Loss 1.717193, Accuracy 0.406250\n","Batch 23466, Loss 1.505569, Accuracy 0.562500\n","Batch 23467, Loss 1.547430, Accuracy 0.343750\n","Batch 23468, Loss 1.583540, Accuracy 0.375000\n","Batch 23469, Loss 1.746073, Accuracy 0.468750\n","Batch 23470, Loss 1.702555, Accuracy 0.406250\n","Batch 23471, Loss 1.417564, Accuracy 0.531250\n","Batch 23472, Loss 1.661160, Accuracy 0.375000\n","Batch 23473, Loss 1.713126, Accuracy 0.312500\n","Batch 23474, Loss 1.396599, Accuracy 0.437500\n","Batch 23475, Loss 1.627412, Accuracy 0.406250\n","Batch 23476, Loss 1.459222, Accuracy 0.375000\n","Batch 23477, Loss 1.718964, Accuracy 0.218750\n","Batch 23478, Loss 1.480616, Accuracy 0.281250\n","Batch 23479, Loss 1.431676, Accuracy 0.250000\n","Batch 23480, Loss 1.367833, Accuracy 0.218750\n","Batch 23481, Loss 1.627196, Accuracy 0.125000\n","Batch 23482, Loss 1.209143, Accuracy 0.500000\n","Batch 23483, Loss 1.139798, Accuracy 0.593750\n","Batch 23484, Loss 1.460748, Accuracy 0.562500\n","Batch 23485, Loss 1.695071, Accuracy 0.437500\n","Batch 23486, Loss 1.411803, Accuracy 0.468750\n","Batch 23487, Loss 1.467429, Accuracy 0.437500\n","Batch 23488, Loss 1.525597, Accuracy 0.500000\n","Batch 23489, Loss 1.662396, Accuracy 0.406250\n","Batch 23490, Loss 1.626136, Accuracy 0.437500\n","Batch 23491, Loss 1.554457, Accuracy 0.468750\n","Batch 23492, Loss 1.651325, Accuracy 0.375000\n","Batch 23493, Loss 1.519474, Accuracy 0.468750\n","Batch 23494, Loss 1.776153, Accuracy 0.375000\n","Batch 23495, Loss 1.684461, Accuracy 0.312500\n","Batch 23496, Loss 1.446149, Accuracy 0.437500\n","Batch 23497, Loss 1.265202, Accuracy 0.468750\n","Batch 23498, Loss 1.292430, Accuracy 0.468750\n","Batch 23499, Loss 1.329392, Accuracy 0.406250\n","Batch 23500, Loss 1.200309, Accuracy 0.562500\n","Batch 23501, Loss 1.482973, Accuracy 0.187500\n","Batch 23502, Loss 1.388705, Accuracy 0.468750\n","Batch 23503, Loss 1.541186, Accuracy 0.437500\n","Batch 23504, Loss 1.375285, Accuracy 0.343750\n","Batch 23505, Loss 1.477080, Accuracy 0.531250\n","Batch 23506, Loss 1.797797, Accuracy 0.406250\n","Batch 23507, Loss 1.412654, Accuracy 0.468750\n","Batch 23508, Loss 1.755793, Accuracy 0.406250\n","Batch 23509, Loss 1.405136, Accuracy 0.593750\n","Batch 23510, Loss 1.365532, Accuracy 0.531250\n","Batch 23511, Loss 1.315248, Accuracy 0.562500\n","Batch 23512, Loss 1.903126, Accuracy 0.468750\n","Batch 23513, Loss 1.723871, Accuracy 0.437500\n","Batch 23514, Loss 2.281815, Accuracy 0.375000\n","Batch 23515, Loss 1.541416, Accuracy 0.593750\n","Batch 23516, Loss 1.977425, Accuracy 0.375000\n","Batch 23517, Loss 1.885876, Accuracy 0.343750\n","Batch 23518, Loss 2.238731, Accuracy 0.312500\n","Batch 23519, Loss 2.026780, Accuracy 0.375000\n","Batch 23520, Loss 2.190007, Accuracy 0.312500\n","Batch 23521, Loss 2.035281, Accuracy 0.312500\n","Batch 23522, Loss 2.189720, Accuracy 0.250000\n","Batch 23523, Loss 1.939114, Accuracy 0.406250\n","Batch 23524, Loss 2.028781, Accuracy 0.281250\n","Batch 23525, Loss 2.217688, Accuracy 0.156250\n","Batch 23526, Loss 2.154202, Accuracy 0.218750\n","Batch 23527, Loss 2.086752, Accuracy 0.187500\n","Batch 23528, Loss 2.052415, Accuracy 0.218750\n","Batch 23529, Loss 1.840317, Accuracy 0.406250\n","Batch 23530, Loss 1.956160, Accuracy 0.281250\n","Batch 23531, Loss 1.948240, Accuracy 0.218750\n","Batch 23532, Loss 1.873592, Accuracy 0.250000\n","Batch 23533, Loss 2.439158, Accuracy 0.125000\n","Batch 23534, Loss 2.043519, Accuracy 0.218750\n","Batch 23535, Loss 2.163988, Accuracy 0.187500\n","Batch 23536, Loss 2.500709, Accuracy 0.093750\n","Batch 23537, Loss 2.273323, Accuracy 0.343750\n","Batch 23538, Loss 2.313532, Accuracy 0.281250\n","Batch 23539, Loss 2.583843, Accuracy 0.125000\n","Batch 23540, Loss 1.842973, Accuracy 0.437500\n","Batch 23541, Loss 2.405587, Accuracy 0.218750\n","Batch 23542, Loss 2.595269, Accuracy 0.281250\n","Batch 23543, Loss 2.163712, Accuracy 0.437500\n","Batch 23544, Loss 2.245776, Accuracy 0.187500\n","Batch 23545, Loss 1.927100, Accuracy 0.312500\n","Batch 23546, Loss 1.935902, Accuracy 0.281250\n","Batch 23547, Loss 1.789922, Accuracy 0.312500\n","Batch 23548, Loss 1.746535, Accuracy 0.312500\n","Batch 23549, Loss 1.672962, Accuracy 0.312500\n","Batch 23550, Loss 1.643515, Accuracy 0.281250\n","Batch 23551, Loss 1.684582, Accuracy 0.218750\n","Batch 23552, Loss 1.468662, Accuracy 0.218750\n","Batch 23553, Loss 1.088772, Accuracy 0.437500\n","Batch 23554, Loss 1.232193, Accuracy 0.312500\n","Batch 23555, Loss 1.596454, Accuracy 0.187500\n","Batch 23556, Loss 1.773097, Accuracy 0.531250\n","Batch 23557, Loss 1.368163, Accuracy 0.562500\n","Batch 23558, Loss 2.162216, Accuracy 0.250000\n","Batch 23559, Loss 1.541257, Accuracy 0.437500\n","Batch 23560, Loss 1.492244, Accuracy 0.500000\n","Batch 23561, Loss 1.938752, Accuracy 0.468750\n","Batch 23562, Loss 1.628189, Accuracy 0.531250\n","Batch 23563, Loss 1.955783, Accuracy 0.218750\n","Batch 23564, Loss 2.253386, Accuracy 0.218750\n","Batch 23565, Loss 1.821577, Accuracy 0.375000\n","Batch 23566, Loss 1.546957, Accuracy 0.531250\n","Batch 23567, Loss 1.553136, Accuracy 0.468750\n","Batch 23568, Loss 1.801807, Accuracy 0.437500\n","Batch 23569, Loss 1.862866, Accuracy 0.250000\n","Batch 23570, Loss 1.840755, Accuracy 0.312500\n","Batch 23571, Loss 1.601532, Accuracy 0.343750\n","Batch 23572, Loss 1.722864, Accuracy 0.437500\n","Batch 23573, Loss 1.645815, Accuracy 0.343750\n","Batch 23574, Loss 1.498528, Accuracy 0.437500\n","Batch 23575, Loss 1.593913, Accuracy 0.250000\n","Batch 23576, Loss 1.689031, Accuracy 0.125000\n","Batch 23577, Loss 1.431895, Accuracy 0.187500\n","Batch 23578, Loss 1.329448, Accuracy 0.281250\n","Batch 23579, Loss 1.315036, Accuracy 0.375000\n","Batch 23580, Loss 1.216553, Accuracy 0.656250\n","Batch 23581, Loss 1.077152, Accuracy 0.625000\n","Batch 23582, Loss 1.251963, Accuracy 0.531250\n","Batch 23583, Loss 1.720878, Accuracy 0.468750\n","Batch 23584, Loss 1.519311, Accuracy 0.500000\n","Batch 23585, Loss 1.514222, Accuracy 0.500000\n","Batch 23586, Loss 1.320095, Accuracy 0.531250\n","Batch 23587, Loss 1.202170, Accuracy 0.656250\n","Batch 23588, Loss 1.381169, Accuracy 0.531250\n","Batch 23589, Loss 1.351929, Accuracy 0.437500\n","Batch 23590, Loss 1.200710, Accuracy 0.531250\n","Batch 23591, Loss 1.188265, Accuracy 0.437500\n","Batch 23592, Loss 1.712235, Accuracy 0.312500\n","Batch 23593, Loss 1.177500, Accuracy 0.500000\n","Batch 23594, Loss 1.349392, Accuracy 0.500000\n","Batch 23595, Loss 1.323804, Accuracy 0.437500\n","Batch 23596, Loss 1.346045, Accuracy 0.468750\n","Batch 23597, Loss 1.269692, Accuracy 0.562500\n","Batch 23598, Loss 1.528078, Accuracy 0.468750\n","Batch 23599, Loss 1.626029, Accuracy 0.437500\n","Batch 23600, Loss 1.406035, Accuracy 0.593750\n","Batch except\n","Batch except\n","Batch except\n","=================================================\n","Test, Loss 3.573478, Accuracy 0.166667\n","=================================================\n","Batch 23601, Loss 1.454172, Accuracy 0.437500\n","Batch 23602, Loss 1.301040, Accuracy 0.562500\n","Batch 23603, Loss 1.428058, Accuracy 0.593750\n","Batch 23604, Loss 1.247839, Accuracy 0.531250\n","Batch 23605, Loss 1.638889, Accuracy 0.468750\n","Batch 23606, Loss 1.088959, Accuracy 0.593750\n","Batch 23607, Loss 1.289355, Accuracy 0.500000\n","Batch 23608, Loss 3.648005, Accuracy 0.218750\n","Batch 23609, Loss 4.830807, Accuracy 0.000000\n","Batch 23610, Loss 4.038448, Accuracy 0.000000\n","Batch 23611, Loss 3.243474, Accuracy 0.000000\n","Batch 23612, Loss 2.520801, Accuracy 0.000000\n","Batch 23613, Loss 1.916320, Accuracy 0.000000\n","Batch 23614, Loss 1.568156, Accuracy 0.562500\n","Batch 23615, Loss 1.383421, Accuracy 0.875000\n","Batch 23616, Loss 1.321142, Accuracy 0.375000\n","Batch 23617, Loss 1.293258, Accuracy 0.468750\n","Batch 23618, Loss 1.280471, Accuracy 0.406250\n","Batch 23619, Loss 1.258857, Accuracy 0.500000\n","Batch 23620, Loss 1.224659, Accuracy 0.687500\n","Batch 23621, Loss 1.204596, Accuracy 0.468750\n","Batch 23622, Loss 1.187962, Accuracy 0.375000\n","Batch 23623, Loss 1.157362, Accuracy 0.437500\n","Batch 23624, Loss 1.142157, Accuracy 0.437500\n","Batch 23625, Loss 1.107734, Accuracy 0.531250\n","Batch 23626, Loss 1.082990, Accuracy 0.562500\n","Batch 23627, Loss 1.101208, Accuracy 0.593750\n","Batch 23628, Loss 1.168369, Accuracy 0.468750\n","Batch 23629, Loss 1.351104, Accuracy 0.312500\n","Batch 23630, Loss 1.393436, Accuracy 0.281250\n","Batch 23631, Loss 1.163940, Accuracy 0.500000\n","Batch 23632, Loss 1.347991, Accuracy 0.437500\n","Batch 23633, Loss 1.283341, Accuracy 0.406250\n","Batch 23634, Loss 1.494026, Accuracy 0.187500\n","Batch 23635, Loss 1.514057, Accuracy 0.125000\n","Batch 23636, Loss 1.222947, Accuracy 0.375000\n","Batch 23637, Loss 1.361966, Accuracy 0.250000\n","Batch 23638, Loss 1.328955, Accuracy 0.343750\n","Batch 23639, Loss 1.273863, Accuracy 0.406250\n","Batch 23640, Loss 1.273469, Accuracy 0.406250\n","Batch 23641, Loss 1.255057, Accuracy 0.437500\n","Batch 23642, Loss 1.274435, Accuracy 0.343750\n","Batch 23643, Loss 1.287297, Accuracy 0.250000\n","Batch 23644, Loss 1.250255, Accuracy 0.375000\n","Batch 23645, Loss 1.235027, Accuracy 0.375000\n","Batch 23646, Loss 1.226691, Accuracy 0.406250\n","Batch 23647, Loss 1.232262, Accuracy 0.250000\n","Batch 23648, Loss 1.222785, Accuracy 0.312500\n","Batch 23649, Loss 1.231899, Accuracy 0.562500\n","Batch 23650, Loss 1.169734, Accuracy 0.687500\n","Batch 23651, Loss 1.178550, Accuracy 0.500000\n","Batch 23652, Loss 1.209846, Accuracy 0.500000\n","Batch 23653, Loss 1.176536, Accuracy 0.531250\n","Batch 23654, Loss 1.243627, Accuracy 0.562500\n","Batch 23655, Loss 1.203666, Accuracy 0.437500\n","Batch 23656, Loss 1.259887, Accuracy 0.500000\n","Batch 23657, Loss 1.189283, Accuracy 0.562500\n","Batch 23658, Loss 1.386763, Accuracy 0.437500\n","Batch 23659, Loss 1.432044, Accuracy 0.406250\n","Batch 23660, Loss 1.694803, Accuracy 0.343750\n","Batch 23661, Loss 1.240417, Accuracy 0.562500\n","Batch 23662, Loss 1.179161, Accuracy 0.656250\n","Batch 23663, Loss 1.421044, Accuracy 0.406250\n","Batch 23664, Loss 1.386248, Accuracy 0.437500\n","Batch 23665, Loss 1.393557, Accuracy 0.437500\n","Batch 23666, Loss 1.628625, Accuracy 0.281250\n","Batch 23667, Loss 1.532236, Accuracy 0.375000\n","Batch 23668, Loss 1.535626, Accuracy 0.343750\n","Batch 23669, Loss 1.413450, Accuracy 0.437500\n","Batch 23670, Loss 1.459415, Accuracy 0.375000\n","Batch 23671, Loss 1.625235, Accuracy 0.218750\n","Batch 23672, Loss 1.564782, Accuracy 0.250000\n","Batch 23673, Loss 1.423237, Accuracy 0.312500\n","Batch 23674, Loss 1.274030, Accuracy 0.343750\n","Batch 23675, Loss 1.339951, Accuracy 0.343750\n","Batch 23676, Loss 1.265961, Accuracy 0.250000\n","Batch 23677, Loss 1.488181, Accuracy 0.125000\n","Batch 23678, Loss 1.244743, Accuracy 0.250000\n","Batch 23679, Loss 1.305001, Accuracy 0.375000\n","Batch 23680, Loss 1.586542, Accuracy 0.500000\n","Batch 23681, Loss 1.292880, Accuracy 0.718750\n","Batch 23682, Loss 1.413823, Accuracy 0.468750\n","Batch 23683, Loss 1.951300, Accuracy 0.218750\n","Batch 23684, Loss 1.611335, Accuracy 0.406250\n","Batch 23685, Loss 1.598225, Accuracy 0.468750\n","Batch 23686, Loss 1.431898, Accuracy 0.468750\n","Batch 23687, Loss 1.705700, Accuracy 0.406250\n","Batch 23688, Loss 1.823802, Accuracy 0.312500\n","Batch 23689, Loss 1.544068, Accuracy 0.406250\n","Batch 23690, Loss 1.618387, Accuracy 0.406250\n","Batch 23691, Loss 1.511907, Accuracy 0.406250\n","Batch 23692, Loss 1.604823, Accuracy 0.406250\n","Batch 23693, Loss 1.655036, Accuracy 0.343750\n","Batch 23694, Loss 1.744472, Accuracy 0.281250\n","Batch 23695, Loss 1.481403, Accuracy 0.437500\n","Batch 23696, Loss 1.550341, Accuracy 0.343750\n","Batch 23697, Loss 1.510734, Accuracy 0.343750\n","Batch 23698, Loss 1.483158, Accuracy 0.312500\n","Batch 23699, Loss 1.572031, Accuracy 0.187500\n","Batch 23700, Loss 1.568904, Accuracy 0.312500\n","Batch 23701, Loss 1.518973, Accuracy 0.218750\n","Batch 23702, Loss 1.591307, Accuracy 0.250000\n","Batch 23703, Loss 1.696389, Accuracy 0.343750\n","Batch 23704, Loss 1.434415, Accuracy 0.500000\n","Batch 23705, Loss 1.649674, Accuracy 0.437500\n","Batch 23706, Loss 1.417097, Accuracy 0.500000\n","Batch 23707, Loss 1.751254, Accuracy 0.312500\n","Batch 23708, Loss 1.519261, Accuracy 0.437500\n","Batch 23709, Loss 1.593734, Accuracy 0.343750\n","Batch 23710, Loss 1.574202, Accuracy 0.437500\n","Batch 23711, Loss 1.820845, Accuracy 0.218750\n","Batch 23712, Loss 1.633417, Accuracy 0.312500\n","Batch 23713, Loss 1.683026, Accuracy 0.343750\n","Batch 23714, Loss 1.611649, Accuracy 0.343750\n","Batch 23715, Loss 1.695558, Accuracy 0.312500\n","Batch 23716, Loss 1.600001, Accuracy 0.250000\n","Batch 23717, Loss 1.601242, Accuracy 0.250000\n","Batch 23718, Loss 1.442126, Accuracy 0.281250\n","Batch 23719, Loss 1.633411, Accuracy 0.218750\n","Batch 23720, Loss 1.751466, Accuracy 0.250000\n","Batch 23721, Loss 1.416017, Accuracy 0.218750\n","Batch 23722, Loss 1.346067, Accuracy 0.343750\n","Batch 23723, Loss 1.313368, Accuracy 0.406250\n","Batch 23724, Loss 1.370361, Accuracy 0.312500\n","Batch 23725, Loss 1.226768, Accuracy 0.562500\n","Batch 23726, Loss 1.336000, Accuracy 0.687500\n","Batch 23727, Loss 1.580201, Accuracy 0.375000\n","Batch 23728, Loss 1.612921, Accuracy 0.468750\n","Batch 23729, Loss 1.529130, Accuracy 0.562500\n","Batch 23730, Loss 1.936440, Accuracy 0.312500\n","Batch 23731, Loss 1.723524, Accuracy 0.406250\n","Batch 23732, Loss 1.730163, Accuracy 0.281250\n","Batch 23733, Loss 1.590358, Accuracy 0.343750\n","Batch 23734, Loss 1.645077, Accuracy 0.375000\n","Batch 23735, Loss 1.593820, Accuracy 0.281250\n","Batch 23736, Loss 1.495753, Accuracy 0.218750\n","Batch 23737, Loss 1.483356, Accuracy 0.343750\n","Batch 23738, Loss 1.370503, Accuracy 0.468750\n","Batch 23739, Loss 1.087780, Accuracy 0.687500\n","Batch 23740, Loss 1.444136, Accuracy 0.375000\n","Batch 23741, Loss 1.537738, Accuracy 0.406250\n","Batch 23742, Loss 1.177220, Accuracy 0.468750\n","Batch 23743, Loss 1.493295, Accuracy 0.406250\n","Batch 23744, Loss 1.482674, Accuracy 0.406250\n","Batch 23745, Loss 1.428369, Accuracy 0.531250\n","Batch 23746, Loss 1.357409, Accuracy 0.531250\n","Batch 23747, Loss 1.940552, Accuracy 0.375000\n","Batch 23748, Loss 1.140625, Accuracy 0.687500\n","Batch 23749, Loss 1.839703, Accuracy 0.562500\n","Batch 23750, Loss 1.622326, Accuracy 0.375000\n","Batch 23751, Loss 1.648748, Accuracy 0.406250\n","Batch 23752, Loss 2.022149, Accuracy 0.437500\n","Batch 23753, Loss 1.929989, Accuracy 0.343750\n","Batch 23754, Loss 1.717669, Accuracy 0.437500\n","Batch 23755, Loss 1.701708, Accuracy 0.312500\n","Batch 23756, Loss 1.578862, Accuracy 0.468750\n","Batch 23757, Loss 1.578295, Accuracy 0.406250\n","Batch 23758, Loss 1.922702, Accuracy 0.312500\n","Batch 23759, Loss 1.799765, Accuracy 0.406250\n","Batch 23760, Loss 1.692794, Accuracy 0.468750\n","Batch 23761, Loss 1.750485, Accuracy 0.312500\n","Batch 23762, Loss 1.837293, Accuracy 0.218750\n","Batch 23763, Loss 1.686724, Accuracy 0.281250\n","Batch 23764, Loss 1.549469, Accuracy 0.375000\n","Batch 23765, Loss 1.611506, Accuracy 0.281250\n","Batch 23766, Loss 1.561108, Accuracy 0.250000\n","Batch 23767, Loss 1.369479, Accuracy 0.218750\n","Batch 23768, Loss 1.252941, Accuracy 0.250000\n","Batch 23769, Loss 1.288962, Accuracy 0.281250\n","Batch 23770, Loss 1.456913, Accuracy 0.375000\n","Batch 23771, Loss 1.663001, Accuracy 0.468750\n","Batch 23772, Loss 1.387890, Accuracy 0.656250\n","Batch 23773, Loss 1.247367, Accuracy 0.656250\n","Batch 23774, Loss 1.315408, Accuracy 0.500000\n","Batch 23775, Loss 1.726264, Accuracy 0.531250\n","Batch 23776, Loss 2.180040, Accuracy 0.406250\n","Batch 23777, Loss 1.762957, Accuracy 0.500000\n","Batch 23778, Loss 2.238358, Accuracy 0.343750\n","Batch 23779, Loss 1.874885, Accuracy 0.406250\n","Batch 23780, Loss 1.668759, Accuracy 0.437500\n","Batch 23781, Loss 1.952117, Accuracy 0.312500\n","Batch 23782, Loss 1.379947, Accuracy 0.562500\n","Batch 23783, Loss 1.705892, Accuracy 0.343750\n","Batch 23784, Loss 1.858903, Accuracy 0.343750\n","Batch 23785, Loss 2.033903, Accuracy 0.250000\n","Batch 23786, Loss 2.062266, Accuracy 0.250000\n","Batch 23787, Loss 1.647129, Accuracy 0.312500\n","Batch 23788, Loss 1.697339, Accuracy 0.375000\n","Batch 23789, Loss 1.479074, Accuracy 0.468750\n","Batch 23790, Loss 1.651368, Accuracy 0.281250\n","Batch 23791, Loss 1.665931, Accuracy 0.375000\n","Batch 23792, Loss 1.747233, Accuracy 0.156250\n","Batch 23793, Loss 1.757750, Accuracy 0.187500\n","Batch 23794, Loss 1.537562, Accuracy 0.281250\n","Batch 23795, Loss 1.564071, Accuracy 0.187500\n","Batch 23796, Loss 1.726670, Accuracy 0.187500\n","Batch 23797, Loss 1.690648, Accuracy 0.187500\n","Batch 23798, Loss 1.847134, Accuracy 0.218750\n","Batch 23799, Loss 1.960320, Accuracy 0.062500\n","Batch 23800, Loss 1.881193, Accuracy 0.250000\n","Batch except\n","Batch except\n","Batch except\n","=================================================\n","Test, Loss 3.055299, Accuracy 0.177083\n","=================================================\n","Batch 23801, Loss 1.573084, Accuracy 0.343750\n","Batch 23802, Loss 1.665139, Accuracy 0.437500\n","Batch 23803, Loss 2.032026, Accuracy 0.312500\n","Batch 23804, Loss 1.599930, Accuracy 0.531250\n","Batch 23805, Loss 1.638880, Accuracy 0.375000\n","Batch 23806, Loss 1.775723, Accuracy 0.343750\n","Batch 23807, Loss 1.479682, Accuracy 0.500000\n","Batch 23808, Loss 1.413809, Accuracy 0.375000\n","Batch 23809, Loss 1.658132, Accuracy 0.343750\n","Batch 23810, Loss 1.421924, Accuracy 0.437500\n","Batch 23811, Loss 1.670497, Accuracy 0.375000\n","Batch 23812, Loss 1.629175, Accuracy 0.281250\n","Batch 23813, Loss 1.397913, Accuracy 0.281250\n","Batch 23814, Loss 1.732160, Accuracy 0.281250\n","Batch 23815, Loss 1.285021, Accuracy 0.281250\n","Batch 23816, Loss 1.675974, Accuracy 0.406250\n","Batch 23817, Loss 1.457828, Accuracy 0.531250\n","Batch 23818, Loss 1.651366, Accuracy 0.468750\n","Batch 23819, Loss 1.425081, Accuracy 0.500000\n","Batch 23820, Loss 1.559653, Accuracy 0.375000\n","Batch 23821, Loss 1.698401, Accuracy 0.468750\n","Batch 23822, Loss 1.135995, Accuracy 0.687500\n","Batch 23823, Loss 1.387063, Accuracy 0.500000\n","Batch 23824, Loss 1.729114, Accuracy 0.375000\n","Batch 23825, Loss 1.467453, Accuracy 0.531250\n","Batch 23826, Loss 1.564039, Accuracy 0.343750\n","Batch 23827, Loss 1.118867, Accuracy 0.562500\n","Batch 23828, Loss 1.291444, Accuracy 0.625000\n","Batch 23829, Loss 1.357902, Accuracy 0.562500\n","Batch 23830, Loss 1.413256, Accuracy 0.500000\n","Batch 23831, Loss 1.193843, Accuracy 0.531250\n","Batch 23832, Loss 1.268758, Accuracy 0.625000\n","Batch 23833, Loss 1.283452, Accuracy 0.625000\n","Batch 23834, Loss 1.428464, Accuracy 0.468750\n","Batch 23835, Loss 1.277700, Accuracy 0.593750\n","Batch 23836, Loss 1.357432, Accuracy 0.531250\n","Batch 23837, Loss 1.267358, Accuracy 0.562500\n","Batch 23838, Loss 1.163482, Accuracy 0.562500\n","Batch 23839, Loss 1.055384, Accuracy 0.625000\n","Batch 23840, Loss 1.421304, Accuracy 0.406250\n","Batch 23841, Loss 1.403114, Accuracy 0.468750\n","Batch 23842, Loss 1.570124, Accuracy 0.375000\n","Batch 23843, Loss 1.285597, Accuracy 0.562500\n","Batch 23844, Loss 1.359373, Accuracy 0.500000\n","Batch 23845, Loss 1.282495, Accuracy 0.531250\n","Batch 23846, Loss 1.305161, Accuracy 0.535714\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rb6Qp4eNDSUW","colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"status":"ok","timestamp":1592460678810,"user_tz":-480,"elapsed":2736,"user":{"displayName":"SM Health","photoUrl":"","userId":"14421832128980954224"}},"outputId":"ed8a0cda-b230-4ea7-946b-c14aa1ac6c9c"},"source":["!ls -la '/content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/models/'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["total 369623\n","drwx------ 2 root root     4096 Jun  3 08:23  assets\n","-rw------- 1 root root 94621224 Jun  4 01:55 'Copy of github_yeyupiaoling_resnet50.h5'\n","-rw------- 1 root root 94621112 Jun  4 01:55 'Copy of resnet50.h5'\n","-rw------- 1 root root 94621224 May 29 04:37  github_yeyupiaoling_resnet50.h5\n","-rw------- 1 root root 94621112 Jun 17 03:26  resnet50.h5\n","drwx------ 2 root root     4096 Jun  3 08:23  variables\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UjTmRwFCwvbr","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592460592347,"user_tz":-480,"elapsed":79070,"user":{"displayName":"SM Health","photoUrl":"","userId":"14421832128980954224"}},"outputId":"37348ef8-0e95-4e51-c5c5-1df300023d11"},"source":["# predict.py\n","\n","\n","import librosa\n","import numpy as np\n","import tensorflow as tf\n","import os\n","\n","# model_path = '/content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/models/github_yeyupiaoling_resnet50.h5' # yeyupiaoling作者的模型, 准确率高\n","model_path = '/content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/models/resnet50.h5' # 自己训练的模型，准确率低\n","model = tf.keras.models.load_model(model_path)\n","\n","# 读取音频数据\n","def load_data(data_path):\n","    wav, sr = librosa.load(data_path, sr=16000)\n","    intervals = librosa.effects.split(wav, top_db=20)\n","    wav_output = []\n","    for sliced in intervals:\n","        wav_output.extend(wav[sliced[0]:sliced[1]])\n","    assert len(wav_output) >= 8000, \"有效音频小于0.5s\"\n","    wav_output = np.array(wav_output)\n","    ps = librosa.feature.melspectrogram(y=wav_output, sr=sr, hop_length=256).astype(np.float32)\n","    ps = ps[np.newaxis, ..., np.newaxis]\n","    return ps\n","\n","\n","def infer(audio_path):\n","    print('infer：audio_path %s' % (audio_path))\n","\n","    data = load_data(audio_path)\n","    result = model.predict(data)\n","    print('infer：result %s' % (result))\n","\n","    max = np.max(result, axis=1)\n","    print('infer：max %s' % (max))\n","\n","    index = np.argmax(result, axis=1)\n","    print('infer：index %s' % (index))\n","\n","    # predict_dataset = tf.convert_to_tensor(result)\n","    # print('infer：predict_dataset %s' % (predict_dataset))\n","\n","    # predictions = model(predict_dataset)\n","    # print('infer：predictions %s' % (predictions))\n","\n","    # class_idx = tf.argmax(predictions).numpy()\n","    # p = tf.nn.softmax(predictions)[class_idx]\n","    # print('infer：class_idx %s' % (class_idx))\n","\n","    lab = tf.argmax(result, 1, output_type=tf.int32)\n","    print('infer：argmax %s' % (lab))\n","\n","    # argmax2 = tf.argmax(predict_dataset, 1, output_type=tf.float32)\n","    # print('infer：argmax2 %s' % (argmax2))\n","\n","    return lab\n","\n","\n","\n","def infer2(audio_path):\n","    print('infer2：audio_path %s' % (audio_path))\n","\n","    data = load_data(audio_path)\n","    result = model.predict(data)\n","    print('infer2：result %s' % (result))\n","\n","    max = np.max(result, axis=1)\n","    print('infer2：max %s' % (max))\n","\n","    index = np.argmax(result, axis=1)\n","    print('infer2：index %s' % (index))\n","\n","    labels = ['air_conditioner', 'car_horn', 'children_playing', 'dog_bark', 'drilling', 'engine_idling', 'gun_shot', 'jackhammer', 'siren', 'street_music']\n","    #          0                     1            2                      3            4              5                  6             7               8         9\n","    print('infer2：labels %s' % labels[int(index)])\n","\n","\n","    return index\n","\n","\n","if __name__ == '__main__':\n","\n","    print('model_path %s ' % (model_path))\n","\n","    # 要预测的音频文件\n","    # path = 'F:/Downloads/UrbanSound8K/predict/fold5.wav'fold8-4918-3-0-0.wav\n","    # path = 'F:/Downloads/UrbanSound8K/predict/fold8-4918-3-0-0.wav'\n","    # path = 'F:/Downloads/UrbanSound8K/predict/fold8-17009-2-0-4.wav'\n","    # path = 'F:/Downloads/UrbanSound8K/predict/fold8-17009-2-0-10.wav'\n","\n","    # path = '/content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/server'\n","    path = '/content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict'\n","    wav_list = os.listdir(path)\n","    for wav in wav_list:\n","        print('音频：########################################################')\n","        uri = os.path.join(path, wav)\n","        print('音频：uri %s' % (uri))\n","\n","        try:\n","\n","            # label = infer(uri)\n","            # labels = ['air_conditioner', 'car_horn', 'children_playing', 'dog_bark', 'drilling', 'engine_idling', 'gun_shot', 'jackhammer', 'siren', 'street_music']\n","            #          0                     1                      2             3            4                   5             6               7             8         9\n","            index = infer2(uri)\n","            # print('音频：%s 的预测结果标签为：index %d' % index)\n","            # print('音频：%s 的预测结果标签为：%s' % (path, labels[index]))\n","\n","        except:\n","            print('音频：except')\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","model_path /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/models/resnet50.h5 \n","音频：########################################################\n","音频：uri /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/7061-6-0-0.wav\n","infer2：audio_path /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/7061-6-0-0.wav\n","infer2：result [[0.02111227 0.01462406 0.0033954  0.00572845 0.02343955 0.04079945\n","  0.07555167 0.35237265 0.3899884  0.07298808]]\n","infer2：max [0.3899884]\n","infer2：index [8]\n","infer2：labels siren\n","音频：########################################################\n","音频：uri /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/fold10-7965-3-11-0.wav\n","infer2：audio_path /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/fold10-7965-3-11-0.wav\n","infer2：result [[0.03738586 0.02860939 0.00855223 0.0106274  0.03207279 0.05144677\n","  0.08822538 0.33424968 0.3269789  0.08185166]]\n","infer2：max [0.33424968]\n","infer2：index [7]\n","infer2：labels jackhammer\n","音频：########################################################\n","音频：uri /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/fold5.wav\n","infer2：audio_path /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/fold5.wav\n","infer2：result [[0.0210097  0.0145457  0.00337272 0.00570379 0.02339331 0.04073357\n","  0.07547386 0.35251054 0.3903793  0.07287759]]\n","infer2：max [0.3903793]\n","infer2：index [8]\n","infer2：labels siren\n","音频：########################################################\n","音频：uri /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/fold8-17009-2-0-10.wav\n","infer2：audio_path /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/fold8-17009-2-0-10.wav\n","infer2：result [[0.0210097  0.0145457  0.00337272 0.00570379 0.02339331 0.04073357\n","  0.07547386 0.35251054 0.3903793  0.07287759]]\n","infer2：max [0.3903793]\n","infer2：index [8]\n","infer2：labels siren\n","音频：########################################################\n","音频：uri /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/fold8-17009-2-0-4.wav\n","infer2：audio_path /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/fold8-17009-2-0-4.wav\n","infer2：result [[0.0210097  0.0145457  0.00337272 0.00570379 0.02339331 0.04073357\n","  0.07547386 0.35251054 0.3903793  0.07287759]]\n","infer2：max [0.3903793]\n","infer2：index [8]\n","infer2：labels siren\n","音频：########################################################\n","音频：uri /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/fold8-4918-3-0-0.wav\n","infer2：audio_path /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/fold8-4918-3-0-0.wav\n","音频：except\n","音频：########################################################\n","音频：uri /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/7063-6-0-0.wav\n","infer2：audio_path /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/7063-6-0-0.wav\n","infer2：result [[0.03738586 0.02860939 0.00855223 0.0106274  0.03207279 0.05144677\n","  0.08822538 0.33424968 0.3269789  0.08185166]]\n","infer2：max [0.33424968]\n","infer2：index [7]\n","infer2：labels jackhammer\n","音频：########################################################\n","音频：uri /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/dahaqian.wav\n","infer2：audio_path /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/dahaqian.wav\n","WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f56ea780510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","infer2：result [[0.0210097  0.0145457  0.00337272 0.00570379 0.02339331 0.04073357\n","  0.07547386 0.35251054 0.3903793  0.07287759]]\n","infer2：max [0.3903793]\n","infer2：index [8]\n","infer2：labels siren\n","音频：########################################################\n","音频：uri /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/dahaqian.mp3\n","infer2：audio_path /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/dahaqian.mp3\n","infer2：result [[0.0210097  0.0145457  0.00337272 0.00570379 0.02339331 0.04073357\n","  0.07547386 0.35251054 0.3903793  0.07287759]]\n","infer2：max [0.3903793]\n","infer2：index [8]\n","infer2：labels siren\n","音频：########################################################\n","音频：uri /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/gou2248.wav\n","infer2：audio_path /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/gou2248.wav\n","WARNING:tensorflow:6 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f56ea780510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","infer2：result [[0.0210097  0.0145457  0.00337272 0.00570379 0.02339331 0.04073357\n","  0.07547386 0.35251054 0.3903793  0.07287759]]\n","infer2：max [0.3903793]\n","infer2：index [8]\n","infer2：labels siren\n","音频：########################################################\n","音频：uri /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/gou2217.wav\n","infer2：audio_path /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/gou2217.wav\n","WARNING:tensorflow:7 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f56ea780510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","infer2：result [[0.0210097  0.0145457  0.00337272 0.00570379 0.02339331 0.04073357\n","  0.07547386 0.35251054 0.3903793  0.07287759]]\n","infer2：max [0.3903793]\n","infer2：index [8]\n","infer2：labels siren\n","音频：########################################################\n","音频：uri /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/gou1570.wav\n","infer2：audio_path /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/gou1570.wav\n","WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f56ea780510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","infer2：result [[0.0210097  0.0145457  0.00337272 0.00570379 0.02339331 0.04073357\n","  0.07547386 0.35251054 0.3903793  0.07287759]]\n","infer2：max [0.3903793]\n","infer2：index [8]\n","infer2：labels siren\n","音频：########################################################\n","音频：uri /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/gou1886.wav\n","infer2：audio_path /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/gou1886.wav\n","WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f56ea780510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","infer2：result [[0.0210097  0.0145457  0.00337272 0.00570379 0.02339331 0.04073357\n","  0.07547386 0.35251054 0.3903793  0.07287759]]\n","infer2：max [0.3903793]\n","infer2：index [8]\n","infer2：labels siren\n","音频：########################################################\n","音频：uri /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/gou939.wav\n","infer2：audio_path /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/gou939.wav\n","WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f56ea780510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","infer2：result [[0.0210097  0.0145457  0.00337272 0.00570379 0.02339331 0.04073357\n","  0.07547386 0.35251054 0.3903793  0.07287759]]\n","infer2：max [0.3903793]\n","infer2：index [8]\n","infer2：labels siren\n","音频：########################################################\n","音频：uri /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/gou1421.wav\n","infer2：audio_path /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/gou1421.wav\n","WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f56ea780510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","infer2：result [[0.0210097  0.0145457  0.00337272 0.00570379 0.02339331 0.04073357\n","  0.07547386 0.35251054 0.3903793  0.07287759]]\n","infer2：max [0.3903793]\n","infer2：index [8]\n","infer2：labels siren\n","音频：########################################################\n","音频：uri /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/gou2069.wav\n","infer2：audio_path /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/gou2069.wav\n","WARNING:tensorflow:10 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f56ea780510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","infer2：result [[0.03738586 0.02860939 0.00855223 0.0106274  0.03207279 0.05144677\n","  0.08822538 0.33424968 0.3269789  0.08185166]]\n","infer2：max [0.33424968]\n","infer2：index [7]\n","infer2：labels jackhammer\n","音频：########################################################\n","音频：uri /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/baby11239.wav\n","infer2：audio_path /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/baby11239.wav\n","WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f56ea780510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","infer2：result [[0.0210097  0.0145457  0.00337272 0.00570379 0.02339331 0.04073357\n","  0.07547386 0.35251054 0.3903793  0.07287759]]\n","infer2：max [0.3903793]\n","infer2：index [8]\n","infer2：labels siren\n","音频：########################################################\n","音频：uri /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/baby11119.wav\n","infer2：audio_path /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/baby11119.wav\n","WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f56ea780510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","infer2：result [[0.0210097  0.0145457  0.00337272 0.00570379 0.02339331 0.04073357\n","  0.07547386 0.35251054 0.3903793  0.07287759]]\n","infer2：max [0.3903793]\n","infer2：index [8]\n","infer2：labels siren\n","音频：########################################################\n","音频：uri /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/baby1446.wav\n","infer2：audio_path /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/baby1446.wav\n","WARNING:tensorflow:11 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f56ea780510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","infer2：result [[0.0210097  0.0145457  0.00337272 0.00570379 0.02339331 0.04073357\n","  0.07547386 0.35251054 0.3903793  0.07287759]]\n","infer2：max [0.3903793]\n","infer2：index [8]\n","infer2：labels siren\n","音频：########################################################\n","音频：uri /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/car9529.wav\n","infer2：audio_path /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/car9529.wav\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f56ea780510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","infer2：result [[0.03738586 0.02860939 0.00855223 0.0106274  0.03207279 0.05144677\n","  0.08822538 0.33424968 0.3269789  0.08185166]]\n","infer2：max [0.33424968]\n","infer2：index [7]\n","infer2：labels jackhammer\n","音频：########################################################\n","音频：uri /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/car11935.wav\n","infer2：audio_path /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/car11935.wav\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f56ea780510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","infer2：result [[0.02163251 0.01499188 0.00348152 0.00581234 0.02353859 0.04092455\n","  0.07561965 0.35113356 0.3889414  0.07392402]]\n","infer2：max [0.3889414]\n","infer2：index [8]\n","infer2：labels siren\n","音频：########################################################\n","音频：uri /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/car5747.wav\n","infer2：audio_path /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/car5747.wav\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f56ea780510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","infer2：result [[0.02111227 0.01462406 0.0033954  0.00572845 0.02343955 0.04079945\n","  0.07555167 0.35237265 0.3899884  0.07298808]]\n","infer2：max [0.3899884]\n","infer2：index [8]\n","infer2：labels siren\n","音频：########################################################\n","音频：uri /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/car9275.wav\n","infer2：audio_path /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/car9275.wav\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f56ea780510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","infer2：result [[0.02111227 0.01462406 0.0033954  0.00572845 0.02343955 0.04079945\n","  0.07555167 0.35237265 0.3899884  0.07298808]]\n","infer2：max [0.3899884]\n","infer2：index [8]\n","infer2：labels siren\n","音频：########################################################\n","音频：uri /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/car10047.wav\n","infer2：audio_path /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/car10047.wav\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f56ea780510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","infer2：result [[0.03738586 0.02860939 0.00855223 0.0106274  0.03207279 0.05144677\n","  0.08822538 0.33424968 0.3269789  0.08185166]]\n","infer2：max [0.33424968]\n","infer2：index [7]\n","infer2：labels jackhammer\n","音频：########################################################\n","音频：uri /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/car1122.wav\n","infer2：audio_path /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/car1122.wav\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f56ea780510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","infer2：result [[0.03738586 0.02860939 0.00855223 0.0106274  0.03207279 0.05144677\n","  0.08822538 0.33424968 0.3269789  0.08185166]]\n","infer2：max [0.33424968]\n","infer2：index [7]\n","infer2：labels jackhammer\n","音频：########################################################\n","音频：uri /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/car8487.wav\n","infer2：audio_path /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/car8487.wav\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f56ea780510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","infer2：result [[0.0210097  0.0145457  0.00337272 0.00570379 0.02339331 0.04073357\n","  0.07547386 0.35251054 0.3903793  0.07287759]]\n","infer2：max [0.3903793]\n","infer2：index [8]\n","infer2：labels siren\n","音频：########################################################\n","音频：uri /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/car3697.wav\n","infer2：audio_path /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/car3697.wav\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f56ea780510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","infer2：result [[0.0210097  0.0145457  0.00337272 0.00570379 0.02339331 0.04073357\n","  0.07547386 0.35251054 0.3903793  0.07287759]]\n","infer2：max [0.3903793]\n","infer2：index [8]\n","infer2：labels siren\n","音频：########################################################\n","音频：uri /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/car_119_10785.wav\n","infer2：audio_path /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/car_119_10785.wav\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f56ea780510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n","infer2：result [[0.0210097  0.0145457  0.00337272 0.00570379 0.02339331 0.04073357\n","  0.07547386 0.35251054 0.3903793  0.07287759]]\n","infer2：max [0.3903793]\n","infer2：index [8]\n","infer2：labels siren\n","音频：########################################################\n","音频：uri /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/server\n","infer2：audio_path /content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/predict/server\n","音频：except\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bVCQWRjlG8cU","colab":{"base_uri":"https://localhost:8080/","height":395},"executionInfo":{"status":"error","timestamp":1591590458441,"user_tz":-480,"elapsed":945,"user":{"displayName":"SM Health","photoUrl":"","userId":"14421832128980954224"}},"outputId":"6ab8f9ce-2ad6-4125-82c4-602bdca8d7dc"},"source":["# tensorflow_lite_convertor.py\n","\n","# https://www.tensorflow.org/lite/convert/python_api?hl=zh-cn\n","\n","\n","# # -3\n","import tensorflow as tf\n","\n","converter = tf.lite.TFLiteConverter.from_saved_model('/content/drive/My Drive/audio_classifier_tutorial/inception_dec_2015')\n","# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n","tflite_model = converter.convert()\n","open(\"converted_model.tflite\", \"wb\").write(tflite_model)\n","\n","\n","# # -2\n","# from tensorflow.contrib import lite\n","# converter = lite.TFLiteConverter.from_saved_model('/content/drive/My Drive/audio_classifier_tutorial/inception_dec_2015/tensorflow_inception_graph.pb')\n","# tfmodel = converter.convert()\n","# open (\"model.tflite\" , \"wb\") .write(tfmodel)\n","\n","# import tensorflow as tf\n","\n","# # https://www.tensorflow.org/tutorials/keras/save_and_load\n","# # 重新创建完全相同的模型，包括其权重和优化程序\n","# new_model = tf.keras.models.load_model('/content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/models/github_yeyupiaoling_resnet50.h5')\n","# # 显示网络结构\n","# new_model.summary()\n","\n","# converter = tf.lite.TFLiteConverter.from_keras_model(new_model)\n","# tflite_model = converter.convert()\n","\n","\n","# -1\n","# !tflite_convert --output_file='/content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/models/foo.tflite' --keras_model_file='/content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/models/github_yeyupiaoling_resnet50.h5'\n","\n","# 0\n","# import tensorflow as tf\n","\n","# # 建立一个简单的模型。\n","# # root = tf.train.Checkpoint()\n","# # root.v1 = tf.Variable(3.)\n","# # root.v2 = tf.Variable(2.)\n","# # root.f = tf.function(lambda x: root.v1 * root.v2 * x)\n","\n","# # 保存模型。\n","# export_dir = \"/content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/models\"\n","# # input_data = tf.constant(1., shape=[1, 1])\n","# # to_save = root.f.get_concrete_function(input_data)\n","# # tf.saved_model.save(root, export_dir, to_save)\n","\n","# # 转换模型。\n","# converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n","# tflite_model = converter.convert()\n","\n","\n","# 1\n","# import tensorflow as tf\n","\n","# # 建立一个简单的模型。\n","# root = tf.train.Checkpoint()\n","# root.v1 = tf.Variable(3.)\n","# root.v2 = tf.Variable(2.)\n","# root.f = tf.function(lambda x: root.v1 * root.v2 * x)\n","\n","# # 保存模型。\n","# model_path = '/content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/models' # yeyupiaoling作者的模型, 准确率高\n","# export_dir = model_path\n","# # input_data = tf.constant(1., shape=[1, 1])\n","# # to_save = root.f.get_concrete_function(input_data)\n","# # tf.saved_model.save(root, export_dir, to_save)\n","\n","# # 转换模型。\n","# model = tf.saved_model.load(export_dir)\n","# concrete_func = model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n","# concrete_func.inputs[0].set_shape([1, 256, 256, 3])\n","# converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n","\n","# # converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n","# tflite_model = converter.convert()\n","\n","\n","# 2\n","# import tensorflow as tf\n","#\n","# # 创建一个简单的 Keras 模型。\n","# x = [-1, 0, 1, 2, 3, 4]\n","# y = [-3, -1, 1, 3, 5, 7]\n","#\n","# model = tf.keras.models.Sequential(\n","#     [tf.keras.layers.Dense(units=1, input_shape=[1])])\n","# model.compile(optimizer='sgd', loss='mean_squared_error')\n","# model.fit(x, y, epochs=50)\n","#\n","# # 转换模型。\n","# converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","# tflite_model = converter.convert()\n","\n","\n","\n","# 3\n","# import tensorflow as tf\n","\n","# # 建立一个模型。\n","# root = tf.train.Checkpoint()\n","# root.v1 = tf.Variable(3.)\n","# root.v2 = tf.Variable(2.)\n","# root.f = tf.function(lambda x: root.v1 * root.v2 * x)\n","\n","# # 生成 concrete function。\n","# input_data = tf.constant(1., shape=[1, 1])\n","# concrete_func = root.f.get_concrete_function(input_data)\n","\n","# # 转换模型。\n","# #\n","# # `from_concrete_function` 的传入参数被设计为一个一个 concrete function 的列表，然而\n","# # 现阶段仅支持每次调用时仅接受一个concrete function。\n","# # 同时转换多个concrete function的功能正在开发中。\n","# converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n","# tflite_model = converter.convert()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-ea35781a14ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/audio_classifier_tutorial/inception_dec_2015'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mfrom_saved_model\u001b[0;34m(cls, saved_model_dir, signature_keys, tags)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0;31m# in order to create a tf.estimator.Exporter that exports a TFLite model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m       \u001b[0msaved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignature_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m       \u001b[0msignature_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(export_dir, tags)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0ma\u001b[0m \u001b[0mMetaGraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSavedModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m   \"\"\"\n\u001b[0;32m--> 578\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_internal\u001b[0;34m(export_dir, tags, loader_cls)\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m   saved_model_proto, debug_info = (\n\u001b[0;32m--> 588\u001b[0;31m       loader_impl.parse_saved_model_with_debug_info(export_dir))\n\u001b[0m\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m   if (len(saved_model_proto.meta_graphs) == 1 and\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model_with_debug_info\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mMissing\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0minfo\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mfine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \"\"\"\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0msaved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m   debug_info_path = os.path.join(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    111\u001b[0m                   (export_dir,\n\u001b[1;32m    112\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: /content/drive/My Drive/audio_classifier_tutorial/inception_dec_2015/{saved_model.pbtxt|saved_model.pb}"]}]},{"cell_type":"code","metadata":{"id":"3ln2kUC9yii1","colab":{"base_uri":"https://localhost:8080/","height":395},"executionInfo":{"status":"error","timestamp":1591584950237,"user_tz":-480,"elapsed":1310,"user":{"displayName":"SM Health","photoUrl":"","userId":"14421832128980954224"}},"outputId":"301500f1-9aad-4044-8d4b-a8c4ebfc02aa"},"source":["# https://www.cnblogs.com/chenzhen0530/p/10685944.html\n","\n","#*-coding:utf-8-*\n","\n","\"\"\"\n","将keras的.h5的模型文件，转换成TensorFlow的pb文件\n","\"\"\"\n","# ==========================================================\n","\n","# from keras.models import load_model\n","import keras\n","import tensorflow as tf\n","import os\n","from keras import backend\n","\n","\n","def h5_to_pb(h5_model, output_dir, model_name, out_prefix=\"output_\", log_tensorboard=True):\n","    \"\"\".h5模型文件转换成pb模型文件\n","    Argument:\n","        h5_model: str\n","            .h5模型文件\n","        output_dir: str\n","            pb模型文件保存路径\n","        model_name: str\n","            pb模型文件名称\n","        out_prefix: str\n","            根据训练，需要修改\n","        log_tensorboard: bool\n","            是否生成日志文件\n","    Return:\n","        pb模型文件\n","    \"\"\"\n","    if os.path.exists(output_dir) == False:\n","        os.mkdir(output_dir)\n","    out_nodes = []\n","    for i in range(len(h5_model.outputs)):\n","        out_nodes.append(out_prefix + str(i + 1))\n","        tf.identity(h5_model.output[i], out_prefix + str(i + 1))\n","    sess = backend.get_session()\n","\n","    from tensorflow.python.framework import graph_util, graph_io\n","    # 写入pb模型文件\n","    init_graph = sess.graph.as_graph_def()\n","    main_graph = graph_util.convert_variables_to_constants(sess, init_graph, out_nodes)\n","    graph_io.write_graph(main_graph, output_dir, name=model_name, as_text=False)\n","    # 输出日志文件\n","    if log_tensorboard:\n","        from tensorflow.python.tools import import_pb_to_tensorboard\n","        import_pb_to_tensorboard.import_to_tensorboard(os.path.join(output_dir, model_name), output_dir)\n","\n","\n","if __name__ == '__main__':\n","    #  .h模型文件路径参数\n","    input_path = '/content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/models/'\n","    weight_file = 'github_yeyupiaoling_resnet50.h5'\n","    weight_file_path = os.path.join(input_path, weight_file)\n","    output_graph_name = weight_file[:-3] + '.pb'\n","\n","    #  pb模型文件输出输出路径\n","    output_dir = os.path.join(os.getcwd(), \"/content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/models/\")\n","\n","    #  加载模型\n","    h5_model = load_model(weight_file_path)\n","    h5_to_pb(h5_model, output_dir=output_dir, model_name=output_graph_name)\n","    print('Finished')"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-69f1f9ee4275>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m#  加载模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mh5_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mh5_to_pb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_graph_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Finished'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'write'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_deserialize_model\u001b[0;34m(h5dict, custom_objects, compile)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m     \u001b[0mmodel_weights_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    625\u001b[0m                         '`Sequential.from_config(config)`?')\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    145\u001b[0m                     \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                     custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n\u001b[0;32m--> 147\u001b[0;31m                                         list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mconf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_configs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             layer = layer_module.deserialize(conf,\n\u001b[0;32m--> 301\u001b[0;31m                                              custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m    302\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbuild_input_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    145\u001b[0m                     \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                     custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n\u001b[0;32m--> 147\u001b[0;31m                                         list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0;31m# First, we create all layers and enqueue nodes to be processed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'layers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mprocess_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;31m# Then we process nodes in order of layer depth.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mprocess_layer\u001b[0;34m(layer_data)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             layer = deserialize_layer(layer_data,\n\u001b[0;32m-> 1042\u001b[0;31m                                       custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0mcreated_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    147\u001b[0m                                         list(custom_objects.items())))\n\u001b[1;32m    148\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;31m# Then `cls` may be a function returning a class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m   1177\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \"\"\"\n\u001b[0;32m-> 1179\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcount_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0mkernel_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0mbias_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, rank, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_initializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_initializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_initializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_regularizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/initializers.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'config'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/initializers.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    508\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                                     printable_module_name='initializer')\n\u001b[0m\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 raise ValueError('Unknown ' + printable_module_name +\n\u001b[0;32m--> 140\u001b[0;31m                                  ': ' + class_name)\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mcustom_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_objects\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Unknown initializer: GlorotUniform"]}]},{"cell_type":"code","metadata":{"id":"LtvVmD1h3Oj2","colab":{"base_uri":"https://localhost:8080/","height":415},"executionInfo":{"status":"error","timestamp":1591585616556,"user_tz":-480,"elapsed":1152,"user":{"displayName":"SM Health","photoUrl":"","userId":"14421832128980954224"}},"outputId":"76df4c65-454f-4ef2-da71-d6b7c966cc74"},"source":["# https://github.com/amir-abdi/keras_to_tensorflow/blob/master/keras_to_tensorflow.py\n","\n","#!/usr/bin/env python\n","\"\"\"\n","Copyright (c) 2019, by the Authors: Amir H. Abdi\n","This script is freely available under the MIT Public License.\n","Please see the License file in the root for details.\n","The following code snippet will convert the keras model files\n","to the freezed .pb tensorflow weight file. The resultant TensorFlow model\n","holds both the model architecture and its associated weights.\n","\"\"\"\n","\n","import tensorflow as tf\n","from tensorflow.python.framework import graph_util\n","from tensorflow.python.framework import graph_io\n","from pathlib import Path\n","from absl import app\n","from absl import flags\n","from absl import logging\n","import keras\n","from keras import backend as K\n","from keras.models import model_from_json, model_from_yaml\n","\n","K.set_learning_phase(0)\n","FLAGS = flags.FLAGS\n","\n","flags.DEFINE_string('input_model', None, 'Path to the input model.')\n","flags.DEFINE_string('input_model_json', None, 'Path to the input model '\n","                                              'architecture in json format.')\n","flags.DEFINE_string('input_model_yaml', None, 'Path to the input model '\n","                                              'architecture in yaml format.')\n","flags.DEFINE_string('output_model', None, 'Path where the converted model will '\n","                                          'be stored.')\n","flags.DEFINE_boolean('save_graph_def', False,\n","                     'Whether to save the graphdef.pbtxt file which contains '\n","                     'the graph definition in ASCII format.')\n","flags.DEFINE_string('output_nodes_prefix', None,\n","                    'If set, the output nodes will be renamed to '\n","                    '`output_nodes_prefix`+i, where `i` will numerate the '\n","                    'number of of output nodes of the network.')\n","flags.DEFINE_boolean('quantize', False,\n","                     'If set, the resultant TensorFlow graph weights will be '\n","                     'converted from float into eight-bit equivalents. See '\n","                     'documentation here: '\n","                     'https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms')\n","flags.DEFINE_boolean('channels_first', False,\n","                     'Whether channels are the first dimension of a tensor. '\n","                     'The default is TensorFlow behaviour where channels are '\n","                     'the last dimension.')\n","flags.DEFINE_boolean('output_meta_ckpt', False,\n","                     'If set to True, exports the model as .meta, .index, and '\n","                     '.data files, with a checkpoint file. These can be later '\n","                     'loaded in TensorFlow to continue training.')\n","\n","flags.mark_flag_as_required('input_model')\n","flags.mark_flag_as_required('output_model')\n","\n","\n","def load_model(input_model_path, input_json_path=None, input_yaml_path=None):\n","    if not Path(input_model_path).exists():\n","        raise FileNotFoundError(\n","            'Model file `{}` does not exist.'.format(input_model_path))\n","    try:\n","        model = keras.models.load_model(input_model_path)\n","        return model\n","    except FileNotFoundError as err:\n","        logging.error('Input mode file (%s) does not exist.', FLAGS.input_model)\n","        raise err\n","    except ValueError as wrong_file_err:\n","        if input_json_path:\n","            if not Path(input_json_path).exists():\n","                raise FileNotFoundError(\n","                    'Model description json file `{}` does not exist.'.format(\n","                        input_json_path))\n","            try:\n","                model = model_from_json(open(str(input_json_path)).read())\n","                model.load_weights(input_model_path)\n","                return model\n","            except Exception as err:\n","                logging.error(\"Couldn't load model from json.\")\n","                raise err\n","        elif input_yaml_path:\n","            if not Path(input_yaml_path).exists():\n","                raise FileNotFoundError(\n","                    'Model description yaml file `{}` does not exist.'.format(\n","                        input_yaml_path))\n","            try:\n","                model = model_from_yaml(open(str(input_yaml_path)).read())\n","                model.load_weights(input_model_path)\n","                return model\n","            except Exception as err:\n","                logging.error(\"Couldn't load model from yaml.\")\n","                raise err\n","        else:\n","            logging.error(\n","                'Input file specified only holds the weights, and not '\n","                'the model definition. Save the model using '\n","                'model.save(filename.h5) which will contain the network '\n","                'architecture as well as its weights. '\n","                'If the model is saved using the '\n","                'model.save_weights(filename) function, either '\n","                'input_model_json or input_model_yaml flags should be set to '\n","                'to import the network architecture prior to loading the '\n","                'weights. \\n'\n","                'Check the keras documentation for more details '\n","                '(https://keras.io/getting-started/faq/)')\n","            raise wrong_file_err\n","\n","\n","def main(args):\n","    # If output_model path is relative and in cwd, make it absolute from root\n","    output_model = FLAGS.output_model\n","    if str(Path(output_model).parent) == '.':\n","        output_model = str((Path.cwd() / output_model))\n","\n","    output_fld = Path(output_model).parent\n","    output_model_name = Path(output_model).name\n","    output_model_stem = Path(output_model).stem\n","    output_model_pbtxt_name = output_model_stem + '.pbtxt'\n","\n","    # Create output directory if it does not exist\n","    Path(output_model).parent.mkdir(parents=True, exist_ok=True)\n","\n","    if FLAGS.channels_first:\n","        K.set_image_data_format('channels_first')\n","    else:\n","        K.set_image_data_format('channels_last')\n","\n","    model = load_model(FLAGS.input_model, FLAGS.input_model_json, FLAGS.input_model_yaml)\n","\n","    # TODO(amirabdi): Support networks with multiple inputs\n","    orig_output_node_names = [node.op.name for node in model.outputs]\n","    if FLAGS.output_nodes_prefix:\n","        num_output = len(orig_output_node_names)\n","        pred = [None] * num_output\n","        converted_output_node_names = [None] * num_output\n","\n","        # Create dummy tf nodes to rename output\n","        for i in range(num_output):\n","            converted_output_node_names[i] = '{}{}'.format(\n","                FLAGS.output_nodes_prefix, i)\n","            pred[i] = tf.identity(model.outputs[i],\n","                                  name=converted_output_node_names[i])\n","    else:\n","        converted_output_node_names = orig_output_node_names\n","    logging.info('Converted output node names are: %s',\n","                 str(converted_output_node_names))\n","\n","    sess = K.get_session()\n","    if FLAGS.output_meta_ckpt:\n","        saver = tf.train.Saver()\n","        saver.save(sess, str(output_fld / output_model_stem))\n","\n","    if FLAGS.save_graph_def:\n","        tf.train.write_graph(sess.graph.as_graph_def(), str(output_fld),\n","                             output_model_pbtxt_name, as_text=True)\n","        logging.info('Saved the graph definition in ascii format at %s',\n","                     str(Path(output_fld) / output_model_pbtxt_name))\n","\n","    if FLAGS.quantize:\n","        from tensorflow.tools.graph_transforms import TransformGraph\n","        transforms = [\"quantize_weights\", \"quantize_nodes\"]\n","        transformed_graph_def = TransformGraph(sess.graph.as_graph_def(), [], converted_output_node_names, transforms)\n","        constant_graph = graph_util.convert_variables_to_constants(\n","            sess,\n","            transformed_graph_def,\n","            converted_output_node_names)\n","    else:\n","        constant_graph = graph_util.convert_variables_to_constants(\n","            sess,\n","            sess.graph.as_graph_def(),\n","            converted_output_node_names)\n","\n","    graph_io.write_graph(constant_graph, str(output_fld), output_model_name, as_text=False)\n","    logging.info('Saved the freezed graph at %s', str(Path(output_fld) / output_model_name))\n","\n","\n","if __name__ == \"__main__\":\n","    app.run(main)\n","\n","\n","# main('/content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/models/github_yeyupiaoling_resnet50.h5'， '/content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/models/github_yeyupiaoling_resnet50.h5.pb')"],"execution_count":null,"outputs":[{"output_type":"error","ename":"DuplicateFlagError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mDuplicateFlagError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-56f4f5947187>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mFLAGS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input_model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Path to the input model.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m flags.DEFINE_string('input_model_json', None, 'Path to the input model '\n\u001b[1;32m     29\u001b[0m                                               'architecture in json format.')\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/absl/flags/_defines.py\u001b[0m in \u001b[0;36mDEFINE_string\u001b[0;34m(name, default, help, flag_values, **args)\u001b[0m\n\u001b[1;32m    239\u001b[0m   \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_argument_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m   \u001b[0mserializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_argument_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m   \u001b[0mDEFINE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/absl/flags/_defines.py\u001b[0m in \u001b[0;36mDEFINE\u001b[0;34m(parser, name, default, help, flag_values, serializer, module_name, **args)\u001b[0m\n\u001b[1;32m     80\u001b[0m   \"\"\"\n\u001b[1;32m     81\u001b[0m   DEFINE_flag(_flag.Flag(parser, serializer, name, default, help, **args),\n\u001b[0;32m---> 82\u001b[0;31m               flag_values, module_name)\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/absl/flags/_defines.py\u001b[0m in \u001b[0;36mDEFINE_flag\u001b[0;34m(flag, flag_values, module_name)\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;31m# Copying the reference to flag_values prevents pychecker warnings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m   \u001b[0mfv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m   \u001b[0mfv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mflag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m   \u001b[0;31m# Tell flag_values who's defining the flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/absl/flags/_flagvalues.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, name, flag)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;31m# module is simply being imported a subsequent time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0m_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDuplicateFlagError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_flag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m     \u001b[0mshort_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshort_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;31m# If a new flag overrides an old one, we need to cleanup the old flag's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mDuplicateFlagError\u001b[0m: The flag 'input_model' is defined twice. First from /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py, Second from /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py.  Description from first occurrence: Path to the input model."]}]},{"cell_type":"code","metadata":{"id":"x7KFwwAq6qCt","colab":{"base_uri":"https://localhost:8080/","height":245},"executionInfo":{"status":"error","timestamp":1591586464147,"user_tz":-480,"elapsed":1085,"user":{"displayName":"SM Health","photoUrl":"","userId":"14421832128980954224"}},"outputId":"2b06b746-c6ac-4e73-bbfc-6047ba4e5075"},"source":["\n","# https://stackoverflow.com/questions/45466020/how-to-export-keras-h5-to-tensorflow-pb\n","\n","def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n","    \"\"\"\n","    Freezes the state of a session into a pruned computation graph.\n","\n","    Creates a new computation graph where variable nodes are replaced by\n","    constants taking their current value in the session. The new graph will be\n","    pruned so subgraphs that are not necessary to compute the requested\n","    outputs are removed.\n","    @param session The TensorFlow session to be frozen.\n","    @param keep_var_names A list of variable names that should not be frozen,\n","                          or None to freeze all the variables in the graph.\n","    @param output_names Names of the relevant graph outputs.\n","    @param clear_devices Remove the device directives from the graph for better portability.\n","    @return The frozen graph definition.\n","    \"\"\"\n","    graph = session.graph\n","    with graph.as_default():\n","        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n","        output_names = output_names or []\n","        output_names += [v.op.name for v in tf.global_variables()]\n","        input_graph_def = graph.as_graph_def()\n","        if clear_devices:\n","            for node in input_graph_def.node:\n","                node.device = \"\"\n","        frozen_graph = tf.graph_util.convert_variables_to_constants(\n","            session, input_graph_def, output_names, freeze_var_names)\n","        return frozen_graph\n","\n","\n","\n","from keras import backend as K\n","\n","# Create, compile and train model...\n","\n","# frozen_graph = freeze_session(K.get_session(), output_names=[out.op.name for out in model.outputs])\n","frozen_graph = freeze_session(tf.keras.backend.get_session(), output_names=[out.op.name for out in model.outputs])\n","\n","\n","# Then you can write the graph to a file as usual with tf.train.write_graph:\n","\n","tf.train.write_graph(frozen_graph, \"/content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/models/github_yeyupiaoling_resnet50.h5\", \"my_model.pb\", as_text=False)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-0f81f1aff060>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# frozen_graph = freeze_session(K.get_session(), output_names=[out.op.name for out in model.outputs])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mfrozen_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfreeze_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.keras.backend' has no attribute 'get_session'"]}]},{"cell_type":"code","metadata":{"id":"CRXZIr_n8Rbh","colab":{"base_uri":"https://localhost:8080/","height":263},"executionInfo":{"status":"error","timestamp":1591586530594,"user_tz":-480,"elapsed":26629,"user":{"displayName":"SM Health","photoUrl":"","userId":"14421832128980954224"}},"outputId":"cae244ad-4c4e-4524-f023-943748198fca"},"source":["# https://stackoverflow.com/questions/55303156/keras-h5-to-tensorflow-serving-in-2019\n","\n","from tensorflow import keras\n","model = keras.models.load_model('/content/drive/My Drive/audio_classifier_tutorial/inception_dec_2015/models/github_yeyupiaoling_resnet50.h5')\n","\n","keras.experimental.export_saved_model(model, '/content/drive/My Drive/audio_classifier_tutorial/inception_dec_2015/tensorflow_inception_graph.pb')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0608 03:30:55.979692 140202015917952 hdf5_format.py:187] No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"],"name":"stderr"},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-f7bf1d8f009b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/models/github_yeyupiaoling_resnet50.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/My Drive/audio_classifier_tutorial/UrbanSound8K/models/github_yeyupiaoling_resnet50.h5.pb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.keras.experimental' has no attribute 'export_saved_model'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gY9MrsOoL4oC","executionInfo":{"status":"ok","timestamp":1611555394399,"user_tz":-480,"elapsed":1338,"user":{"displayName":"SM Health","photoUrl":"","userId":"14421832128980954224"}},"outputId":"6b8f42ad-dbab-4cca-e0f1-e2c88a03c9ea"},"source":["!pwd"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QtQdkrKFL6q7","executionInfo":{"status":"ok","timestamp":1611555401184,"user_tz":-480,"elapsed":948,"user":{"displayName":"SM Health","photoUrl":"","userId":"14421832128980954224"}},"outputId":"bb395f4d-59f2-4319-9f53-80191c2f49c1"},"source":["!ls"],"execution_count":2,"outputs":[{"output_type":"stream","text":["sample_data\n"],"name":"stdout"}]}]}